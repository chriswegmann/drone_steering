{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posture Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Engineer features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import libraries and define transformers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from keras.utils import to_categorical\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ipytest.magics\n",
    "import pytest\n",
    "__file__ = 'drone_pos_model_christian.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shuffler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        x=x.loc[np.random.permutation(x.index)]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, x_columns):\n",
    "        self.x_columns = x_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_x\",\"leftShoulder_x\"]].sum(axis=1)/4\n",
    "        for col in self.x_columns:\n",
    "            x[col] = x[col] - shift\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, y_columns):\n",
    "        self.y_columns = y_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_y\",\"leftShoulder_y\",\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/4\n",
    "        for col in list(set(self.y_columns)-set([\"label\"])):\n",
    "            x[col] = x[col] - shift\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shoulder_y = x[[\"rightShoulder_y\",\"leftShoulder_y\"]].sum(axis=1)/2\n",
    "        hip_y = x[[\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/2\n",
    "        y_dist = hip_y - shoulder_y\n",
    "        \n",
    "        for col in list(set(x.columns)-set([\"label\"])):\n",
    "            x[col] /= y_dist\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1867, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364.388477</td>\n",
       "      <td>175.727292</td>\n",
       "      <td>326.376146</td>\n",
       "      <td>176.318343</td>\n",
       "      <td>373.932203</td>\n",
       "      <td>185.283770</td>\n",
       "      <td>323.401138</td>\n",
       "      <td>178.613052</td>\n",
       "      <td>363.882516</td>\n",
       "      <td>247.058341</td>\n",
       "      <td>335.419796</td>\n",
       "      <td>245.791503</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>362.043733</td>\n",
       "      <td>162.669425</td>\n",
       "      <td>322.806684</td>\n",
       "      <td>162.934143</td>\n",
       "      <td>368.892477</td>\n",
       "      <td>106.262375</td>\n",
       "      <td>314.567677</td>\n",
       "      <td>103.431298</td>\n",
       "      <td>360.476755</td>\n",
       "      <td>244.545429</td>\n",
       "      <td>332.341002</td>\n",
       "      <td>246.078227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>361.398062</td>\n",
       "      <td>161.761029</td>\n",
       "      <td>319.718081</td>\n",
       "      <td>157.452745</td>\n",
       "      <td>359.997208</td>\n",
       "      <td>94.588426</td>\n",
       "      <td>315.145723</td>\n",
       "      <td>95.310308</td>\n",
       "      <td>358.496267</td>\n",
       "      <td>245.388146</td>\n",
       "      <td>332.033283</td>\n",
       "      <td>245.604833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>356.940976</td>\n",
       "      <td>156.356530</td>\n",
       "      <td>317.715580</td>\n",
       "      <td>160.940937</td>\n",
       "      <td>355.271911</td>\n",
       "      <td>92.585746</td>\n",
       "      <td>315.198539</td>\n",
       "      <td>95.782529</td>\n",
       "      <td>355.675736</td>\n",
       "      <td>241.225170</td>\n",
       "      <td>332.092374</td>\n",
       "      <td>243.839404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>355.355181</td>\n",
       "      <td>159.860870</td>\n",
       "      <td>319.357292</td>\n",
       "      <td>159.059428</td>\n",
       "      <td>355.228806</td>\n",
       "      <td>95.781997</td>\n",
       "      <td>315.496033</td>\n",
       "      <td>96.264859</td>\n",
       "      <td>355.045702</td>\n",
       "      <td>243.383177</td>\n",
       "      <td>330.646016</td>\n",
       "      <td>244.469512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "0       364.388477      175.727292       326.376146       176.318343   \n",
       "9       362.043733      162.669425       322.806684       162.934143   \n",
       "10      361.398062      161.761029       319.718081       157.452745   \n",
       "11      356.940976      156.356530       317.715580       160.940937   \n",
       "12      355.355181      159.860870       319.357292       159.059428   \n",
       "\n",
       "    leftWrist_x  leftWrist_y  rightWrist_x  rightWrist_y   leftHip_x  \\\n",
       "0    373.932203   185.283770    323.401138    178.613052  363.882516   \n",
       "9    368.892477   106.262375    314.567677    103.431298  360.476755   \n",
       "10   359.997208    94.588426    315.145723     95.310308  358.496267   \n",
       "11   355.271911    92.585746    315.198539     95.782529  355.675736   \n",
       "12   355.228806    95.781997    315.496033     96.264859  355.045702   \n",
       "\n",
       "     leftHip_y  rightHip_x  rightHip_y  label  \n",
       "0   247.058341  335.419796  245.791503      3  \n",
       "9   244.545429  332.341002  246.078227      1  \n",
       "10  245.388146  332.033283  245.604833      1  \n",
       "11  241.225170  332.092374  243.839404      1  \n",
       "12  243.383177  330.646016  244.469512      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"posture_training_data\"\n",
    "df = pd.read_csv(\"../data/posture/\"+ path + \".csv\",low_memory=False)\n",
    "df = df.dropna().drop_duplicates()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.isnull().all().all() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set pipeline arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['leftShoulder_x', 'rightShoulder_x', 'leftWrist_x', 'rightWrist_x', 'leftHip_x' ,'rightHip_x']\n",
    "y_cols = list(set(df.columns)-set(x_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Build data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>2.722892</td>\n",
       "      <td>-0.504198</td>\n",
       "      <td>2.182960</td>\n",
       "      <td>-0.495802</td>\n",
       "      <td>2.858452</td>\n",
       "      <td>-0.368456</td>\n",
       "      <td>2.140703</td>\n",
       "      <td>-0.463208</td>\n",
       "      <td>2.715705</td>\n",
       "      <td>0.508997</td>\n",
       "      <td>2.311417</td>\n",
       "      <td>0.491003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>2.312823</td>\n",
       "      <td>-0.501604</td>\n",
       "      <td>1.837280</td>\n",
       "      <td>-0.498396</td>\n",
       "      <td>2.395828</td>\n",
       "      <td>-1.185243</td>\n",
       "      <td>1.737426</td>\n",
       "      <td>-1.219555</td>\n",
       "      <td>2.293832</td>\n",
       "      <td>0.490711</td>\n",
       "      <td>1.952834</td>\n",
       "      <td>0.509289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2.225171</td>\n",
       "      <td>-0.474920</td>\n",
       "      <td>1.739897</td>\n",
       "      <td>-0.525080</td>\n",
       "      <td>2.208861</td>\n",
       "      <td>-1.257000</td>\n",
       "      <td>1.686662</td>\n",
       "      <td>-1.248596</td>\n",
       "      <td>2.191386</td>\n",
       "      <td>0.498739</td>\n",
       "      <td>1.883281</td>\n",
       "      <td>0.501261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2.244502</td>\n",
       "      <td>-0.527326</td>\n",
       "      <td>1.776885</td>\n",
       "      <td>-0.472674</td>\n",
       "      <td>2.224605</td>\n",
       "      <td>-1.287556</td>\n",
       "      <td>1.746879</td>\n",
       "      <td>-1.249446</td>\n",
       "      <td>2.229419</td>\n",
       "      <td>0.484417</td>\n",
       "      <td>1.948275</td>\n",
       "      <td>0.515583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>2.210080</td>\n",
       "      <td>-0.495256</td>\n",
       "      <td>1.783899</td>\n",
       "      <td>-0.504744</td>\n",
       "      <td>2.208584</td>\n",
       "      <td>-1.253889</td>\n",
       "      <td>1.738185</td>\n",
       "      <td>-1.248173</td>\n",
       "      <td>2.206416</td>\n",
       "      <td>0.493569</td>\n",
       "      <td>1.917547</td>\n",
       "      <td>0.506431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "555         2.722892       -0.504198         2.182960        -0.495802   \n",
       "1505        2.312823       -0.501604         1.837280        -0.498396   \n",
       "560         2.225171       -0.474920         1.739897        -0.525080   \n",
       "300         2.244502       -0.527326         1.776885        -0.472674   \n",
       "1715        2.210080       -0.495256         1.783899        -0.504744   \n",
       "\n",
       "      leftWrist_x  leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  \\\n",
       "555      2.858452    -0.368456      2.140703     -0.463208   2.715705   \n",
       "1505     2.395828    -1.185243      1.737426     -1.219555   2.293832   \n",
       "560      2.208861    -1.257000      1.686662     -1.248596   2.191386   \n",
       "300      2.224605    -1.287556      1.746879     -1.249446   2.229419   \n",
       "1715     2.208584    -1.253889      1.738185     -1.248173   2.206416   \n",
       "\n",
       "      leftHip_y  rightHip_x  rightHip_y  label  \n",
       "555    0.508997    2.311417    0.491003      3  \n",
       "1505   0.490711    1.952834    0.509289      1  \n",
       "560    0.498739    1.883281    0.501261      1  \n",
       "300    0.484417    1.948275    0.515583      1  \n",
       "1715   0.493569    1.917547    0.506431      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_pipeline = make_pipeline(XCentralizer(x_cols), YCentralizer(y_cols), YScaler(), Shuffler())\n",
    "processed_df = processing_pipeline.fit_transform(df)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[0] == processed_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Split in train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processed_df.iloc[:int(processed_df.shape[0]*0.8)]\n",
    "df_test = processed_df.iloc[int(processed_df.shape[0]*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train.shape[0] + df_test.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define numpy arrays as needed by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['label'], axis=1).values\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "x_test = df_test.drop(['label'], axis=1).values\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1493, 12) (1493, 7)\n",
      "x_train[0]= [ 2.72289192 -0.50419768  2.18296018 -0.49580232  2.85845216 -0.36845632\n",
      "  2.14070281 -0.463208    2.7157052   0.50899717  2.31141728  0.49100283] \n",
      " y_train[0]= [0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape )\n",
    "print(\"x_train[0]=\", x_train[0],\"\\n y_train[0]=\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 112       \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import optimizers, losses, metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation=\"relu\", input_shape=(12, )))\n",
    "model.add(layers.Dense(15, activation=\"relu\"))\n",
    "model.add(layers.Dense(7, activation=\"softmax\")) \n",
    "model.summary()   \n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.005),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Fit and validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1194 samples, validate on 299 samples\n",
      "Epoch 1/500\n",
      "1194/1194 [==============================] - 0s 282us/step - loss: 1.2715 - acc: 0.5670 - val_loss: 0.9053 - val_acc: 0.6890\n",
      "Epoch 2/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.6187 - acc: 0.8543 - val_loss: 0.5223 - val_acc: 0.7893\n",
      "Epoch 3/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.2912 - acc: 0.9456 - val_loss: 0.2109 - val_acc: 0.9599\n",
      "Epoch 4/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 0.1246 - acc: 0.9883 - val_loss: 0.0791 - val_acc: 0.9967\n",
      "Epoch 5/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0593 - acc: 0.9941 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 6/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0298 - acc: 0.9975 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 7/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 0.0172 - acc: 0.9983 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 8/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0103 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 9/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "Epoch 10/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9967\n",
      "Epoch 11/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9967\n",
      "Epoch 12/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0050 - acc: 0.9975 - val_loss: 0.0052 - val_acc: 0.9967\n",
      "Epoch 13/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0067 - acc: 0.9975 - val_loss: 0.0058 - val_acc: 0.9967\n",
      "Epoch 14/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0041 - val_acc: 0.9967\n",
      "Epoch 15/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0039 - acc: 0.9983 - val_loss: 0.0073 - val_acc: 0.9967\n",
      "Epoch 16/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0045 - val_acc: 0.9967\n",
      "Epoch 17/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0046 - val_acc: 0.9967\n",
      "Epoch 18/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0035 - val_acc: 0.9967\n",
      "Epoch 19/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0042 - acc: 0.9983 - val_loss: 0.0053 - val_acc: 0.9967\n",
      "Epoch 20/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0021 - acc: 0.9983 - val_loss: 0.0067 - val_acc: 0.9967\n",
      "Epoch 21/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0099 - acc: 0.9966 - val_loss: 0.0050 - val_acc: 0.9967\n",
      "Epoch 22/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 0.0059 - acc: 0.9966 - val_loss: 0.0033 - val_acc: 0.9967\n",
      "Epoch 23/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 8.8274e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967\n",
      "Epoch 24/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 0.0075 - acc: 0.9966 - val_loss: 0.0051 - val_acc: 0.9967\n",
      "Epoch 25/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0040 - acc: 0.9975 - val_loss: 0.0064 - val_acc: 0.9967\n",
      "Epoch 26/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0037 - val_acc: 0.9967\n",
      "Epoch 28/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 29/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0028 - val_acc: 0.9967\n",
      "Epoch 30/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 6.7976e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0078 - acc: 0.9966 - val_loss: 0.0045 - val_acc: 0.9967\n",
      "Epoch 32/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 0.0011 - acc: 0.9992 - val_loss: 0.0042 - val_acc: 0.9967\n",
      "Epoch 33/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0055 - val_acc: 0.9967\n",
      "Epoch 34/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0067 - acc: 0.9975 - val_loss: 0.0045 - val_acc: 0.9967\n",
      "Epoch 35/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9967\n",
      "Epoch 36/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 0.0066 - acc: 0.9966 - val_loss: 0.0070 - val_acc: 0.9967\n",
      "Epoch 37/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 38/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 39/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 8.9672e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9967\n",
      "Epoch 40/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0038 - acc: 0.9975 - val_loss: 0.0046 - val_acc: 0.9967\n",
      "Epoch 41/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9967\n",
      "Epoch 42/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0052 - val_acc: 0.9967\n",
      "Epoch 43/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0104 - acc: 0.9975 - val_loss: 0.0081 - val_acc: 0.9967\n",
      "Epoch 44/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 45/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 6.7342e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9967\n",
      "Epoch 46/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9967\n",
      "Epoch 47/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0049 - val_acc: 0.9967\n",
      "Epoch 48/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0089 - val_acc: 0.9967\n",
      "Epoch 49/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 0.0102 - val_acc: 0.9967\n",
      "Epoch 50/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 0.0051 - acc: 0.9975 - val_loss: 0.0061 - val_acc: 0.9967\n",
      "Epoch 51/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 8.2219e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967\n",
      "Epoch 52/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0047 - acc: 0.9975 - val_loss: 0.0052 - val_acc: 0.9967\n",
      "Epoch 53/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "Epoch 54/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 0.0055 - acc: 0.9975 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Epoch 55/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "Epoch 56/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 57/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0016 - acc: 0.9992 - val_loss: 0.0056 - val_acc: 0.9967\n",
      "Epoch 58/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0036 - val_acc: 0.9967\n",
      "Epoch 59/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 3.9969e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9532\n",
      "Epoch 60/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 0.0054 - val_acc: 0.9967\n",
      "Epoch 61/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9967\n",
      "Epoch 62/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0118 - val_acc: 0.9967\n",
      "Epoch 63/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 7.2625e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9967\n",
      "Epoch 65/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0108 - val_acc: 0.9967\n",
      "Epoch 66/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 0.0036 - acc: 0.9983 - val_loss: 0.0064 - val_acc: 0.9967\n",
      "Epoch 67/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.6885e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 0.0016 - acc: 0.9992 - val_loss: 0.0053 - val_acc: 0.9967\n",
      "Epoch 69/500\n",
      "1194/1194 [==============================] - 0s 70us/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.0083 - val_acc: 0.9967\n",
      "Epoch 70/500\n",
      "1194/1194 [==============================] - 0s 69us/step - loss: 5.7004e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "1194/1194 [==============================] - 0s 63us/step - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0065 - val_acc: 0.9967\n",
      "Epoch 72/500\n",
      "1194/1194 [==============================] - 0s 68us/step - loss: 7.2285e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9967\n",
      "Epoch 73/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0080 - val_acc: 0.9967\n",
      "Epoch 74/500\n",
      "1194/1194 [==============================] - 0s 66us/step - loss: 5.3320e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.0055 - val_acc: 0.9967\n",
      "Epoch 76/500\n",
      "1194/1194 [==============================] - 0s 81us/step - loss: 4.4551e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9967\n",
      "Epoch 77/500\n",
      "1194/1194 [==============================] - 0s 85us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0071 - val_acc: 0.9967\n",
      "Epoch 78/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0081 - val_acc: 0.9967\n",
      "Epoch 79/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0153 - val_acc: 0.9967\n",
      "Epoch 80/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 81/500\n",
      "1194/1194 [==============================] - 0s 69us/step - loss: 0.0012 - acc: 0.9992 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0081 - val_acc: 0.9967\n",
      "Epoch 83/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 5.2030e-04 - acc: 1.0000 - val_loss: 3.1470e-04 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "1194/1194 [==============================] - 0s 66us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0114 - val_acc: 0.9967\n",
      "Epoch 85/500\n",
      "1194/1194 [==============================] - 0s 70us/step - loss: 5.0574e-04 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9967\n",
      "Epoch 86/500\n",
      "1194/1194 [==============================] - 0s 68us/step - loss: 2.9103e-04 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9599\n",
      "Epoch 87/500\n",
      "1194/1194 [==============================] - 0s 63us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 8.4212e-04 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 2.5190e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9967\n",
      "Epoch 89/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 0.0043 - acc: 0.9975 - val_loss: 0.0068 - val_acc: 0.9967\n",
      "Epoch 90/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 1.7577e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 5.6714e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9967\n",
      "Epoch 92/500\n",
      "1194/1194 [==============================] - 0s 63us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0079 - val_acc: 0.9967\n",
      "Epoch 93/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 0.0028 - acc: 0.9983 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 94/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 0.0010 - acc: 0.9992 - val_loss: 0.0030 - val_acc: 0.9967\n",
      "Epoch 95/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 9.3543e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9967\n",
      "Epoch 96/500\n",
      "1194/1194 [==============================] - 0s 63us/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0084 - val_acc: 0.9967\n",
      "Epoch 97/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 2.6931e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.6285e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9967\n",
      "Epoch 99/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0081 - val_acc: 0.9967\n",
      "Epoch 100/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 3.2766e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9967\n",
      "Epoch 101/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0143 - val_acc: 0.9967\n",
      "Epoch 102/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 0.0044 - acc: 0.9992 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "Epoch 103/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 2.5466e-04 - acc: 1.0000 - val_loss: 5.9559e-04 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 1.5027e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9967\n",
      "Epoch 105/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0083 - val_acc: 0.9967\n",
      "Epoch 106/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 1.5758e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9967\n",
      "Epoch 107/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 3.4137e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9967\n",
      "Epoch 108/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.9603e-04 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9967\n",
      "Epoch 109/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "Epoch 110/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 3.5805e-04 - acc: 1.0000 - val_loss: 3.6657e-04 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 8.0460e-04 - acc: 0.9992 - val_loss: 0.0186 - val_acc: 0.9967\n",
      "Epoch 112/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0166 - val_acc: 0.9967\n",
      "Epoch 113/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0140 - val_acc: 0.9967\n",
      "Epoch 114/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 8.7286e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9967\n",
      "Epoch 115/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 8.6295e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Epoch 116/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.8741e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9967\n",
      "Epoch 117/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0112 - val_acc: 0.9967\n",
      "Epoch 118/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0035 - acc: 0.9975 - val_loss: 0.0186 - val_acc: 0.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 6.2410e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9967\n",
      "Epoch 120/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0100 - val_acc: 0.9967\n",
      "Epoch 121/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.4027e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9967\n",
      "Epoch 122/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.0431e-04 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9967\n",
      "Epoch 123/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0139 - val_acc: 0.9967\n",
      "Epoch 124/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 4.6922e-04 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 0.9967\n",
      "Epoch 125/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0200 - val_acc: 0.9967\n",
      "Epoch 126/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0012 - acc: 0.9992 - val_loss: 0.0211 - val_acc: 0.9967\n",
      "Epoch 127/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0211 - val_acc: 0.9967\n",
      "Epoch 128/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0166 - val_acc: 0.9967\n",
      "Epoch 129/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 0.0014 - acc: 0.9992 - val_loss: 0.0174 - val_acc: 0.9967\n",
      "Epoch 130/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 3.2257e-04 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9967\n",
      "Epoch 131/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 7.2515e-05 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 0.9967\n",
      "Epoch 132/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0139 - val_acc: 0.9967\n",
      "Epoch 133/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 3.2102e-04 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9967\n",
      "Epoch 134/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "Epoch 135/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.6616e-04 - acc: 1.0000 - val_loss: 6.9357e-04 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 2.0585e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9967\n",
      "Epoch 137/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "Epoch 138/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0424 - val_acc: 0.9933\n",
      "Epoch 139/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 9.8873e-04 - acc: 0.9992 - val_loss: 9.4451e-04 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.4133e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9967\n",
      "Epoch 141/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.3234e-05 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9967\n",
      "Epoch 142/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0118 - val_acc: 0.9967\n",
      "Epoch 143/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.0475e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "Epoch 144/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0177 - val_acc: 0.9967\n",
      "Epoch 145/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.0430e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.8937e-04 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9967\n",
      "Epoch 147/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 3.3665e-04 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9967\n",
      "Epoch 148/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 2.2428e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9967\n",
      "Epoch 149/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 3.1720e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9967\n",
      "Epoch 150/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 5.6265e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9967\n",
      "Epoch 151/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 1.4291e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.2323e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9967\n",
      "Epoch 153/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0014 - acc: 0.9992 - val_loss: 0.0192 - val_acc: 0.9967\n",
      "Epoch 154/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 3.5525e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9967\n",
      "Epoch 155/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.3458e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 8.8817e-05 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9866\n",
      "Epoch 157/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0248 - val_acc: 0.9967\n",
      "Epoch 158/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0308 - val_acc: 0.9967\n",
      "Epoch 159/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0264 - val_acc: 0.9967\n",
      "Epoch 160/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 4.1761e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 7.1342e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9967\n",
      "Epoch 162/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 6.9676e-05 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9933\n",
      "Epoch 163/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0157 - val_acc: 0.9967\n",
      "Epoch 164/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 6.8617e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 6.9916e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 7.7291e-06 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9967\n",
      "Epoch 167/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0084 - val_acc: 0.9967\n",
      "Epoch 168/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.1558e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9967\n",
      "Epoch 169/500\n",
      "1194/1194 [==============================] - 0s 77us/step - loss: 4.0126e-04 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9933\n",
      "Epoch 170/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0024 - val_acc: 0.9967\n",
      "Epoch 171/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.6562e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9967\n",
      "Epoch 172/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.6979e-05 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9967\n",
      "Epoch 173/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 3.7923e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9967\n",
      "Epoch 174/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 8.9210e-06 - acc: 1.0000 - val_loss: 5.2202e-04 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 2.8438e-04 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 0.9967\n",
      "Epoch 176/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.9593e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 7.9778e-04 - acc: 0.9992 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "Epoch 178/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 3.7251e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 1.0285e-05 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9967\n",
      "Epoch 180/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 7.3405e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9967\n",
      "Epoch 181/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 1.6288e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967\n",
      "Epoch 182/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 5.6567e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 0.0038 - acc: 0.9983 - val_loss: 0.0100 - val_acc: 0.9967\n",
      "Epoch 184/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.0946e-05 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9967\n",
      "Epoch 185/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 3.7176e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9967\n",
      "Epoch 186/500\n",
      "1194/1194 [==============================] - 0s 63us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0134 - val_acc: 0.9967\n",
      "Epoch 187/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 2.2886e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 4.3923e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 189/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.6317e-05 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 0.9967\n",
      "Epoch 190/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0160 - val_acc: 0.9967\n",
      "Epoch 191/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 3.8997e-05 - acc: 1.0000 - val_loss: 1.3062e-04 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 8.7097e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0134 - val_acc: 0.9967\n",
      "Epoch 194/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 2.1298e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9967\n",
      "Epoch 195/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 6.9256e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.5956e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9967\n",
      "Epoch 197/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0172 - val_acc: 0.9967\n",
      "Epoch 198/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 6.6335e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967\n",
      "Epoch 199/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 2.0983e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 200/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.2111e-05 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9967\n",
      "Epoch 201/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 3.1334e-04 - acc: 1.0000 - val_loss: 2.6101e-05 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 1.0058e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9967\n",
      "Epoch 203/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 2.7636e-04 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9967\n",
      "Epoch 204/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 5.1823e-04 - acc: 1.0000 - val_loss: 3.6002e-05 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 2.6220e-04 - acc: 1.0000 - val_loss: 5.7343e-04 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 2.0896e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9967\n",
      "Epoch 207/500\n",
      "1194/1194 [==============================] - 0s 69us/step - loss: 2.5946e-04 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 0.9967\n",
      "Epoch 208/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0200 - val_acc: 0.9967\n",
      "Epoch 209/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 7.6553e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967\n",
      "Epoch 210/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 1.5425e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967\n",
      "Epoch 211/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 0.0017 - acc: 0.9992 - val_loss: 0.0147 - val_acc: 0.9967\n",
      "Epoch 212/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.0233e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Epoch 213/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 4.8146e-06 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9967\n",
      "Epoch 214/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 8.8374e-06 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9967\n",
      "Epoch 215/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0128 - val_acc: 0.9967\n",
      "Epoch 216/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 1.5768e-05 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9967\n",
      "Epoch 217/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 2.6072e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "1194/1194 [==============================] - 0s 43us/step - loss: 7.4084e-06 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9967\n",
      "Epoch 219/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.0100e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 1.8180e-06 - acc: 1.0000 - val_loss: 8.4996e-06 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 8.5518e-07 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9967\n",
      "Epoch 222/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 3.2659e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9967\n",
      "Epoch 223/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 3.3302e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967\n",
      "Epoch 224/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 5.6261e-04 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9933\n",
      "Epoch 225/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 1.0166e-05 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.7281e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9967\n",
      "Epoch 227/500\n",
      "1194/1194 [==============================] - 0s 43us/step - loss: 2.9820e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 8.4471e-06 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9967\n",
      "Epoch 229/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 1.9551e-06 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9967\n",
      "Epoch 230/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 0.0011 - acc: 0.9992 - val_loss: 0.0517 - val_acc: 0.9866\n",
      "Epoch 231/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 3.3707e-05 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "1194/1194 [==============================] - 0s 38us/step - loss: 7.8117e-05 - acc: 1.0000 - val_loss: 2.1539e-04 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 8.4611e-07 - acc: 1.0000 - val_loss: 3.9780e-04 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 1.0698e-05 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 9.1904e-04 - acc: 0.9992 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "1194/1194 [==============================] - 0s 40us/step - loss: 5.1487e-07 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 5.2156e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 2.0757e-05 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9933\n",
      "Epoch 239/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0039 - val_acc: 0.9967\n",
      "Epoch 240/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 9.9612e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967\n",
      "Epoch 241/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 7.6200e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 7.4379e-07 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9967\n",
      "Epoch 243/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 6.3343e-05 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9967\n",
      "Epoch 244/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 0.0010 - acc: 0.9992 - val_loss: 6.5633e-05 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "1194/1194 [==============================] - 0s 40us/step - loss: 2.3036e-06 - acc: 1.0000 - val_loss: 8.4501e-05 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.3399e-06 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "Epoch 247/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 3.7331e-06 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9933\n",
      "Epoch 248/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 7.4476e-04 - acc: 0.9992 - val_loss: 0.0109 - val_acc: 0.9967\n",
      "Epoch 249/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 3.0047e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9967\n",
      "Epoch 250/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 3.0731e-06 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9967\n",
      "Epoch 251/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 1.5301e-04 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9967\n",
      "Epoch 252/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 6.3773e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 4.8086e-07 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9967\n",
      "Epoch 254/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 3.5224e-05 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9967\n",
      "Epoch 255/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 7.4836e-05 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9833\n",
      "Epoch 256/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 1.2027e-05 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 6.1537e-06 - acc: 1.0000 - val_loss: 1.4610e-04 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 7.1671e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9967\n",
      "Epoch 259/500\n",
      "1194/1194 [==============================] - 0s 40us/step - loss: 1.0468e-06 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 0.9967\n",
      "Epoch 260/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 4.1912e-06 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9967\n",
      "Epoch 261/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0168 - val_acc: 0.9967\n",
      "Epoch 262/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 5.8283e-06 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9967\n",
      "Epoch 263/500\n",
      "1194/1194 [==============================] - 0s 46us/step - loss: 5.3783e-07 - acc: 1.0000 - val_loss: 1.4711e-04 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 3.7999e-04 - acc: 1.0000 - val_loss: 7.2717e-06 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 4.7761e-04 - acc: 1.0000 - val_loss: 4.4309e-04 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 3.5250e-07 - acc: 1.0000 - val_loss: 5.8524e-04 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "1194/1194 [==============================] - 0s 45us/step - loss: 3.2564e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 8.8884e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9967\n",
      "Epoch 269/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.2819e-06 - acc: 1.0000 - val_loss: 1.3582e-05 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "1194/1194 [==============================] - 0s 46us/step - loss: 1.4351e-05 - acc: 1.0000 - val_loss: 2.6719e-05 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 5.2884e-07 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9967\n",
      "Epoch 272/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 2.0599e-06 - acc: 1.0000 - val_loss: 6.4024e-04 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 3.7653e-06 - acc: 1.0000 - val_loss: 1.2035e-05 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 7.8782e-06 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9967\n",
      "Epoch 275/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 2.1900e-05 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9967\n",
      "Epoch 276/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 0.0020 - acc: 0.9983 - val_loss: 0.0400 - val_acc: 0.9967\n",
      "Epoch 277/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 7.3940e-04 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9967\n",
      "Epoch 278/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.1804e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 2.0872e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 2.1561e-07 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9967\n",
      "Epoch 281/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0117 - val_acc: 0.9967\n",
      "Epoch 282/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.0307e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9967\n",
      "Epoch 283/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 9.8332e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9967\n",
      "Epoch 284/500\n",
      "1194/1194 [==============================] - 0s 40us/step - loss: 2.5720e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967\n",
      "Epoch 285/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 2.5380e-07 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9967\n",
      "Epoch 286/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 8.7630e-04 - acc: 0.9992 - val_loss: 0.0114 - val_acc: 0.9967\n",
      "Epoch 287/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 8.0124e-07 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9967\n",
      "Epoch 288/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 7.7142e-07 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9967\n",
      "Epoch 289/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 5.6471e-07 - acc: 1.0000 - val_loss: 3.5136e-05 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "1194/1194 [==============================] - 0s 46us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "Epoch 291/500\n",
      "1194/1194 [==============================] - 0s 43us/step - loss: 6.7528e-07 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "Epoch 292/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 5.8795e-07 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9967\n",
      "Epoch 293/500\n",
      "1194/1194 [==============================] - 0s 43us/step - loss: 3.8357e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9967\n",
      "Epoch 294/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 4.8303e-06 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9967\n",
      "Epoch 295/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 9.3284e-04 - acc: 0.9992 - val_loss: 0.0337 - val_acc: 0.9967\n",
      "Epoch 296/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 8.3840e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 1.8291e-07 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.8401e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 4.8522e-07 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9933\n",
      "Epoch 300/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 1.1358e-04 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 0.9933\n",
      "Epoch 301/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 3.0653e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9967\n",
      "Epoch 302/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 1.9594e-07 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967\n",
      "Epoch 303/500\n",
      "1194/1194 [==============================] - 0s 45us/step - loss: 2.1032e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 0.0016 - acc: 0.9992 - val_loss: 0.0154 - val_acc: 0.9967\n",
      "Epoch 305/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.3589e-06 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 306/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 9.4040e-07 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9967\n",
      "Epoch 307/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 3.4393e-07 - acc: 1.0000 - val_loss: 6.7259e-05 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "1194/1194 [==============================] - 0s 36us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 3.7851e-05 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 1.1335e-04 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9967\n",
      "Epoch 310/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 1.3068e-06 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "Epoch 311/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 5.6935e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 3.3324e-04 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9967\n",
      "Epoch 313/500\n",
      "1194/1194 [==============================] - ETA: 0s - loss: 6.1370e-06 - acc: 1.000 - 0s 42us/step - loss: 6.0160e-06 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9967\n",
      "Epoch 314/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 2.3732e-06 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Epoch 315/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 3.0288e-07 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9967\n",
      "Epoch 316/500\n",
      "1194/1194 [==============================] - 0s 40us/step - loss: 4.4722e-07 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9866\n",
      "Epoch 317/500\n",
      "1194/1194 [==============================] - 0s 43us/step - loss: 3.8150e-04 - acc: 1.0000 - val_loss: 1.1235e-05 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 5.9174e-06 - acc: 1.0000 - val_loss: 1.7752e-04 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 2.6189e-07 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 2.6479e-07 - acc: 1.0000 - val_loss: 8.1619e-05 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 5.8480e-06 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 2.0329e-05 - acc: 1.0000 - val_loss: 2.2697e-05 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 1.2132e-06 - acc: 1.0000 - val_loss: 4.8410e-04 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.7882e-07 - acc: 1.0000 - val_loss: 7.3163e-04 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.5520e-07 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9967\n",
      "Epoch 326/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 4.3349e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9967\n",
      "Epoch 327/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 4.4046e-07 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9967\n",
      "Epoch 328/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 3.9986e-07 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9967\n",
      "Epoch 329/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 2.0607e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 3.2594e-07 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9967\n",
      "Epoch 331/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 4.4386e-04 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 0.9967\n",
      "Epoch 332/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 3.6837e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9967\n",
      "Epoch 333/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 3.9661e-07 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "Epoch 334/500\n",
      "1194/1194 [==============================] - 0s 68us/step - loss: 3.4278e-07 - acc: 1.0000 - val_loss: 6.5466e-04 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.5091e-07 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9967\n",
      "Epoch 336/500\n",
      "1194/1194 [==============================] - 0s 69us/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 337/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 5.6262e-07 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9967\n",
      "Epoch 338/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 5.4698e-07 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9967\n",
      "Epoch 339/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 3.9506e-07 - acc: 1.0000 - val_loss: 5.6175e-04 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 1.8600e-07 - acc: 1.0000 - val_loss: 3.2726e-05 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 4.4307e-07 - acc: 1.0000 - val_loss: 0.0646 - val_acc: 0.9933\n",
      "Epoch 342/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 1.1299e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 343/500\n",
      "1194/1194 [==============================] - 0s 67us/step - loss: 6.8604e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967\n",
      "Epoch 344/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 3.5614e-05 - acc: 1.0000 - val_loss: 1.3605e-04 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.9194e-07 - acc: 1.0000 - val_loss: 4.3974e-04 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.9519e-07 - acc: 1.0000 - val_loss: 1.0372e-05 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 9.7534e-04 - acc: 0.9992 - val_loss: 1.5238e-05 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 8.3244e-05 - acc: 1.0000 - val_loss: 2.1456e-05 - val_acc: 1.0000\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194/1194 [==============================] - 0s 50us/step - loss: 4.2551e-07 - acc: 1.0000 - val_loss: 3.9874e-05 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 2.7282e-07 - acc: 1.0000 - val_loss: 9.7674e-05 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.7722e-07 - acc: 1.0000 - val_loss: 6.9660e-05 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 9.4653e-05 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9866\n",
      "Epoch 353/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 2.2101e-06 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9866\n",
      "Epoch 354/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.5409e-07 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9967\n",
      "Epoch 355/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.6753e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.4277e-07 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9967\n",
      "Epoch 357/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 7.8645e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 358/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 5.9184e-07 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9967\n",
      "Epoch 359/500\n",
      "1194/1194 [==============================] - 0s 44us/step - loss: 3.1277e-07 - acc: 1.0000 - val_loss: 2.2701e-04 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.4058e-07 - acc: 1.0000 - val_loss: 5.4536e-04 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.8441e-07 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9967\n",
      "Epoch 362/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 2.6566e-04 - acc: 1.0000 - val_loss: 5.0935e-05 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 0.0012 - acc: 0.9992 - val_loss: 8.7731e-06 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 8.8468e-07 - acc: 1.0000 - val_loss: 1.0658e-05 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 5.3162e-07 - acc: 1.0000 - val_loss: 2.5199e-05 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 2.1975e-07 - acc: 1.0000 - val_loss: 5.3006e-05 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "1194/1194 [==============================] - 0s 46us/step - loss: 3.1835e-07 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9967\n",
      "Epoch 368/500\n",
      "1194/1194 [==============================] - 0s 37us/step - loss: 1.1342e-04 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9967\n",
      "Epoch 369/500\n",
      "1194/1194 [==============================] - 0s 51us/step - loss: 1.8757e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9967\n",
      "Epoch 370/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.6579e-07 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9967\n",
      "Epoch 371/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 2.4641e-07 - acc: 1.0000 - val_loss: 0.0518 - val_acc: 0.9967\n",
      "Epoch 372/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 8.3990e-04 - acc: 0.9992 - val_loss: 0.0326 - val_acc: 0.9967\n",
      "Epoch 373/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 2.6051e-05 - acc: 1.0000 - val_loss: 9.3452e-06 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "1194/1194 [==============================] - 0s 66us/step - loss: 5.4793e-07 - acc: 1.0000 - val_loss: 6.2833e-05 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.4796e-07 - acc: 1.0000 - val_loss: 3.6641e-04 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.3443e-07 - acc: 1.0000 - val_loss: 3.2172e-05 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 1.5906e-04 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 0.9967\n",
      "Epoch 378/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 9.4854e-07 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9967\n",
      "Epoch 379/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 1.4427e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967\n",
      "Epoch 380/500\n",
      "1194/1194 [==============================] - 0s 45us/step - loss: 1.3588e-07 - acc: 1.0000 - val_loss: 2.0215e-04 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 1.2410e-07 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9967\n",
      "Epoch 382/500\n",
      "1194/1194 [==============================] - 0s 42us/step - loss: 6.5442e-07 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9833\n",
      "Epoch 383/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 4.2519e-06 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 8.1543e-06 - acc: 1.0000 - val_loss: 3.4289e-06 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 7.0894e-07 - acc: 1.0000 - val_loss: 5.9829e-06 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 2.7737e-07 - acc: 1.0000 - val_loss: 8.1229e-04 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "1194/1194 [==============================] - 0s 39us/step - loss: 1.2560e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967\n",
      "Epoch 388/500\n",
      "1194/1194 [==============================] - 0s 41us/step - loss: 1.6009e-07 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9967\n",
      "Epoch 389/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 0.0012 - acc: 0.9992 - val_loss: 0.0313 - val_acc: 0.9967\n",
      "Epoch 390/500\n",
      "1194/1194 [==============================] - 0s 45us/step - loss: 1.2052e-05 - acc: 1.0000 - val_loss: 2.6497e-04 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "1194/1194 [==============================] - 0s 47us/step - loss: 1.2490e-07 - acc: 1.0000 - val_loss: 2.7105e-04 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.2470e-07 - acc: 1.0000 - val_loss: 3.2992e-04 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "1194/1194 [==============================] - 0s 40us/step - loss: 1.2440e-07 - acc: 1.0000 - val_loss: 3.7392e-04 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.2325e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 6.7298e-05 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9967\n",
      "Epoch 396/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 5.2766e-07 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9967\n",
      "Epoch 397/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.7113e-07 - acc: 1.0000 - val_loss: 7.4788e-04 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 1.2360e-07 - acc: 1.0000 - val_loss: 6.0553e-04 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "1194/1194 [==============================] - 0s 68us/step - loss: 1.2315e-07 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9967\n",
      "Epoch 400/500\n",
      "1194/1194 [==============================] - 0s 69us/step - loss: 0.0048 - acc: 0.9992 - val_loss: 0.0134 - val_acc: 0.9967\n",
      "Epoch 401/500\n",
      "1194/1194 [==============================] - 0s 71us/step - loss: 2.2310e-07 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 402/500\n",
      "1194/1194 [==============================] - 0s 66us/step - loss: 2.2175e-07 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "Epoch 403/500\n",
      "1194/1194 [==============================] - 0s 64us/step - loss: 2.0687e-07 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9967\n",
      "Epoch 404/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 1.3728e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2530e-07 - acc: 1.0000 - val_loss: 4.0359e-04 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 9.3461e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9967\n",
      "Epoch 407/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.3808e-07 - acc: 1.0000 - val_loss: 5.6558e-04 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 1.2475e-07 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9967\n",
      "Epoch 409/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.4462e-07 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9967\n",
      "Epoch 410/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 8.1895e-04 - acc: 0.9992 - val_loss: 0.0217 - val_acc: 0.9967\n",
      "Epoch 411/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 5.3215e-07 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9967\n",
      "Epoch 412/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.4350e-07 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9967\n",
      "Epoch 413/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 3.2321e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.2225e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2280e-07 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.0697e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9967\n",
      "Epoch 417/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.2824e-07 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9967\n",
      "Epoch 418/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.1881e-07 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9967\n",
      "Epoch 419/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.3289e-07 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9967\n",
      "Epoch 420/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.3683e-07 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 0.9967\n",
      "Epoch 421/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 1.1486e-04 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9967\n",
      "Epoch 422/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 9.5244e-07 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "Epoch 423/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.5775e-07 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9967\n",
      "Epoch 424/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.4192e-07 - acc: 1.0000 - val_loss: 5.1155e-05 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "1194/1194 [==============================] - 0s 61us/step - loss: 1.6262e-06 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 0.9967\n",
      "Epoch 426/500\n",
      "1194/1194 [==============================] - 0s 65us/step - loss: 5.7138e-06 - acc: 1.0000 - val_loss: 1.4524e-05 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.2214e-06 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9799\n",
      "Epoch 428/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 2.6297e-05 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.4493e-06 - acc: 1.0000 - val_loss: 2.7514e-05 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.1101e-06 - acc: 1.0000 - val_loss: 6.6631e-05 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.9514e-07 - acc: 1.0000 - val_loss: 7.3966e-05 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.3159e-07 - acc: 1.0000 - val_loss: 9.5911e-04 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.2265e-07 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9967\n",
      "Epoch 434/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0215 - val_acc: 0.9967\n",
      "Epoch 435/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 3.0064e-07 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9967\n",
      "Epoch 436/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 2.8816e-07 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 0.9967\n",
      "Epoch 437/500\n",
      "1194/1194 [==============================] - 0s 62us/step - loss: 2.3768e-07 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "Epoch 438/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.6174e-07 - acc: 1.0000 - val_loss: 8.1367e-04 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 1.2355e-07 - acc: 1.0000 - val_loss: 6.5259e-05 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "1194/1194 [==============================] - 0s 79us/step - loss: 3.1927e-05 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 0.9967\n",
      "Epoch 441/500\n",
      "1194/1194 [==============================] - 0s 69us/step - loss: 2.3493e-07 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9967\n",
      "Epoch 442/500\n",
      "1194/1194 [==============================] - 0s 58us/step - loss: 1.9339e-07 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9967\n",
      "Epoch 443/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.4582e-07 - acc: 1.0000 - val_loss: 8.5874e-06 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 3.2709e-06 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9799\n",
      "Epoch 445/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.9485e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2780e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.2480e-07 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9967\n",
      "Epoch 448/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 1.0519e-06 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9967\n",
      "Epoch 449/500\n",
      "1194/1194 [==============================] - 0s 52us/step - loss: 5.5982e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.2081e-07 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2076e-07 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.2096e-07 - acc: 1.0000 - val_loss: 6.9595e-05 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9967\n",
      "Epoch 454/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.3615e-04 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9967\n",
      "Epoch 455/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 4.9184e-07 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9967\n",
      "Epoch 456/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.5151e-07 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9967\n",
      "Epoch 457/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.7283e-07 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9967\n",
      "Epoch 458/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.2720e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967\n",
      "Epoch 459/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 5.7396e-07 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 2.6398e-07 - acc: 1.0000 - val_loss: 0.0601 - val_acc: 0.9933\n",
      "Epoch 461/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 3.2978e-07 - acc: 1.0000 - val_loss: 6.3371e-05 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.3299e-07 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9900\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194/1194 [==============================] - 0s 54us/step - loss: 3.4500e-05 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9967\n",
      "Epoch 464/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 3.7334e-07 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9967\n",
      "Epoch 465/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.8241e-07 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2051e-07 - acc: 1.0000 - val_loss: 6.1312e-04 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.2036e-07 - acc: 1.0000 - val_loss: 1.6050e-05 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.8915e-07 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9866\n",
      "Epoch 469/500\n",
      "1194/1194 [==============================] - 0s 60us/step - loss: 0.0041 - acc: 0.9992 - val_loss: 4.0889e-06 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 4.2766e-06 - acc: 1.0000 - val_loss: 4.3474e-06 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 7.8174e-07 - acc: 1.0000 - val_loss: 5.2462e-06 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.9160e-07 - acc: 1.0000 - val_loss: 8.1040e-06 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "1194/1194 [==============================] - 0s 59us/step - loss: 1.3359e-07 - acc: 1.0000 - val_loss: 3.9975e-04 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 1.2036e-07 - acc: 1.0000 - val_loss: 9.2960e-05 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.3387e-05 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 0.9967\n",
      "Epoch 476/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.4097e-07 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9967\n",
      "Epoch 477/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.3678e-07 - acc: 1.0000 - val_loss: 3.5319e-06 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 0.0012 - acc: 0.9992 - val_loss: 5.8816e-06 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 5.1243e-05 - acc: 1.0000 - val_loss: 9.7867e-06 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 1.3399e-07 - acc: 1.0000 - val_loss: 9.7961e-06 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.3069e-07 - acc: 1.0000 - val_loss: 1.0263e-05 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.2745e-07 - acc: 1.0000 - val_loss: 1.9370e-05 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.2255e-07 - acc: 1.0000 - val_loss: 1.0131e-04 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 2.3683e-04 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9967\n",
      "Epoch 485/500\n",
      "1194/1194 [==============================] - 0s 57us/step - loss: 3.6151e-07 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 0.9967\n",
      "Epoch 486/500\n",
      "1194/1194 [==============================] - 0s 48us/step - loss: 3.0069e-07 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9967\n",
      "Epoch 487/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 2.0588e-07 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9967\n",
      "Epoch 488/500\n",
      "1194/1194 [==============================] - 0s 55us/step - loss: 1.2161e-07 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9967\n",
      "Epoch 489/500\n",
      "1194/1194 [==============================] - 0s 50us/step - loss: 1.2081e-07 - acc: 1.0000 - val_loss: 5.3195e-06 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 2.7836e-07 - acc: 1.0000 - val_loss: 3.2292e-06 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 3.1412e-05 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9967\n",
      "Epoch 492/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 6.9404e-07 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 493/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.4866e-07 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9967\n",
      "Epoch 494/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 1.3024e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 2.5844e-04 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 1.1991e-07 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9967\n",
      "Epoch 497/500\n",
      "1194/1194 [==============================] - 0s 53us/step - loss: 5.0376e-06 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 0.9967\n",
      "Epoch 498/500\n",
      "1194/1194 [==============================] - 0s 54us/step - loss: 4.6166e-07 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9967\n",
      "Epoch 499/500\n",
      "1194/1194 [==============================] - 0s 56us/step - loss: 1.2111e-07 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9967\n",
      "Epoch 500/500\n",
      "1194/1194 [==============================] - 0s 49us/step - loss: 1.2036e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=500, batch_size=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"acc\"],  label=[\"acc\"])\n",
    "plt.plot(history.history['val_acc'], label=[\"val_acc\"])\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=[\"loss\"]) \n",
    "plt.plot(history.history['val_loss'], label=[\"val_loss\"])\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.5 Evaluate with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374/374 [==============================] - 0s 29us/step\n",
      "Loss / Accuracy Evaluation\n",
      "--------------------------\n",
      "Loss:     0.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss / Accuracy Evaluation\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Loss:     \" + str(round(test_loss,5)))\n",
    "print(\"Accuracy: \" + str(round(test_acc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tes_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.0433497e-34, 1.0000000e+00, 1.3778420e-30, 2.9094296e-11,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tes_pred[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1 h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model, delete current reference and re-load it from file\n",
    "model.save('model_posture.h5')\n",
    "del model\n",
    "model = load_model('model_posture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.2 tensorflow.js format (JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflowjs library can't be installed directly with pip / conda due to conflicting dependencies. Best is to set up a new environment explicitly for this and install tensorflowjs with the following commands:\n",
    "\n",
    "```\n",
    "pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "pip install --no-deps tensorflowjs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "# ! pip install --no-deps tensorflowjs\n",
    "# ! pip install ipykernel\n",
    "# ! pip install tensorflow_hub\n",
    "# import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfjs.converters.save_keras_model(model, 'model_json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adapt the two files as follows in order for them to work on Azure:\n",
    "* add a file extension .pb to the file with no extension (otherwise Azure blocks it from viewing)\n",
    "* adapt the automatically generated model.json to reflect the extension .pb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
