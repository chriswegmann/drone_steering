{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model for Posture Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining transformers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#from category_encoders.one_hot import OneHotEncoder\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer\n",
    "#from category_encoders.ordinal import OrdinalEncoder\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ipytest.magics\n",
    "import pytest\n",
    "# set the file name (required)\n",
    "__file__ = 'drone_pos_model.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shuffler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        x=x.loc[np.random.permutation(x.index)]\n",
    "        \n",
    "        return x\n",
    "############################################################################################\n",
    "class XCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, x_columns):\n",
    "        self.x_columns = x_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_x\",\"leftShoulder_x\",\"leftHip_x\",\"rightHip_x\"]].sum(axis=1)/4\n",
    "        for col in self.x_columns:\n",
    "            x[col] = x[col] - shift\n",
    "        return x\n",
    "############################################################################################\n",
    "    \n",
    "class YCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, y_columns):\n",
    "        self.y_columns = y_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_y\",\"leftShoulder_y\",\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/4\n",
    "        for col in list(set(self.y_columns)-set([\"label\"])):\n",
    "            x[col] = x[col] - shift\n",
    "        return x\n",
    "############################################################################################\n",
    "\n",
    "class YScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shoulder_y = x[[\"rightShoulder_y\",\"leftShoulder_y\"]].sum(axis=1)/2\n",
    "        hip_y = x[[\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/2\n",
    "        y_dist = hip_y - shoulder_y\n",
    "        \n",
    "        for col in list(set(x.columns)-set([\"label\"])):\n",
    "            x[col] /= y_dist\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: \n",
      " [1 3 4 2 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.19500</td>\n",
       "      <td>0.50875</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.26625</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.41125</td>\n",
       "      <td>0.34625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.18875</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.18625</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.25875</td>\n",
       "      <td>0.33250</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.27625</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.46750</td>\n",
       "      <td>0.33625</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49125</td>\n",
       "      <td>0.19000</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.17875</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26125</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.19875</td>\n",
       "      <td>0.51125</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.26375</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.46375</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "0         0.49250         0.18750           0.4000          0.18250   \n",
       "1         0.49250         0.18875           0.4025          0.18625   \n",
       "2         0.49125         0.19000           0.4025          0.17875   \n",
       "\n",
       "   leftElbow_x  leftElbow_y  rightElbow_x  rightElbow_y  leftWrist_x  \\\n",
       "0       0.5050      0.26000       0.34375       0.19500      0.50875   \n",
       "1       0.5075      0.25875       0.33250       0.19750      0.50000   \n",
       "2       0.5050      0.26125       0.33500       0.19875      0.51125   \n",
       "\n",
       "   leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  leftHip_y  rightHip_x  \\\n",
       "0      0.33875       0.26625       0.16875    0.46500    0.34375     0.41125   \n",
       "1      0.33750       0.27625       0.17500    0.46750    0.33625     0.40875   \n",
       "2      0.33500       0.26375       0.16875    0.46375    0.33875     0.40875   \n",
       "\n",
       "   rightHip_y  label  \n",
       "0     0.34625      1  \n",
       "1     0.33750      1  \n",
       "2     0.33750      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pwd\n",
    "#df = pd.read_csv(\"video_001.csv\", delimiter=',')\n",
    "# Christian's video is less noisy. Therefore I only train the model with his data at the moment. \n",
    "# acc increased 5 % taking his video camparing to all videos.\n",
    "#path = \"all_videos_posture_steptime50_checksum8160\"\n",
    "#path = \"video_Christian_posture_steptime50_checksum8160\"\n",
    "path = \"video_all_posture_steptime50_checksum8160\"\n",
    "df = pd.read_csv(\"../data/\"+ path + \".csv\",low_memory=False)\n",
    "#df=df.drop([5557], axis=0)\n",
    "#type(df.leftShoulder_x)\n",
    "#df.info()\n",
    "#print(df.dtypes)\n",
    "#print()\n",
    "print('labels: \\n', df['label'].unique())\n",
    "#Â we have a mix of categorical, numeric, and string data.\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3719, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.dropna().drop_duplicates()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that we don't have any null values\n",
    "assert df1.isnull().all().all() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-pipline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1.copy()\n",
    "features_df = x.drop(\"label\", axis=1)\n",
    "label_df = x[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(features_df, label_df, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2975, 16), (744, 16), (2975,), (744,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df.shape, x_test_df.shape, y_train_df.shape, y_test_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.50875</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.26625</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.41125</td>\n",
       "      <td>0.34625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.18875</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.18625</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.25875</td>\n",
       "      <td>0.33250</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.27625</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>0.33625</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "0          0.4925         0.18750           0.4000          0.18250   \n",
       "1          0.4925         0.18875           0.4025          0.18625   \n",
       "\n",
       "   leftElbow_x  leftElbow_y  rightElbow_x  rightElbow_y  leftWrist_x  \\\n",
       "0       0.5050      0.26000       0.34375        0.1950      0.50875   \n",
       "1       0.5075      0.25875       0.33250        0.1975      0.50000   \n",
       "\n",
       "   leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  leftHip_y  rightHip_x  \\\n",
       "0      0.33875       0.26625       0.16875     0.4650    0.34375     0.41125   \n",
       "1      0.33750       0.27625       0.17500     0.4675    0.33625     0.40875   \n",
       "\n",
       "   rightHip_y  label  \n",
       "0     0.34625      1  \n",
       "1     0.33750      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df1.copy()\n",
    "#x=x.drop([\"label\"], axis = 1)\n",
    "x_cols = ['leftShoulder_x', 'rightShoulder_x',\n",
    "        'leftElbow_x', 'rightElbow_x',\n",
    "        'leftWrist_x', 'rightWrist_x',\n",
    "        'leftHip_x', 'rightHip_x']\n",
    "#xtrans = XCentralizer(x_cols)\n",
    "#x = xtrans.transform(x)\n",
    "\n",
    "y_cols = list(set(x.columns)-set(x_cols))\n",
    "#print(y_cols)\n",
    "#ytrans = YCentralizer(y_cols)\n",
    "#x = ytrans.transform(x)\n",
    "\n",
    "#ytrans = YScaler()\n",
    "#x = ytrans.transform(x)\n",
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "processing_pipeline = make_pipeline(\n",
    "    XCentralizer(x_cols),\n",
    "    YCentralizer(y_cols), \n",
    "    YScaler(),\n",
    "    Shuffler()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = processing_pipeline.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = processed_df.drop(\"label\", axis=1)\n",
    "label_df = processed_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================= test session starts =============================================================================\n",
      "platform darwin -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0\n",
      "rootdir: /Users/lsafari/drone_steering/models, inifile:\n",
      "plugins: remotedata-0.2.1, openfiles-0.3.0, doctestplus-0.1.3, arraydiff-0.2\n",
      "collected 1 item\n",
      "\n",
      "drone_pos_model.py .                                                                                                                                                    [100%]\n",
      "\n",
      "========================================================================== 1 passed in 0.03 seconds ===========================================================================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "def test_processingpipeline():\n",
    "    #Â remember, this first pipeline only acts on the features, not the target.\n",
    "    processed_df = processing_pipeline.fit_transform(x)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert x.shape[0] == processed_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processed_df.iloc[:int(processed_df.shape[0]*0.8)]\n",
    "df_val = processed_df.iloc[int(processed_df.shape[0]*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train.shape[0] + df_val.shape[0] == processed_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = df_train['label']\n",
    "x_train_df = df_train.drop('label', axis = 1)\n",
    "y_val_df = df_val['label']\n",
    "x_val_df = df_val.drop('label', axis = 1)\n",
    "x_train=x_train_df.values\n",
    "y_train=y_train_df.values\n",
    "x_val=x_val_df.values\n",
    "y_val=y_val_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= [ 0.31054687 -0.47265625 -0.28320312 -0.52734375  0.39648438  0.01171875\n",
      " -0.39257812 -0.02734375  0.39648438  0.50390625 -0.43164062  0.39453125\n",
      "  0.19335938  0.53515625 -0.22070312  0.46484375] \n",
      " y_train= 4\n"
     ]
    }
   ],
   "source": [
    "x_train\n",
    "print(\"x_train=\", x_train[0],\"\\n y_train=\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                340       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 735\n",
      "Trainable params: 735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import optimizers, losses, metrics\n",
    "\n",
    "\n",
    "#default vaues\n",
    "#activation=\"relu\"\n",
    "#optimizer=\"adam\"\n",
    "lr=0.01\n",
    "#momentum=0\n",
    "#creat model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(\n",
    "        20, \n",
    "        activation=\"relu\", \n",
    "        input_shape=(16, )))\n",
    "model.add(layers.Dense(15, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"softmax\")) #is a fast rectifier\n",
    "model.summary()   \n",
    "\n",
    "model.compile(\n",
    "optimizer=optimizers.RMSprop(lr=0.01),\n",
    "loss=losses.categorical_crossentropy,\n",
    "metrics=[\"accuracy\"] \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2975/2975 [==============================] - 0s 88us/step - loss: 1.1163 - acc: 0.5859\n",
      "Epoch 2/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.8038 - acc: 0.7509\n",
      "Epoch 3/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.7069 - acc: 0.7751\n",
      "Epoch 4/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.6252 - acc: 0.8118\n",
      "Epoch 5/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.5734 - acc: 0.8252\n",
      "Epoch 6/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.5474 - acc: 0.8339\n",
      "Epoch 7/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.5024 - acc: 0.8450\n",
      "Epoch 8/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.4997 - acc: 0.8491\n",
      "Epoch 9/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.4831 - acc: 0.8471\n",
      "Epoch 10/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.4673 - acc: 0.8575\n",
      "Epoch 11/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.4596 - acc: 0.8595\n",
      "Epoch 12/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.4356 - acc: 0.8679\n",
      "Epoch 13/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.4318 - acc: 0.8726\n",
      "Epoch 14/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.4181 - acc: 0.8699\n",
      "Epoch 15/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.4122 - acc: 0.8736\n",
      "Epoch 16/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.4191 - acc: 0.8699\n",
      "Epoch 17/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.4020 - acc: 0.8763\n",
      "Epoch 18/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.4131 - acc: 0.8709\n",
      "Epoch 19/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.4029 - acc: 0.8753\n",
      "Epoch 20/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3798 - acc: 0.8810\n",
      "Epoch 21/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3848 - acc: 0.8766\n",
      "Epoch 22/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3645 - acc: 0.8787\n",
      "Epoch 23/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3738 - acc: 0.8844\n",
      "Epoch 24/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3765 - acc: 0.8813\n",
      "Epoch 25/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3653 - acc: 0.8834\n",
      "Epoch 26/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3572 - acc: 0.8850\n",
      "Epoch 27/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.3580 - acc: 0.8881\n",
      "Epoch 28/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.3502 - acc: 0.8881\n",
      "Epoch 29/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.3507 - acc: 0.8897\n",
      "Epoch 30/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3428 - acc: 0.8911\n",
      "Epoch 31/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3418 - acc: 0.8894\n",
      "Epoch 32/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3387 - acc: 0.8951\n",
      "Epoch 33/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3434 - acc: 0.8911\n",
      "Epoch 34/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3339 - acc: 0.8955\n",
      "Epoch 35/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.3297 - acc: 0.8914\n",
      "Epoch 36/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3260 - acc: 0.8985\n",
      "Epoch 37/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3317 - acc: 0.8934\n",
      "Epoch 38/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3331 - acc: 0.8921\n",
      "Epoch 39/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3218 - acc: 0.8971\n",
      "Epoch 40/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3181 - acc: 0.8978\n",
      "Epoch 41/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3197 - acc: 0.8961\n",
      "Epoch 42/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3126 - acc: 0.8958\n",
      "Epoch 43/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3111 - acc: 0.8985\n",
      "Epoch 44/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3121 - acc: 0.9022\n",
      "Epoch 45/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3007 - acc: 0.9076\n",
      "Epoch 46/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3105 - acc: 0.8958\n",
      "Epoch 47/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3076 - acc: 0.8968\n",
      "Epoch 48/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3043 - acc: 0.9025\n",
      "Epoch 49/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3004 - acc: 0.9025\n",
      "Epoch 50/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3111 - acc: 0.9042\n",
      "Epoch 51/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2937 - acc: 0.9066\n",
      "Epoch 52/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2912 - acc: 0.9059\n",
      "Epoch 53/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2846 - acc: 0.9089\n",
      "Epoch 54/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2921 - acc: 0.9069\n",
      "Epoch 55/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2962 - acc: 0.9039\n",
      "Epoch 56/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3083 - acc: 0.9066\n",
      "Epoch 57/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2800 - acc: 0.9103\n",
      "Epoch 58/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2794 - acc: 0.9123\n",
      "Epoch 59/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2920 - acc: 0.9052\n",
      "Epoch 60/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2870 - acc: 0.9052\n",
      "Epoch 61/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2835 - acc: 0.9096\n",
      "Epoch 62/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2859 - acc: 0.9072\n",
      "Epoch 63/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2821 - acc: 0.9109\n",
      "Epoch 64/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2845 - acc: 0.9076\n",
      "Epoch 65/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2744 - acc: 0.9096\n",
      "Epoch 66/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2816 - acc: 0.9116\n",
      "Epoch 67/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2892 - acc: 0.9119\n",
      "Epoch 68/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2722 - acc: 0.9109\n",
      "Epoch 69/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2753 - acc: 0.9133\n",
      "Epoch 70/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2700 - acc: 0.9139\n",
      "Epoch 71/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2827 - acc: 0.9103\n",
      "Epoch 72/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2850 - acc: 0.9099\n",
      "Epoch 73/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2756 - acc: 0.9086\n",
      "Epoch 74/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2668 - acc: 0.9156\n",
      "Epoch 75/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2676 - acc: 0.9163\n",
      "Epoch 76/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2676 - acc: 0.9166\n",
      "Epoch 77/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2787 - acc: 0.9119\n",
      "Epoch 78/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2678 - acc: 0.9170\n",
      "Epoch 79/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2604 - acc: 0.9163\n",
      "Epoch 80/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2685 - acc: 0.9150\n",
      "Epoch 81/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2568 - acc: 0.9200\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2547 - acc: 0.9183\n",
      "Epoch 83/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2644 - acc: 0.9170\n",
      "Epoch 84/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2618 - acc: 0.9200\n",
      "Epoch 85/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2575 - acc: 0.9187\n",
      "Epoch 86/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2628 - acc: 0.9163\n",
      "Epoch 87/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2646 - acc: 0.9197\n",
      "Epoch 88/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2635 - acc: 0.9207\n",
      "Epoch 89/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2598 - acc: 0.9183\n",
      "Epoch 90/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2576 - acc: 0.9193\n",
      "Epoch 91/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2509 - acc: 0.9160\n",
      "Epoch 92/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2674 - acc: 0.9187\n",
      "Epoch 93/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2663 - acc: 0.9079\n",
      "Epoch 94/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2655 - acc: 0.9136\n",
      "Epoch 95/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2693 - acc: 0.9187\n",
      "Epoch 96/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2572 - acc: 0.9197\n",
      "Epoch 97/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2512 - acc: 0.9203\n",
      "Epoch 98/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2440 - acc: 0.9183\n",
      "Epoch 99/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2511 - acc: 0.9176\n",
      "Epoch 100/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2568 - acc: 0.9213\n",
      "Epoch 101/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2480 - acc: 0.9213\n",
      "Epoch 102/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2483 - acc: 0.9143\n",
      "Epoch 103/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2627 - acc: 0.9197\n",
      "Epoch 104/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2700 - acc: 0.9200\n",
      "Epoch 105/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2531 - acc: 0.9217\n",
      "Epoch 106/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2556 - acc: 0.9217\n",
      "Epoch 107/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2481 - acc: 0.9197\n",
      "Epoch 108/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2477 - acc: 0.9213\n",
      "Epoch 109/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2491 - acc: 0.9217\n",
      "Epoch 110/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2574 - acc: 0.9176\n",
      "Epoch 111/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2460 - acc: 0.9227\n",
      "Epoch 112/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2701 - acc: 0.9153\n",
      "Epoch 113/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2476 - acc: 0.9301\n",
      "Epoch 114/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2392 - acc: 0.9297\n",
      "Epoch 115/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2396 - acc: 0.9287\n",
      "Epoch 116/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2441 - acc: 0.9250\n",
      "Epoch 117/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2543 - acc: 0.9197\n",
      "Epoch 118/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2425 - acc: 0.9187\n",
      "Epoch 119/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2506 - acc: 0.9230\n",
      "Epoch 120/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2369 - acc: 0.9203\n",
      "Epoch 121/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2403 - acc: 0.9230\n",
      "Epoch 122/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2372 - acc: 0.9244\n",
      "Epoch 123/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2634 - acc: 0.9244\n",
      "Epoch 124/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2836 - acc: 0.9254\n",
      "Epoch 125/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2430 - acc: 0.9277\n",
      "Epoch 126/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2448 - acc: 0.9244\n",
      "Epoch 127/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2535 - acc: 0.9224\n",
      "Epoch 128/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2427 - acc: 0.9213\n",
      "Epoch 129/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2484 - acc: 0.9271\n",
      "Epoch 130/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2456 - acc: 0.9240\n",
      "Epoch 131/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2314 - acc: 0.9281\n",
      "Epoch 132/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2359 - acc: 0.9291\n",
      "Epoch 133/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2262 - acc: 0.9230\n",
      "Epoch 134/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2328 - acc: 0.9261\n",
      "Epoch 135/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2505 - acc: 0.9230\n",
      "Epoch 136/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2550 - acc: 0.9207\n",
      "Epoch 137/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2327 - acc: 0.9261\n",
      "Epoch 138/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2369 - acc: 0.9281\n",
      "Epoch 139/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2467 - acc: 0.9237\n",
      "Epoch 140/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2370 - acc: 0.9277\n",
      "Epoch 141/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2417 - acc: 0.9200\n",
      "Epoch 142/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2292 - acc: 0.9267\n",
      "Epoch 143/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2332 - acc: 0.9227\n",
      "Epoch 144/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2334 - acc: 0.9304\n",
      "Epoch 145/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2379 - acc: 0.9240\n",
      "Epoch 146/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2421 - acc: 0.9264\n",
      "Epoch 147/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2310 - acc: 0.9281\n",
      "Epoch 148/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2352 - acc: 0.9224\n",
      "Epoch 149/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2251 - acc: 0.9294\n",
      "Epoch 150/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2452 - acc: 0.9264\n",
      "Epoch 151/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2342 - acc: 0.9240\n",
      "Epoch 152/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2529 - acc: 0.9210\n",
      "Epoch 153/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2403 - acc: 0.9264\n",
      "Epoch 154/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2311 - acc: 0.9287\n",
      "Epoch 155/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2372 - acc: 0.9237\n",
      "Epoch 156/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2278 - acc: 0.9294\n",
      "Epoch 157/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2586 - acc: 0.9267\n",
      "Epoch 158/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2248 - acc: 0.9287\n",
      "Epoch 159/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2252 - acc: 0.9267\n",
      "Epoch 160/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2225 - acc: 0.9338\n",
      "Epoch 161/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2308 - acc: 0.9301\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2380 - acc: 0.9244\n",
      "Epoch 163/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2267 - acc: 0.9297\n",
      "Epoch 164/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2392 - acc: 0.9281\n",
      "Epoch 165/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2293 - acc: 0.9321\n",
      "Epoch 166/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2285 - acc: 0.9264\n",
      "Epoch 167/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2223 - acc: 0.9281\n",
      "Epoch 168/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2340 - acc: 0.9304\n",
      "Epoch 169/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2476 - acc: 0.9304\n",
      "Epoch 170/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2216 - acc: 0.9334\n",
      "Epoch 171/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2361 - acc: 0.9264\n",
      "Epoch 172/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2214 - acc: 0.9355\n",
      "Epoch 173/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2277 - acc: 0.9274\n",
      "Epoch 174/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2110 - acc: 0.9318\n",
      "Epoch 175/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2302 - acc: 0.9240\n",
      "Epoch 176/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2126 - acc: 0.9324\n",
      "Epoch 177/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.2272 - acc: 0.9297\n",
      "Epoch 178/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2393 - acc: 0.9297\n",
      "Epoch 179/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2252 - acc: 0.9304\n",
      "Epoch 180/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2283 - acc: 0.9297\n",
      "Epoch 181/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2205 - acc: 0.9314\n",
      "Epoch 182/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2372 - acc: 0.9207\n",
      "Epoch 183/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2274 - acc: 0.9334\n",
      "Epoch 184/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2140 - acc: 0.9331\n",
      "Epoch 185/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2245 - acc: 0.9324\n",
      "Epoch 186/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2193 - acc: 0.9308\n",
      "Epoch 187/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2164 - acc: 0.9328\n",
      "Epoch 188/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2322 - acc: 0.9284\n",
      "Epoch 189/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2179 - acc: 0.9311\n",
      "Epoch 190/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2259 - acc: 0.9301\n",
      "Epoch 191/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2037 - acc: 0.9358\n",
      "Epoch 192/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2290 - acc: 0.9277\n",
      "Epoch 193/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2254 - acc: 0.9311\n",
      "Epoch 194/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2192 - acc: 0.9348\n",
      "Epoch 195/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2325 - acc: 0.9281\n",
      "Epoch 196/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2331 - acc: 0.9297\n",
      "Epoch 197/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2253 - acc: 0.9321\n",
      "Epoch 198/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2234 - acc: 0.9304\n",
      "Epoch 199/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2245 - acc: 0.9334\n",
      "Epoch 200/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2152 - acc: 0.9311\n",
      "Epoch 201/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2401 - acc: 0.9234\n",
      "Epoch 202/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2261 - acc: 0.9301\n",
      "Epoch 203/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2340 - acc: 0.9334\n",
      "Epoch 204/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2236 - acc: 0.9311\n",
      "Epoch 205/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2116 - acc: 0.9348\n",
      "Epoch 206/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2165 - acc: 0.9281\n",
      "Epoch 207/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2268 - acc: 0.9250\n",
      "Epoch 208/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2136 - acc: 0.9338\n",
      "Epoch 209/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2163 - acc: 0.9324\n",
      "Epoch 210/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2057 - acc: 0.9338\n",
      "Epoch 211/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2254 - acc: 0.9271\n",
      "Epoch 212/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2057 - acc: 0.9308\n",
      "Epoch 213/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2069 - acc: 0.9368\n",
      "Epoch 214/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2330 - acc: 0.9274\n",
      "Epoch 215/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2123 - acc: 0.9365\n",
      "Epoch 216/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2197 - acc: 0.9331\n",
      "Epoch 217/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2270 - acc: 0.9271\n",
      "Epoch 218/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2130 - acc: 0.9345\n",
      "Epoch 219/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2084 - acc: 0.9318\n",
      "Epoch 220/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2408 - acc: 0.9331\n",
      "Epoch 221/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2208 - acc: 0.9304\n",
      "Epoch 222/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2208 - acc: 0.9338\n",
      "Epoch 223/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2237 - acc: 0.9314\n",
      "Epoch 224/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2211 - acc: 0.9287\n",
      "Epoch 225/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2241 - acc: 0.9345\n",
      "Epoch 226/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2233 - acc: 0.9371\n",
      "Epoch 227/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2037 - acc: 0.9355\n",
      "Epoch 228/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2119 - acc: 0.9348\n",
      "Epoch 229/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2302 - acc: 0.9267\n",
      "Epoch 230/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2218 - acc: 0.9304\n",
      "Epoch 231/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2257 - acc: 0.9281\n",
      "Epoch 232/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2163 - acc: 0.9308\n",
      "Epoch 233/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2184 - acc: 0.9328\n",
      "Epoch 234/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2167 - acc: 0.9358\n",
      "Epoch 235/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2287 - acc: 0.9281\n",
      "Epoch 236/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2171 - acc: 0.9365\n",
      "Epoch 237/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2190 - acc: 0.9291\n",
      "Epoch 238/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2172 - acc: 0.9341\n",
      "Epoch 239/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2216 - acc: 0.9304\n",
      "Epoch 240/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2119 - acc: 0.9345\n",
      "Epoch 241/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2048 - acc: 0.9341\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2176 - acc: 0.9365\n",
      "Epoch 243/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2207 - acc: 0.9314\n",
      "Epoch 244/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2014 - acc: 0.9321\n",
      "Epoch 245/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2275 - acc: 0.9355\n",
      "Epoch 246/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2315 - acc: 0.9351\n",
      "Epoch 247/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2150 - acc: 0.9361\n",
      "Epoch 248/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2307 - acc: 0.9294\n",
      "Epoch 249/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2185 - acc: 0.9351\n",
      "Epoch 250/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2200 - acc: 0.9291\n",
      "Epoch 251/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2112 - acc: 0.9348\n",
      "Epoch 252/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2205 - acc: 0.9331\n",
      "Epoch 253/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2074 - acc: 0.9324\n",
      "Epoch 254/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2175 - acc: 0.9338\n",
      "Epoch 255/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2131 - acc: 0.9321\n",
      "Epoch 256/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2075 - acc: 0.9338\n",
      "Epoch 257/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2106 - acc: 0.9331\n",
      "Epoch 258/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2127 - acc: 0.9338\n",
      "Epoch 259/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2111 - acc: 0.9308\n",
      "Epoch 260/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2268 - acc: 0.9318\n",
      "Epoch 261/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2077 - acc: 0.9351\n",
      "Epoch 262/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2213 - acc: 0.9314\n",
      "Epoch 263/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2162 - acc: 0.9334\n",
      "Epoch 264/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2067 - acc: 0.9351\n",
      "Epoch 265/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2128 - acc: 0.9304\n",
      "Epoch 266/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2160 - acc: 0.9324\n",
      "Epoch 267/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2050 - acc: 0.9361\n",
      "Epoch 268/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2239 - acc: 0.9311\n",
      "Epoch 269/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2315 - acc: 0.9247\n",
      "Epoch 270/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2094 - acc: 0.9382\n",
      "Epoch 271/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2109 - acc: 0.9345\n",
      "Epoch 272/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2038 - acc: 0.9311\n",
      "Epoch 273/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2044 - acc: 0.9341\n",
      "Epoch 274/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2124 - acc: 0.9382\n",
      "Epoch 275/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2255 - acc: 0.9314\n",
      "Epoch 276/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2029 - acc: 0.9338\n",
      "Epoch 277/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2028 - acc: 0.9345\n",
      "Epoch 278/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2396 - acc: 0.9345\n",
      "Epoch 279/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2447 - acc: 0.9324\n",
      "Epoch 280/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2187 - acc: 0.9311\n",
      "Epoch 281/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2041 - acc: 0.9348\n",
      "Epoch 282/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2106 - acc: 0.9378\n",
      "Epoch 283/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2169 - acc: 0.9308\n",
      "Epoch 284/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2125 - acc: 0.9361\n",
      "Epoch 285/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2201 - acc: 0.9324\n",
      "Epoch 286/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2010 - acc: 0.9345\n",
      "Epoch 287/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2070 - acc: 0.9388\n",
      "Epoch 288/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2209 - acc: 0.9287\n",
      "Epoch 289/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2133 - acc: 0.9328\n",
      "Epoch 290/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2234 - acc: 0.9334\n",
      "Epoch 291/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2108 - acc: 0.9385\n",
      "Epoch 292/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2110 - acc: 0.9408\n",
      "Epoch 293/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2149 - acc: 0.9361\n",
      "Epoch 294/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2165 - acc: 0.9334\n",
      "Epoch 295/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2144 - acc: 0.9371\n",
      "Epoch 296/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1997 - acc: 0.9378\n",
      "Epoch 297/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2099 - acc: 0.9297\n",
      "Epoch 298/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2093 - acc: 0.9341\n",
      "Epoch 299/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2199 - acc: 0.9328\n",
      "Epoch 300/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2087 - acc: 0.9348\n",
      "Epoch 301/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2217 - acc: 0.9297\n",
      "Epoch 302/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2390 - acc: 0.9254\n",
      "Epoch 303/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2028 - acc: 0.9351\n",
      "Epoch 304/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2076 - acc: 0.9351\n",
      "Epoch 305/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2090 - acc: 0.9351\n",
      "Epoch 306/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2097 - acc: 0.9341\n",
      "Epoch 307/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2040 - acc: 0.9355\n",
      "Epoch 308/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2085 - acc: 0.9375\n",
      "Epoch 309/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2232 - acc: 0.9328\n",
      "Epoch 310/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2143 - acc: 0.9385\n",
      "Epoch 311/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2044 - acc: 0.9351\n",
      "Epoch 312/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2144 - acc: 0.9324\n",
      "Epoch 313/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2028 - acc: 0.9358\n",
      "Epoch 314/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1998 - acc: 0.9361\n",
      "Epoch 315/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2179 - acc: 0.9301\n",
      "Epoch 316/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1955 - acc: 0.9392\n",
      "Epoch 317/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1960 - acc: 0.9395\n",
      "Epoch 318/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2045 - acc: 0.9324\n",
      "Epoch 319/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1997 - acc: 0.9385\n",
      "Epoch 320/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1960 - acc: 0.9388\n",
      "Epoch 321/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2181 - acc: 0.9375\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2140 - acc: 0.9338\n",
      "Epoch 323/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2021 - acc: 0.9311\n",
      "Epoch 324/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2048 - acc: 0.9355\n",
      "Epoch 325/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1908 - acc: 0.9368\n",
      "Epoch 326/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2262 - acc: 0.9331\n",
      "Epoch 327/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2008 - acc: 0.9371\n",
      "Epoch 328/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2081 - acc: 0.9361\n",
      "Epoch 329/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1963 - acc: 0.9355\n",
      "Epoch 330/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2127 - acc: 0.9334\n",
      "Epoch 331/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1972 - acc: 0.9402\n",
      "Epoch 332/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2005 - acc: 0.9375\n",
      "Epoch 333/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2153 - acc: 0.9378\n",
      "Epoch 334/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1959 - acc: 0.9408\n",
      "Epoch 335/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1925 - acc: 0.9392\n",
      "Epoch 336/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2288 - acc: 0.9341\n",
      "Epoch 337/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1954 - acc: 0.9371\n",
      "Epoch 338/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1968 - acc: 0.9368\n",
      "Epoch 339/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2118 - acc: 0.9361\n",
      "Epoch 340/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2002 - acc: 0.9398\n",
      "Epoch 341/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1972 - acc: 0.9405\n",
      "Epoch 342/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2129 - acc: 0.9338\n",
      "Epoch 343/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1977 - acc: 0.9402\n",
      "Epoch 344/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2071 - acc: 0.9405\n",
      "Epoch 345/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2076 - acc: 0.9398\n",
      "Epoch 346/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2104 - acc: 0.9324\n",
      "Epoch 347/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2055 - acc: 0.9318\n",
      "Epoch 348/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1997 - acc: 0.9321\n",
      "Epoch 349/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2118 - acc: 0.9311\n",
      "Epoch 350/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1984 - acc: 0.9392\n",
      "Epoch 351/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2125 - acc: 0.9361\n",
      "Epoch 352/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2088 - acc: 0.9365\n",
      "Epoch 353/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2051 - acc: 0.9321\n",
      "Epoch 354/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1938 - acc: 0.9375\n",
      "Epoch 355/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2236 - acc: 0.9324\n",
      "Epoch 356/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2162 - acc: 0.9304\n",
      "Epoch 357/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2057 - acc: 0.9351\n",
      "Epoch 358/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2163 - acc: 0.9318\n",
      "Epoch 359/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1973 - acc: 0.9361\n",
      "Epoch 360/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1971 - acc: 0.9341\n",
      "Epoch 361/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2076 - acc: 0.9382\n",
      "Epoch 362/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2069 - acc: 0.9371\n",
      "Epoch 363/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1982 - acc: 0.9402\n",
      "Epoch 364/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1909 - acc: 0.9412\n",
      "Epoch 365/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2056 - acc: 0.9375\n",
      "Epoch 366/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1987 - acc: 0.9334\n",
      "Epoch 367/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2146 - acc: 0.9375\n",
      "Epoch 368/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2075 - acc: 0.9392\n",
      "Epoch 369/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2011 - acc: 0.9395\n",
      "Epoch 370/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2082 - acc: 0.9328\n",
      "Epoch 371/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2019 - acc: 0.9439\n",
      "Epoch 372/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2088 - acc: 0.9324\n",
      "Epoch 373/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1988 - acc: 0.9388\n",
      "Epoch 374/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2053 - acc: 0.9392\n",
      "Epoch 375/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2105 - acc: 0.9385\n",
      "Epoch 376/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2082 - acc: 0.9348\n",
      "Epoch 377/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2016 - acc: 0.9402\n",
      "Epoch 378/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2064 - acc: 0.9318\n",
      "Epoch 379/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2061 - acc: 0.9382\n",
      "Epoch 380/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1917 - acc: 0.9365\n",
      "Epoch 381/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2129 - acc: 0.9334\n",
      "Epoch 382/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1936 - acc: 0.9385\n",
      "Epoch 383/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2003 - acc: 0.9418\n",
      "Epoch 384/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2046 - acc: 0.9375\n",
      "Epoch 385/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1988 - acc: 0.9365\n",
      "Epoch 386/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2130 - acc: 0.9345\n",
      "Epoch 387/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2116 - acc: 0.9382\n",
      "Epoch 388/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1967 - acc: 0.9291\n",
      "Epoch 389/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2140 - acc: 0.9348\n",
      "Epoch 390/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1919 - acc: 0.9392\n",
      "Epoch 391/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2175 - acc: 0.9395\n",
      "Epoch 392/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1928 - acc: 0.9378\n",
      "Epoch 393/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2100 - acc: 0.9358\n",
      "Epoch 394/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2146 - acc: 0.9378\n",
      "Epoch 395/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2128 - acc: 0.9328\n",
      "Epoch 396/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2156 - acc: 0.9361\n",
      "Epoch 397/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2144 - acc: 0.9311\n",
      "Epoch 398/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2241 - acc: 0.9324\n",
      "Epoch 399/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2003 - acc: 0.9398\n",
      "Epoch 400/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2034 - acc: 0.9355\n",
      "Epoch 401/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1978 - acc: 0.9398\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1971 - acc: 0.9382\n",
      "Epoch 403/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2015 - acc: 0.9334\n",
      "Epoch 404/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1962 - acc: 0.9358\n",
      "Epoch 405/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1818 - acc: 0.9445\n",
      "Epoch 406/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1951 - acc: 0.9418\n",
      "Epoch 407/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1957 - acc: 0.9392\n",
      "Epoch 408/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2003 - acc: 0.9392\n",
      "Epoch 409/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1981 - acc: 0.9371\n",
      "Epoch 410/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2130 - acc: 0.9341\n",
      "Epoch 411/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2144 - acc: 0.9388\n",
      "Epoch 412/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2209 - acc: 0.9331\n",
      "Epoch 413/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2087 - acc: 0.9348\n",
      "Epoch 414/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2065 - acc: 0.9351\n",
      "Epoch 415/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1934 - acc: 0.9412\n",
      "Epoch 416/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1984 - acc: 0.9415\n",
      "Epoch 417/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2002 - acc: 0.9405\n",
      "Epoch 418/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2283 - acc: 0.9388\n",
      "Epoch 419/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2263 - acc: 0.9415\n",
      "Epoch 420/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1935 - acc: 0.9412\n",
      "Epoch 421/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2094 - acc: 0.9368\n",
      "Epoch 422/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2122 - acc: 0.9368\n",
      "Epoch 423/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2094 - acc: 0.9361\n",
      "Epoch 424/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2004 - acc: 0.9365\n",
      "Epoch 425/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1978 - acc: 0.9368\n",
      "Epoch 426/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1973 - acc: 0.9371\n",
      "Epoch 427/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1974 - acc: 0.9392\n",
      "Epoch 428/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2152 - acc: 0.9321\n",
      "Epoch 429/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1962 - acc: 0.9408\n",
      "Epoch 430/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1938 - acc: 0.9361\n",
      "Epoch 431/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2035 - acc: 0.9368\n",
      "Epoch 432/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2028 - acc: 0.9425\n",
      "Epoch 433/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2033 - acc: 0.9402\n",
      "Epoch 434/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2180 - acc: 0.9358\n",
      "Epoch 435/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2066 - acc: 0.9324\n",
      "Epoch 436/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2202 - acc: 0.9341\n",
      "Epoch 437/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1978 - acc: 0.9378\n",
      "Epoch 438/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1993 - acc: 0.9348\n",
      "Epoch 439/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1950 - acc: 0.9382\n",
      "Epoch 440/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1898 - acc: 0.9398\n",
      "Epoch 441/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2100 - acc: 0.9348\n",
      "Epoch 442/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2141 - acc: 0.9415\n",
      "Epoch 443/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1964 - acc: 0.9341\n",
      "Epoch 444/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2018 - acc: 0.9365\n",
      "Epoch 445/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2152 - acc: 0.9338\n",
      "Epoch 446/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2131 - acc: 0.9331\n",
      "Epoch 447/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2102 - acc: 0.9371\n",
      "Epoch 448/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2024 - acc: 0.9368\n",
      "Epoch 449/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2133 - acc: 0.9324\n",
      "Epoch 450/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1967 - acc: 0.9388\n",
      "Epoch 451/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1931 - acc: 0.9395\n",
      "Epoch 452/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2168 - acc: 0.9378\n",
      "Epoch 453/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2128 - acc: 0.9334\n",
      "Epoch 454/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2101 - acc: 0.9368\n",
      "Epoch 455/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1973 - acc: 0.9341\n",
      "Epoch 456/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1963 - acc: 0.9395\n",
      "Epoch 457/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2059 - acc: 0.9321\n",
      "Epoch 458/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2065 - acc: 0.9392\n",
      "Epoch 459/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1963 - acc: 0.9348\n",
      "Epoch 460/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2019 - acc: 0.9392\n",
      "Epoch 461/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1940 - acc: 0.9351\n",
      "Epoch 462/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1979 - acc: 0.9371\n",
      "Epoch 463/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1951 - acc: 0.9345\n",
      "Epoch 464/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1930 - acc: 0.9358\n",
      "Epoch 465/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2181 - acc: 0.9388\n",
      "Epoch 466/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1890 - acc: 0.9415\n",
      "Epoch 467/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1929 - acc: 0.9392\n",
      "Epoch 468/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1878 - acc: 0.9365\n",
      "Epoch 469/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2104 - acc: 0.9415\n",
      "Epoch 470/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1993 - acc: 0.9348\n",
      "Epoch 471/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2113 - acc: 0.9385\n",
      "Epoch 472/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2040 - acc: 0.9368\n",
      "Epoch 473/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1919 - acc: 0.9388\n",
      "Epoch 474/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2107 - acc: 0.9388\n",
      "Epoch 475/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1912 - acc: 0.9351\n",
      "Epoch 476/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2045 - acc: 0.9345\n",
      "Epoch 477/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2047 - acc: 0.9334\n",
      "Epoch 478/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1976 - acc: 0.9371\n",
      "Epoch 479/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1999 - acc: 0.9385\n",
      "Epoch 480/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2065 - acc: 0.9398\n",
      "Epoch 481/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1925 - acc: 0.9408\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2205 - acc: 0.9338\n",
      "Epoch 483/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1936 - acc: 0.9398\n",
      "Epoch 484/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1874 - acc: 0.9425\n",
      "Epoch 485/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1993 - acc: 0.9345\n",
      "Epoch 486/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1932 - acc: 0.9455\n",
      "Epoch 487/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2035 - acc: 0.9308\n",
      "Epoch 488/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2019 - acc: 0.9361\n",
      "Epoch 489/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1952 - acc: 0.9368\n",
      "Epoch 490/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2015 - acc: 0.9345\n",
      "Epoch 491/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1934 - acc: 0.9368\n",
      "Epoch 492/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2079 - acc: 0.9405\n",
      "Epoch 493/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2064 - acc: 0.9324\n",
      "Epoch 494/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2023 - acc: 0.9368\n",
      "Epoch 495/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1967 - acc: 0.9378\n",
      "Epoch 496/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1919 - acc: 0.9388\n",
      "Epoch 497/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2026 - acc: 0.9338\n",
      "Epoch 498/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2014 - acc: 0.9348\n",
      "Epoch 499/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2119 - acc: 0.9378\n",
      "Epoch 500/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2291 - acc: 0.9328\n",
      "Epoch 501/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1861 - acc: 0.9422\n",
      "Epoch 502/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2108 - acc: 0.9408\n",
      "Epoch 503/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1858 - acc: 0.9402\n",
      "Epoch 504/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1990 - acc: 0.9375\n",
      "Epoch 505/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1975 - acc: 0.9388\n",
      "Epoch 506/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1905 - acc: 0.9402\n",
      "Epoch 507/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2410 - acc: 0.9345\n",
      "Epoch 508/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1841 - acc: 0.9395\n",
      "Epoch 509/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2004 - acc: 0.9351\n",
      "Epoch 510/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2102 - acc: 0.9378\n",
      "Epoch 511/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1901 - acc: 0.9358\n",
      "Epoch 512/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1890 - acc: 0.9355\n",
      "Epoch 513/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2101 - acc: 0.9382\n",
      "Epoch 514/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2129 - acc: 0.9368\n",
      "Epoch 515/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1977 - acc: 0.9385\n",
      "Epoch 516/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1811 - acc: 0.9429\n",
      "Epoch 517/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2065 - acc: 0.9412\n",
      "Epoch 518/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2236 - acc: 0.9341\n",
      "Epoch 519/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1929 - acc: 0.9392\n",
      "Epoch 520/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1936 - acc: 0.9348\n",
      "Epoch 521/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1870 - acc: 0.9439\n",
      "Epoch 522/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1817 - acc: 0.9388\n",
      "Epoch 523/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1973 - acc: 0.9371\n",
      "Epoch 524/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2002 - acc: 0.9398\n",
      "Epoch 525/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1961 - acc: 0.9368\n",
      "Epoch 526/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2158 - acc: 0.9331\n",
      "Epoch 527/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2046 - acc: 0.9314\n",
      "Epoch 528/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1837 - acc: 0.9395\n",
      "Epoch 529/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1886 - acc: 0.9382\n",
      "Epoch 530/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1868 - acc: 0.9408\n",
      "Epoch 531/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2013 - acc: 0.9439\n",
      "Epoch 532/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1943 - acc: 0.9392\n",
      "Epoch 533/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1885 - acc: 0.9385\n",
      "Epoch 534/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2113 - acc: 0.9334\n",
      "Epoch 535/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2019 - acc: 0.9398\n",
      "Epoch 536/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1912 - acc: 0.9388\n",
      "Epoch 537/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1903 - acc: 0.9449\n",
      "Epoch 538/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1872 - acc: 0.9402\n",
      "Epoch 539/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.2269 - acc: 0.9358\n",
      "Epoch 540/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1929 - acc: 0.9365\n",
      "Epoch 541/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1957 - acc: 0.9368\n",
      "Epoch 542/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1972 - acc: 0.9408\n",
      "Epoch 543/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2076 - acc: 0.9395\n",
      "Epoch 544/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1952 - acc: 0.9479\n",
      "Epoch 545/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1950 - acc: 0.9382\n",
      "Epoch 546/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1949 - acc: 0.9472\n",
      "Epoch 547/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2129 - acc: 0.9402\n",
      "Epoch 548/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2073 - acc: 0.9375\n",
      "Epoch 549/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2008 - acc: 0.9398\n",
      "Epoch 550/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1870 - acc: 0.9418\n",
      "Epoch 551/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1987 - acc: 0.9408\n",
      "Epoch 552/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2088 - acc: 0.9365\n",
      "Epoch 553/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1857 - acc: 0.9412\n",
      "Epoch 554/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1937 - acc: 0.9398\n",
      "Epoch 555/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1910 - acc: 0.9415\n",
      "Epoch 556/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1902 - acc: 0.9388\n",
      "Epoch 557/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1903 - acc: 0.9385\n",
      "Epoch 558/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2068 - acc: 0.9378\n",
      "Epoch 559/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1985 - acc: 0.9375\n",
      "Epoch 560/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2005 - acc: 0.9324\n",
      "Epoch 561/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1946 - acc: 0.9408\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2381 - acc: 0.9412\n",
      "Epoch 563/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2004 - acc: 0.9328\n",
      "Epoch 564/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1760 - acc: 0.9405\n",
      "Epoch 565/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2157 - acc: 0.9385\n",
      "Epoch 566/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1780 - acc: 0.9435\n",
      "Epoch 567/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2015 - acc: 0.9334\n",
      "Epoch 568/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1824 - acc: 0.9398\n",
      "Epoch 569/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1893 - acc: 0.9412\n",
      "Epoch 570/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1972 - acc: 0.9375\n",
      "Epoch 571/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1908 - acc: 0.9382\n",
      "Epoch 572/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1984 - acc: 0.9385\n",
      "Epoch 573/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1930 - acc: 0.9422\n",
      "Epoch 574/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1889 - acc: 0.9412\n",
      "Epoch 575/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2023 - acc: 0.9408\n",
      "Epoch 576/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1963 - acc: 0.9378\n",
      "Epoch 577/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2116 - acc: 0.9382\n",
      "Epoch 578/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1930 - acc: 0.9358\n",
      "Epoch 579/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2008 - acc: 0.9402\n",
      "Epoch 580/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1930 - acc: 0.9378\n",
      "Epoch 581/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1943 - acc: 0.9382\n",
      "Epoch 582/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1969 - acc: 0.9412\n",
      "Epoch 583/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1953 - acc: 0.9361\n",
      "Epoch 584/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1933 - acc: 0.9358\n",
      "Epoch 585/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2103 - acc: 0.9382\n",
      "Epoch 586/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2040 - acc: 0.9368\n",
      "Epoch 587/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2007 - acc: 0.9371\n",
      "Epoch 588/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2021 - acc: 0.9361\n",
      "Epoch 589/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1825 - acc: 0.9422\n",
      "Epoch 590/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2025 - acc: 0.9355\n",
      "Epoch 591/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1929 - acc: 0.9398\n",
      "Epoch 592/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2167 - acc: 0.9395\n",
      "Epoch 593/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1886 - acc: 0.9358\n",
      "Epoch 594/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1955 - acc: 0.9371\n",
      "Epoch 595/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2039 - acc: 0.9338\n",
      "Epoch 596/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2084 - acc: 0.9341\n",
      "Epoch 597/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1837 - acc: 0.9405\n",
      "Epoch 598/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2130 - acc: 0.9385\n",
      "Epoch 599/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2031 - acc: 0.9368\n",
      "Epoch 600/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2056 - acc: 0.9405\n",
      "Epoch 601/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1845 - acc: 0.9375\n",
      "Epoch 602/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2020 - acc: 0.9375\n",
      "Epoch 603/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1815 - acc: 0.9472\n",
      "Epoch 604/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1870 - acc: 0.9398\n",
      "Epoch 605/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1885 - acc: 0.9395\n",
      "Epoch 606/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1825 - acc: 0.9445\n",
      "Epoch 607/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2079 - acc: 0.9429\n",
      "Epoch 608/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1947 - acc: 0.9398\n",
      "Epoch 609/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1870 - acc: 0.9365\n",
      "Epoch 610/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1993 - acc: 0.9432\n",
      "Epoch 611/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2077 - acc: 0.9398\n",
      "Epoch 612/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1715 - acc: 0.9388\n",
      "Epoch 613/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1927 - acc: 0.9395\n",
      "Epoch 614/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1857 - acc: 0.9358\n",
      "Epoch 615/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1890 - acc: 0.9449\n",
      "Epoch 616/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1885 - acc: 0.9392\n",
      "Epoch 617/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1889 - acc: 0.9402\n",
      "Epoch 618/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1862 - acc: 0.9415\n",
      "Epoch 619/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1879 - acc: 0.9429\n",
      "Epoch 620/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2000 - acc: 0.9361\n",
      "Epoch 621/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1819 - acc: 0.9405\n",
      "Epoch 622/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2056 - acc: 0.9425\n",
      "Epoch 623/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1929 - acc: 0.9365\n",
      "Epoch 624/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1921 - acc: 0.9395\n",
      "Epoch 625/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1935 - acc: 0.9392\n",
      "Epoch 626/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2018 - acc: 0.9365\n",
      "Epoch 627/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1861 - acc: 0.9398\n",
      "Epoch 628/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1778 - acc: 0.9429\n",
      "Epoch 629/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2006 - acc: 0.9395\n",
      "Epoch 630/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1901 - acc: 0.9398\n",
      "Epoch 631/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1950 - acc: 0.9398\n",
      "Epoch 632/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1857 - acc: 0.9439\n",
      "Epoch 633/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1854 - acc: 0.9408\n",
      "Epoch 634/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1921 - acc: 0.9378\n",
      "Epoch 635/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1881 - acc: 0.9392\n",
      "Epoch 636/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1728 - acc: 0.9442\n",
      "Epoch 637/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1924 - acc: 0.9408\n",
      "Epoch 638/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1857 - acc: 0.9385\n",
      "Epoch 639/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1784 - acc: 0.9425\n",
      "Epoch 640/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1845 - acc: 0.9429\n",
      "Epoch 641/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1840 - acc: 0.9415\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1829 - acc: 0.9408\n",
      "Epoch 643/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1996 - acc: 0.9375\n",
      "Epoch 644/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1879 - acc: 0.9442\n",
      "Epoch 645/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1830 - acc: 0.9398\n",
      "Epoch 646/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2031 - acc: 0.9365\n",
      "Epoch 647/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1793 - acc: 0.9435\n",
      "Epoch 648/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1774 - acc: 0.9395\n",
      "Epoch 649/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1827 - acc: 0.9392\n",
      "Epoch 650/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1753 - acc: 0.9449\n",
      "Epoch 651/1000\n",
      "2975/2975 [==============================] - 0s 66us/step - loss: 0.1823 - acc: 0.9361\n",
      "Epoch 652/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1749 - acc: 0.9422\n",
      "Epoch 653/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1773 - acc: 0.9415\n",
      "Epoch 654/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1739 - acc: 0.9392\n",
      "Epoch 655/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1806 - acc: 0.9425\n",
      "Epoch 656/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1868 - acc: 0.9415\n",
      "Epoch 657/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1883 - acc: 0.9412\n",
      "Epoch 658/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1818 - acc: 0.9432\n",
      "Epoch 659/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1762 - acc: 0.9392\n",
      "Epoch 660/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1797 - acc: 0.9459\n",
      "Epoch 661/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1772 - acc: 0.9388\n",
      "Epoch 662/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1781 - acc: 0.9435\n",
      "Epoch 663/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1922 - acc: 0.9378\n",
      "Epoch 664/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1732 - acc: 0.9385\n",
      "Epoch 665/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1734 - acc: 0.9422\n",
      "Epoch 666/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1706 - acc: 0.9472\n",
      "Epoch 667/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1736 - acc: 0.9425\n",
      "Epoch 668/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1761 - acc: 0.9449\n",
      "Epoch 669/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1868 - acc: 0.9412\n",
      "Epoch 670/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1823 - acc: 0.9432\n",
      "Epoch 671/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2079 - acc: 0.9361\n",
      "Epoch 672/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1908 - acc: 0.9402\n",
      "Epoch 673/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1831 - acc: 0.9439\n",
      "Epoch 674/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1751 - acc: 0.9422\n",
      "Epoch 675/1000\n",
      "2975/2975 [==============================] - 0s 62us/step - loss: 0.1851 - acc: 0.9435\n",
      "Epoch 676/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2043 - acc: 0.9355\n",
      "Epoch 677/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1620 - acc: 0.9449\n",
      "Epoch 678/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1984 - acc: 0.9368\n",
      "Epoch 679/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1753 - acc: 0.9425\n",
      "Epoch 680/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1850 - acc: 0.9398\n",
      "Epoch 681/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1841 - acc: 0.9425\n",
      "Epoch 682/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2062 - acc: 0.9408\n",
      "Epoch 683/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1908 - acc: 0.9392\n",
      "Epoch 684/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1895 - acc: 0.9408\n",
      "Epoch 685/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1961 - acc: 0.9365\n",
      "Epoch 686/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1694 - acc: 0.9452\n",
      "Epoch 687/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1910 - acc: 0.9385\n",
      "Epoch 688/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1939 - acc: 0.9412\n",
      "Epoch 689/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1805 - acc: 0.9418\n",
      "Epoch 690/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2081 - acc: 0.9375\n",
      "Epoch 691/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1685 - acc: 0.9506\n",
      "Epoch 692/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1864 - acc: 0.9442\n",
      "Epoch 693/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1822 - acc: 0.9405\n",
      "Epoch 694/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1968 - acc: 0.9442\n",
      "Epoch 695/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1858 - acc: 0.9405\n",
      "Epoch 696/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1865 - acc: 0.9412\n",
      "Epoch 697/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1729 - acc: 0.9415\n",
      "Epoch 698/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1826 - acc: 0.9418\n",
      "Epoch 699/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1797 - acc: 0.9405\n",
      "Epoch 700/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1788 - acc: 0.9442\n",
      "Epoch 701/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1806 - acc: 0.9412\n",
      "Epoch 702/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1758 - acc: 0.9442\n",
      "Epoch 703/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1837 - acc: 0.9466\n",
      "Epoch 704/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1920 - acc: 0.9361\n",
      "Epoch 705/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1748 - acc: 0.9412\n",
      "Epoch 706/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1891 - acc: 0.9422\n",
      "Epoch 707/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1824 - acc: 0.9422\n",
      "Epoch 708/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1705 - acc: 0.9435\n",
      "Epoch 709/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1945 - acc: 0.9398\n",
      "Epoch 710/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1725 - acc: 0.9459\n",
      "Epoch 711/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2047 - acc: 0.9412\n",
      "Epoch 712/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1925 - acc: 0.9351\n",
      "Epoch 713/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1786 - acc: 0.9422\n",
      "Epoch 714/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1846 - acc: 0.9452\n",
      "Epoch 715/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1722 - acc: 0.9425\n",
      "Epoch 716/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1876 - acc: 0.9412\n",
      "Epoch 717/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1736 - acc: 0.9452\n",
      "Epoch 718/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1792 - acc: 0.9449\n",
      "Epoch 719/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1676 - acc: 0.9462\n",
      "Epoch 720/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2036 - acc: 0.9341\n",
      "Epoch 721/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1893 - acc: 0.9466\n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1833 - acc: 0.9429\n",
      "Epoch 723/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1800 - acc: 0.9432\n",
      "Epoch 724/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1722 - acc: 0.9422\n",
      "Epoch 725/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1799 - acc: 0.9445\n",
      "Epoch 726/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2013 - acc: 0.9402\n",
      "Epoch 727/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1825 - acc: 0.9439\n",
      "Epoch 728/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1718 - acc: 0.9439\n",
      "Epoch 729/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1686 - acc: 0.9418\n",
      "Epoch 730/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1804 - acc: 0.9452\n",
      "Epoch 731/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1959 - acc: 0.9435\n",
      "Epoch 732/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1792 - acc: 0.9439\n",
      "Epoch 733/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1818 - acc: 0.9439\n",
      "Epoch 734/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1877 - acc: 0.9365\n",
      "Epoch 735/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1820 - acc: 0.9455\n",
      "Epoch 736/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1922 - acc: 0.9378\n",
      "Epoch 737/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1737 - acc: 0.9405\n",
      "Epoch 738/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1932 - acc: 0.9358\n",
      "Epoch 739/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1618 - acc: 0.9442\n",
      "Epoch 740/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1840 - acc: 0.9439\n",
      "Epoch 741/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1696 - acc: 0.9476\n",
      "Epoch 742/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1600 - acc: 0.9486\n",
      "Epoch 743/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1803 - acc: 0.9435\n",
      "Epoch 744/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1588 - acc: 0.9472\n",
      "Epoch 745/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1779 - acc: 0.9412\n",
      "Epoch 746/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1825 - acc: 0.9452\n",
      "Epoch 747/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1695 - acc: 0.9452\n",
      "Epoch 748/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1770 - acc: 0.9395\n",
      "Epoch 749/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1904 - acc: 0.9408\n",
      "Epoch 750/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1803 - acc: 0.9415\n",
      "Epoch 751/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1761 - acc: 0.9445\n",
      "Epoch 752/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1876 - acc: 0.9405\n",
      "Epoch 753/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1925 - acc: 0.9395\n",
      "Epoch 754/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1983 - acc: 0.9398\n",
      "Epoch 755/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1808 - acc: 0.9378\n",
      "Epoch 756/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1845 - acc: 0.9412\n",
      "Epoch 757/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1877 - acc: 0.9432\n",
      "Epoch 758/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1942 - acc: 0.9382\n",
      "Epoch 759/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1749 - acc: 0.9449\n",
      "Epoch 760/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1806 - acc: 0.9398\n",
      "Epoch 761/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1905 - acc: 0.9479\n",
      "Epoch 762/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1875 - acc: 0.9405\n",
      "Epoch 763/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2003 - acc: 0.9402\n",
      "Epoch 764/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1778 - acc: 0.9425\n",
      "Epoch 765/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1893 - acc: 0.9382\n",
      "Epoch 766/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1779 - acc: 0.9408\n",
      "Epoch 767/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1859 - acc: 0.9422\n",
      "Epoch 768/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1966 - acc: 0.9385\n",
      "Epoch 769/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1768 - acc: 0.9439\n",
      "Epoch 770/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1835 - acc: 0.9439\n",
      "Epoch 771/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1841 - acc: 0.9385\n",
      "Epoch 772/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1724 - acc: 0.9408\n",
      "Epoch 773/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1852 - acc: 0.9462\n",
      "Epoch 774/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1777 - acc: 0.9442\n",
      "Epoch 775/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1833 - acc: 0.9412\n",
      "Epoch 776/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1763 - acc: 0.9442\n",
      "Epoch 777/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1804 - acc: 0.9449\n",
      "Epoch 778/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1874 - acc: 0.9469\n",
      "Epoch 779/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2005 - acc: 0.9395\n",
      "Epoch 780/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1818 - acc: 0.9455\n",
      "Epoch 781/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1793 - acc: 0.9432\n",
      "Epoch 782/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1815 - acc: 0.9445\n",
      "Epoch 783/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1960 - acc: 0.9418\n",
      "Epoch 784/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1909 - acc: 0.9439\n",
      "Epoch 785/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1783 - acc: 0.9466\n",
      "Epoch 786/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1848 - acc: 0.9398\n",
      "Epoch 787/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1649 - acc: 0.9469\n",
      "Epoch 788/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1787 - acc: 0.9385\n",
      "Epoch 789/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1991 - acc: 0.9368\n",
      "Epoch 790/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1834 - acc: 0.9398\n",
      "Epoch 791/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1666 - acc: 0.9482\n",
      "Epoch 792/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1704 - acc: 0.9425\n",
      "Epoch 793/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1922 - acc: 0.9415\n",
      "Epoch 794/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1654 - acc: 0.9408\n",
      "Epoch 795/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1836 - acc: 0.9412\n",
      "Epoch 796/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1948 - acc: 0.9455\n",
      "Epoch 797/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1927 - acc: 0.9435\n",
      "Epoch 798/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1805 - acc: 0.9412\n",
      "Epoch 799/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1910 - acc: 0.9415\n",
      "Epoch 800/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1834 - acc: 0.9402\n",
      "Epoch 801/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1675 - acc: 0.9499\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1903 - acc: 0.9402\n",
      "Epoch 803/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1918 - acc: 0.9439\n",
      "Epoch 804/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1639 - acc: 0.9496\n",
      "Epoch 805/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1677 - acc: 0.9429\n",
      "Epoch 806/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1839 - acc: 0.9445\n",
      "Epoch 807/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1833 - acc: 0.9439\n",
      "Epoch 808/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1587 - acc: 0.9449\n",
      "Epoch 809/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1907 - acc: 0.9398\n",
      "Epoch 810/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1730 - acc: 0.9452\n",
      "Epoch 811/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1822 - acc: 0.9412\n",
      "Epoch 812/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1804 - acc: 0.9412\n",
      "Epoch 813/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1876 - acc: 0.9375\n",
      "Epoch 814/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1780 - acc: 0.9408\n",
      "Epoch 815/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1818 - acc: 0.9425\n",
      "Epoch 816/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1692 - acc: 0.9492\n",
      "Epoch 817/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1701 - acc: 0.9452\n",
      "Epoch 818/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1571 - acc: 0.9503\n",
      "Epoch 819/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1812 - acc: 0.9439\n",
      "Epoch 820/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1665 - acc: 0.9472\n",
      "Epoch 821/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1822 - acc: 0.9432\n",
      "Epoch 822/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1827 - acc: 0.9442\n",
      "Epoch 823/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1574 - acc: 0.9445\n",
      "Epoch 824/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1911 - acc: 0.9462\n",
      "Epoch 825/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1626 - acc: 0.9439\n",
      "Epoch 826/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1956 - acc: 0.9415\n",
      "Epoch 827/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1816 - acc: 0.9408\n",
      "Epoch 828/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1814 - acc: 0.9405\n",
      "Epoch 829/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1766 - acc: 0.9459\n",
      "Epoch 830/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1781 - acc: 0.9442\n",
      "Epoch 831/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2028 - acc: 0.9435\n",
      "Epoch 832/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1963 - acc: 0.9395\n",
      "Epoch 833/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1747 - acc: 0.9439\n",
      "Epoch 834/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1769 - acc: 0.9371\n",
      "Epoch 835/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1745 - acc: 0.9412\n",
      "Epoch 836/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1834 - acc: 0.9449\n",
      "Epoch 837/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1940 - acc: 0.9408\n",
      "Epoch 838/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1848 - acc: 0.9432\n",
      "Epoch 839/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1701 - acc: 0.9445\n",
      "Epoch 840/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1663 - acc: 0.9455\n",
      "Epoch 841/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2008 - acc: 0.9395\n",
      "Epoch 842/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1901 - acc: 0.9425\n",
      "Epoch 843/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1594 - acc: 0.9469\n",
      "Epoch 844/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1764 - acc: 0.9476\n",
      "Epoch 845/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1764 - acc: 0.9449\n",
      "Epoch 846/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1707 - acc: 0.9418\n",
      "Epoch 847/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1668 - acc: 0.9462\n",
      "Epoch 848/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2005 - acc: 0.9439\n",
      "Epoch 849/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1750 - acc: 0.9412\n",
      "Epoch 850/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1925 - acc: 0.9415\n",
      "Epoch 851/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1715 - acc: 0.9469\n",
      "Epoch 852/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1871 - acc: 0.9442\n",
      "Epoch 853/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1889 - acc: 0.9466\n",
      "Epoch 854/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1930 - acc: 0.9385\n",
      "Epoch 855/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1707 - acc: 0.9469\n",
      "Epoch 856/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1878 - acc: 0.9415\n",
      "Epoch 857/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1874 - acc: 0.9385\n",
      "Epoch 858/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1725 - acc: 0.9398\n",
      "Epoch 859/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1907 - acc: 0.9385\n",
      "Epoch 860/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1854 - acc: 0.9415\n",
      "Epoch 861/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1794 - acc: 0.9402\n",
      "Epoch 862/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1783 - acc: 0.9432\n",
      "Epoch 863/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1880 - acc: 0.9422\n",
      "Epoch 864/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1685 - acc: 0.9442\n",
      "Epoch 865/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1649 - acc: 0.9418\n",
      "Epoch 866/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1999 - acc: 0.9405\n",
      "Epoch 867/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1947 - acc: 0.9439\n",
      "Epoch 868/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1944 - acc: 0.9402\n",
      "Epoch 869/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1994 - acc: 0.9378\n",
      "Epoch 870/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1721 - acc: 0.9476\n",
      "Epoch 871/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1734 - acc: 0.9422\n",
      "Epoch 872/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1808 - acc: 0.9395\n",
      "Epoch 873/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2142 - acc: 0.9439\n",
      "Epoch 874/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1800 - acc: 0.9425\n",
      "Epoch 875/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1667 - acc: 0.9472\n",
      "Epoch 876/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1833 - acc: 0.9398\n",
      "Epoch 877/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1741 - acc: 0.9439\n",
      "Epoch 878/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1923 - acc: 0.9435\n",
      "Epoch 879/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1807 - acc: 0.9442\n",
      "Epoch 880/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1784 - acc: 0.9442\n",
      "Epoch 881/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1855 - acc: 0.9415\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1628 - acc: 0.9449\n",
      "Epoch 883/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1653 - acc: 0.9472\n",
      "Epoch 884/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2048 - acc: 0.9392\n",
      "Epoch 885/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1874 - acc: 0.9422\n",
      "Epoch 886/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1671 - acc: 0.9486\n",
      "Epoch 887/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1740 - acc: 0.9466\n",
      "Epoch 888/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1775 - acc: 0.9442\n",
      "Epoch 889/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1966 - acc: 0.9395\n",
      "Epoch 890/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1883 - acc: 0.9398\n",
      "Epoch 891/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1867 - acc: 0.9439\n",
      "Epoch 892/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1710 - acc: 0.9466\n",
      "Epoch 893/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1953 - acc: 0.9429\n",
      "Epoch 894/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1815 - acc: 0.9459\n",
      "Epoch 895/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2153 - acc: 0.9388\n",
      "Epoch 896/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1828 - acc: 0.9415\n",
      "Epoch 897/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1737 - acc: 0.9435\n",
      "Epoch 898/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1746 - acc: 0.9449\n",
      "Epoch 899/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1805 - acc: 0.9415\n",
      "Epoch 900/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1799 - acc: 0.9392\n",
      "Epoch 901/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1829 - acc: 0.9459\n",
      "Epoch 902/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1818 - acc: 0.9425\n",
      "Epoch 903/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2030 - acc: 0.9412\n",
      "Epoch 904/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1965 - acc: 0.9348\n",
      "Epoch 905/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1769 - acc: 0.9452\n",
      "Epoch 906/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1938 - acc: 0.9398\n",
      "Epoch 907/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1768 - acc: 0.9425\n",
      "Epoch 908/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1989 - acc: 0.9445\n",
      "Epoch 909/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1836 - acc: 0.9402\n",
      "Epoch 910/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1837 - acc: 0.9425\n",
      "Epoch 911/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1921 - acc: 0.9408\n",
      "Epoch 912/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2101 - acc: 0.9432\n",
      "Epoch 913/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1963 - acc: 0.9452\n",
      "Epoch 914/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1787 - acc: 0.9385\n",
      "Epoch 915/1000\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 0.2043 - acc: 0.9418\n",
      "Epoch 916/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1814 - acc: 0.9442\n",
      "Epoch 917/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1869 - acc: 0.9442\n",
      "Epoch 918/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1664 - acc: 0.9472\n",
      "Epoch 919/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2032 - acc: 0.9462\n",
      "Epoch 920/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2003 - acc: 0.9371\n",
      "Epoch 921/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1586 - acc: 0.9509\n",
      "Epoch 922/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1977 - acc: 0.9408\n",
      "Epoch 923/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1912 - acc: 0.9365\n",
      "Epoch 924/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1717 - acc: 0.9469\n",
      "Epoch 925/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1757 - acc: 0.9442\n",
      "Epoch 926/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1804 - acc: 0.9412\n",
      "Epoch 927/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1900 - acc: 0.9452\n",
      "Epoch 928/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1925 - acc: 0.9382\n",
      "Epoch 929/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1768 - acc: 0.9472\n",
      "Epoch 930/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1883 - acc: 0.9408\n",
      "Epoch 931/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1942 - acc: 0.9435\n",
      "Epoch 932/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1851 - acc: 0.9392\n",
      "Epoch 933/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1830 - acc: 0.9462\n",
      "Epoch 934/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1954 - acc: 0.9371\n",
      "Epoch 935/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1804 - acc: 0.9395\n",
      "Epoch 936/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1647 - acc: 0.9503\n",
      "Epoch 937/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1989 - acc: 0.9402\n",
      "Epoch 938/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1907 - acc: 0.9429\n",
      "Epoch 939/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1731 - acc: 0.9445\n",
      "Epoch 940/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2030 - acc: 0.9395\n",
      "Epoch 941/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1702 - acc: 0.9482\n",
      "Epoch 942/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1865 - acc: 0.9449\n",
      "Epoch 943/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1673 - acc: 0.9439\n",
      "Epoch 944/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1789 - acc: 0.9449\n",
      "Epoch 945/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1683 - acc: 0.9439\n",
      "Epoch 946/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2028 - acc: 0.9408\n",
      "Epoch 947/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1942 - acc: 0.9388\n",
      "Epoch 948/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1725 - acc: 0.9496\n",
      "Epoch 949/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1995 - acc: 0.9348\n",
      "Epoch 950/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1856 - acc: 0.9429\n",
      "Epoch 951/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1724 - acc: 0.9422\n",
      "Epoch 952/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1985 - acc: 0.9449\n",
      "Epoch 953/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1712 - acc: 0.9425\n",
      "Epoch 954/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1957 - acc: 0.9442\n",
      "Epoch 955/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1528 - acc: 0.9486\n",
      "Epoch 956/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1693 - acc: 0.9459\n",
      "Epoch 957/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2000 - acc: 0.9432\n",
      "Epoch 958/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1645 - acc: 0.9482\n",
      "Epoch 959/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1821 - acc: 0.9402\n",
      "Epoch 960/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1811 - acc: 0.9425\n",
      "Epoch 961/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1837 - acc: 0.9422\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1920 - acc: 0.9432\n",
      "Epoch 963/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1714 - acc: 0.9472\n",
      "Epoch 964/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1738 - acc: 0.9445\n",
      "Epoch 965/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2000 - acc: 0.9442\n",
      "Epoch 966/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1872 - acc: 0.9402\n",
      "Epoch 967/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1885 - acc: 0.9432\n",
      "Epoch 968/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1875 - acc: 0.9472\n",
      "Epoch 969/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1939 - acc: 0.9442\n",
      "Epoch 970/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1932 - acc: 0.9385\n",
      "Epoch 971/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1925 - acc: 0.9361\n",
      "Epoch 972/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1893 - acc: 0.9479\n",
      "Epoch 973/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1905 - acc: 0.9408\n",
      "Epoch 974/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1683 - acc: 0.9445\n",
      "Epoch 975/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1828 - acc: 0.9425\n",
      "Epoch 976/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1639 - acc: 0.9469\n",
      "Epoch 977/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1939 - acc: 0.9435\n",
      "Epoch 978/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1904 - acc: 0.9395\n",
      "Epoch 979/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1799 - acc: 0.9455\n",
      "Epoch 980/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1910 - acc: 0.9425\n",
      "Epoch 981/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1845 - acc: 0.9405\n",
      "Epoch 982/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1856 - acc: 0.9402\n",
      "Epoch 983/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2043 - acc: 0.9452\n",
      "Epoch 984/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2258 - acc: 0.9415\n",
      "Epoch 985/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2130 - acc: 0.9382\n",
      "Epoch 986/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1648 - acc: 0.9452\n",
      "Epoch 987/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1686 - acc: 0.9469\n",
      "Epoch 988/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1906 - acc: 0.9361\n",
      "Epoch 989/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1745 - acc: 0.9405\n",
      "Epoch 990/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1893 - acc: 0.9365\n",
      "Epoch 991/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2056 - acc: 0.9365\n",
      "Epoch 992/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2005 - acc: 0.9432\n",
      "Epoch 993/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1762 - acc: 0.9429\n",
      "Epoch 994/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1848 - acc: 0.9392\n",
      "Epoch 995/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1928 - acc: 0.9405\n",
      "Epoch 996/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1860 - acc: 0.9439\n",
      "Epoch 997/1000\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 0.2023 - acc: 0.9435\n",
      "Epoch 998/1000\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 0.1864 - acc: 0.9449\n",
      "Epoch 999/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1818 - acc: 0.9439\n",
      "Epoch 1000/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1963 - acc: 0.9355\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history[\"loss\"], label=[\"loss\"]) #play with hyperparameters to see the changes\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(history.history[\"acc\"],  label=[\"acc\"])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 0s 19us/step\n",
      "Loss / Accuracy Evaluation\n",
      "--------------------------\n",
      "Loss:     0.33298\n",
      "Accuracy: 0.91667\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_val, y_val)\n",
    "print(\"Loss / Accuracy Evaluation\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Loss:     \" + str(round(test_loss,5)))\n",
    "print(\"Accuracy: \" + str(round(test_acc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9140657e-07, 2.1038881e-02, 3.8363163e-05, 4.0604462e-08,\n",
       "       9.7892249e-01], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_pred[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model in tensorflow.js Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflowjs library can't be installed directly with pip / conda due to conflicting dependencies. Best is to set up a new environment explicitly for this and install tensorflowjs with the following commands:\n",
    "\n",
    "```\n",
    "pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "pip install --no-deps tensorflowjs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.11.0rc2\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow==1.11.0rc2 (from versions: 0.12.1, 1.0.0, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2)\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow==1.11.0rc2\u001b[0m\n",
      "Requirement already satisfied: tensorflowjs in /Users/lsafari/anaconda3/lib/python3.6/site-packages (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "! pip install --no-deps tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/d7/90f34cb0d83a6c5631cf71dfe64cc1054598c843a92b400e55675cc2ac37/pip-18.1-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |ââââââââââââââââââââââââââââââââ| 1.3MB 3.5MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.0\n",
      "    Uninstalling pip-18.0:\n",
      "      Successfully uninstalled pip-18.0\n",
      "Successfully installed pip-18.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /Users/lsafari/anaconda3/lib/python3.6/site-packages (4.8.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (6.4.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (4.3.2)\n",
      "Requirement already satisfied: jupyter_client in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (5.2.3)\n",
      "Requirement already satisfied: tornado>=4.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (5.0.2)\n",
      "Requirement already satisfied: pickleshare in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.7.4)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.12.0)\n",
      "Requirement already satisfied: backcall in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.8.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (1.0.15)\n",
      "Requirement already satisfied: decorator in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (4.3.0)\n",
      "Requirement already satisfied: pygments in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (39.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.1.0)\n",
      "Requirement already satisfied: ipython_genutils in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: six in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (1.11.0)\n",
      "Requirement already satisfied: jupyter_core in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (17.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (2.7.3)\n",
      "Requirement already satisfied: parso>=0.2.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel) (0.5.2)\n",
      "Requirement already satisfied: tensorflow_hub in /Users/lsafari/anaconda3/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (3.6.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.14.3)\n",
      "Requirement already satisfied: setuptools in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow_hub) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ipykernel\n",
    "! pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lsafari/drone_steering/models\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "model.save('pose_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'model_pose_tfjs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adapt the two files as follows in order for them to work on Azure:\n",
    "* add a file extension .pb to the file with no extension (otherwise Azure blocks it from viewing)\n",
    "* adapt the automatically generated model.json to reflect the extension .pb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
