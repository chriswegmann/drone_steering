{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posture detection keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1. Importing libraries and defining transformers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ipytest.magics\n",
    "import pytest\n",
    "# set the file name (required)\n",
    "__file__ = 'drone_pos_model.ipynb'\n",
    "######################################################################################\n",
    "class Shuffler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        x=x.loc[np.random.permutation(x.index)]\n",
    "        \n",
    "        return x\n",
    "############################################################################################\n",
    "class XCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, x_columns):\n",
    "        self.x_columns = x_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_x\",\"leftShoulder_x\",\"leftHip_x\",\"rightHip_x\"]].sum(axis=1)/4\n",
    "        for col in self.x_columns:\n",
    "            x[col] = x[col] - shift\n",
    "        return x\n",
    "############################################################################################\n",
    "class YCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, y_columns):\n",
    "        self.y_columns = y_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_y\",\"leftShoulder_y\",\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/4\n",
    "        for col in list(set(self.y_columns)-set([\"label\"])):\n",
    "            x[col] = x[col] - shift\n",
    "        return x\n",
    "############################################################################################\n",
    "class YScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shoulder_y = x[[\"rightShoulder_y\",\"leftShoulder_y\"]].sum(axis=1)/2\n",
    "        hip_y = x[[\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/2\n",
    "        y_dist = hip_y - shoulder_y\n",
    "        \n",
    "        for col in list(set(x.columns)-set([\"label\"])):\n",
    "            x[col] /= y_dist\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 2.  Data inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3719, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.19500</td>\n",
       "      <td>0.50875</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.26625</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.41125</td>\n",
       "      <td>0.34625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.18875</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.18625</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.25875</td>\n",
       "      <td>0.33250</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.27625</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.46750</td>\n",
       "      <td>0.33625</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49125</td>\n",
       "      <td>0.19000</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.17875</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26125</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.19875</td>\n",
       "      <td>0.51125</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.26375</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.46375</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "0         0.49250         0.18750           0.4000          0.18250   \n",
       "1         0.49250         0.18875           0.4025          0.18625   \n",
       "2         0.49125         0.19000           0.4025          0.17875   \n",
       "\n",
       "   leftElbow_x  leftElbow_y  rightElbow_x  rightElbow_y  leftWrist_x  \\\n",
       "0       0.5050      0.26000       0.34375       0.19500      0.50875   \n",
       "1       0.5075      0.25875       0.33250       0.19750      0.50000   \n",
       "2       0.5050      0.26125       0.33500       0.19875      0.51125   \n",
       "\n",
       "   leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  leftHip_y  rightHip_x  \\\n",
       "0      0.33875       0.26625       0.16875    0.46500    0.34375     0.41125   \n",
       "1      0.33750       0.27625       0.17500    0.46750    0.33625     0.40875   \n",
       "2      0.33500       0.26375       0.16875    0.46375    0.33875     0.40875   \n",
       "\n",
       "   rightHip_y  label  \n",
       "0     0.34625      1  \n",
       "1     0.33750      1  \n",
       "2     0.33750      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"video_all_posture_steptime50_checksum8160\"\n",
    "df = pd.read_csv(\"../data/\"+ path + \".csv\",low_memory=False)\n",
    "df1=df.dropna().drop_duplicates()\n",
    "print(df1.shape)\n",
    "df1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that we don't have any null values\n",
    "assert df1.isnull().all().all() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 3. Setting the pipeline arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['leftShoulder_x', 'rightShoulder_x',\n",
    "        'leftElbow_x', 'rightElbow_x',\n",
    "        'leftWrist_x', 'rightWrist_x',\n",
    "        'leftHip_x', 'rightHip_x']\n",
    "y_cols = list(set(df1.columns)-set(x_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 4. Data prosseser pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>0.275000</td>\n",
       "      <td>-0.486364</td>\n",
       "      <td>-0.270455</td>\n",
       "      <td>-0.513636</td>\n",
       "      <td>0.411364</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>-0.470455</td>\n",
       "      <td>-0.004545</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.377273</td>\n",
       "      <td>-0.461364</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.184091</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>-0.188636</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>0.197368</td>\n",
       "      <td>-0.517544</td>\n",
       "      <td>-0.293860</td>\n",
       "      <td>-0.482456</td>\n",
       "      <td>0.346491</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>-0.267544</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.364035</td>\n",
       "      <td>0.587719</td>\n",
       "      <td>-0.127193</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.232456</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>-0.135965</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.305085</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.288136</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>-0.406780</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>-0.432203</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.516949</td>\n",
       "      <td>-0.186441</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "1833        0.275000       -0.486364        -0.270455        -0.513636   \n",
       "2728        0.197368       -0.517544        -0.293860        -0.482456   \n",
       "330         0.305085       -0.500000        -0.288136        -0.500000   \n",
       "\n",
       "      leftElbow_x  leftElbow_y  rightElbow_x  rightElbow_y  leftWrist_x  \\\n",
       "1833     0.411364     0.022727     -0.470455     -0.004545     0.511364   \n",
       "2728     0.346491     0.043860     -0.267544      0.008772     0.364035   \n",
       "330      0.398305     0.016949     -0.406780      0.050847     0.406780   \n",
       "\n",
       "      leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  leftHip_y  \\\n",
       "1833     0.377273     -0.461364      0.331818   0.184091   0.477273   \n",
       "2728     0.587719     -0.127193      0.570175   0.232456   0.491228   \n",
       "330      0.483051     -0.432203      0.491525   0.169492   0.516949   \n",
       "\n",
       "      rightHip_x  rightHip_y  label  \n",
       "1833   -0.188636    0.522727      0  \n",
       "2728   -0.135965    0.508772      4  \n",
       "330    -0.186441    0.483051      4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_pipeline = make_pipeline(XCentralizer(x_cols), YCentralizer(y_cols), YScaler(), Shuffler())\n",
    "processed_df = processing_pipeline.fit_transform(df1)\n",
    "processed_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df1.shape[0] == processed_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 1.  Train, test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processed_df.iloc[:int(processed_df.shape[0]*0.8)]\n",
    "df_test = processed_df.iloc[int(processed_df.shape[0]*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train.shape[0] + df_test.shape[0] == df1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 2. Setting numpy arrays to be feeded in the neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "x_train=df_train.drop(['label'], axis=1).values\n",
    "y_train=df_train['label'].values\n",
    "x_test=df_test.drop(['label'], axis=1).values\n",
    "y_test=df_test['label'].values\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2975, 16) (2975, 5)\n",
      "x_train[0]= [ 0.275      -0.48636364 -0.27045455 -0.51363636  0.41136364  0.02272727\n",
      " -0.47045455 -0.00454545  0.51136364  0.37727273 -0.46136364  0.33181818\n",
      "  0.18409091  0.47727273 -0.18863636  0.52272727] \n",
      " y_train[0]= [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape )\n",
    "print(\"x_train[0]=\", x_train[0],\"\\n y_train[0]=\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                340       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 735\n",
      "Trainable params: 735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import optimizers, losses, metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(\n",
    "        20, \n",
    "        activation=\"relu\", \n",
    "        input_shape=(16, )))\n",
    "model.add(layers.Dense(15, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"softmax\")) \n",
    "model.summary()   \n",
    "\n",
    "model.compile(\n",
    "optimizer=optimizers.RMSprop(lr=0.005),\n",
    "loss=losses.categorical_crossentropy,\n",
    "metrics=[\"accuracy\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 4. Model fitting and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2380 samples, validate on 595 samples\n",
      "Epoch 1/2000\n",
      "2380/2380 [==============================] - 0s 94us/step - loss: 1.3046 - acc: 0.5105 - val_loss: 1.1085 - val_acc: 0.5529\n",
      "Epoch 2/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.9607 - acc: 0.6794 - val_loss: 0.8463 - val_acc: 0.6756\n",
      "Epoch 3/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.7939 - acc: 0.7492 - val_loss: 0.8414 - val_acc: 0.6723\n",
      "Epoch 4/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.7134 - acc: 0.7739 - val_loss: 0.7087 - val_acc: 0.7866\n",
      "Epoch 5/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.6568 - acc: 0.8038 - val_loss: 0.6066 - val_acc: 0.8151\n",
      "Epoch 6/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.6149 - acc: 0.8189 - val_loss: 0.7823 - val_acc: 0.7059\n",
      "Epoch 7/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.5784 - acc: 0.8303 - val_loss: 0.5519 - val_acc: 0.8269\n",
      "Epoch 8/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.5400 - acc: 0.8399 - val_loss: 0.7146 - val_acc: 0.7513\n",
      "Epoch 9/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.5292 - acc: 0.8462 - val_loss: 0.5545 - val_acc: 0.8370\n",
      "Epoch 10/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.5053 - acc: 0.8487 - val_loss: 0.5492 - val_acc: 0.8403\n",
      "Epoch 11/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.4907 - acc: 0.8521 - val_loss: 0.5168 - val_acc: 0.8622\n",
      "Epoch 12/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.4768 - acc: 0.8626 - val_loss: 0.4860 - val_acc: 0.8471\n",
      "Epoch 13/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.4625 - acc: 0.8727 - val_loss: 0.4572 - val_acc: 0.8790\n",
      "Epoch 14/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.4457 - acc: 0.8706 - val_loss: 0.4497 - val_acc: 0.8790\n",
      "Epoch 15/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.4394 - acc: 0.8714 - val_loss: 0.4691 - val_acc: 0.8874\n",
      "Epoch 16/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.4301 - acc: 0.8723 - val_loss: 0.5145 - val_acc: 0.8605\n",
      "Epoch 17/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.4160 - acc: 0.8807 - val_loss: 0.4589 - val_acc: 0.8723\n",
      "Epoch 18/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.4217 - acc: 0.8727 - val_loss: 0.4243 - val_acc: 0.8790\n",
      "Epoch 19/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.4053 - acc: 0.8811 - val_loss: 0.4333 - val_acc: 0.8622\n",
      "Epoch 20/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3914 - acc: 0.8828 - val_loss: 0.4259 - val_acc: 0.8773\n",
      "Epoch 21/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.4011 - acc: 0.8819 - val_loss: 0.4546 - val_acc: 0.8521\n",
      "Epoch 22/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3903 - acc: 0.8849 - val_loss: 0.4018 - val_acc: 0.8941\n",
      "Epoch 23/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.3833 - acc: 0.8887 - val_loss: 0.4096 - val_acc: 0.8840\n",
      "Epoch 24/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3759 - acc: 0.8840 - val_loss: 0.4412 - val_acc: 0.8571\n",
      "Epoch 25/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3760 - acc: 0.8866 - val_loss: 0.4383 - val_acc: 0.8840\n",
      "Epoch 26/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3723 - acc: 0.8908 - val_loss: 0.3740 - val_acc: 0.8924\n",
      "Epoch 27/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3715 - acc: 0.8899 - val_loss: 0.3845 - val_acc: 0.8908\n",
      "Epoch 28/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3688 - acc: 0.8857 - val_loss: 0.3759 - val_acc: 0.8840\n",
      "Epoch 29/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.3573 - acc: 0.8929 - val_loss: 0.5297 - val_acc: 0.8101\n",
      "Epoch 30/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3607 - acc: 0.8933 - val_loss: 0.3682 - val_acc: 0.8924\n",
      "Epoch 31/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3546 - acc: 0.8983 - val_loss: 0.5033 - val_acc: 0.8303\n",
      "Epoch 32/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3570 - acc: 0.8912 - val_loss: 0.3736 - val_acc: 0.8941\n",
      "Epoch 33/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.3428 - acc: 0.8945 - val_loss: 0.4343 - val_acc: 0.8706\n",
      "Epoch 34/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.3451 - acc: 0.8954 - val_loss: 0.5050 - val_acc: 0.8235\n",
      "Epoch 35/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.3499 - acc: 0.8941 - val_loss: 0.4413 - val_acc: 0.8739\n",
      "Epoch 36/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.3414 - acc: 0.8933 - val_loss: 0.4665 - val_acc: 0.8689\n",
      "Epoch 37/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3328 - acc: 0.8933 - val_loss: 0.4006 - val_acc: 0.8790\n",
      "Epoch 38/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3406 - acc: 0.8887 - val_loss: 0.3435 - val_acc: 0.8992\n",
      "Epoch 39/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.3314 - acc: 0.8987 - val_loss: 0.3685 - val_acc: 0.8924\n",
      "Epoch 40/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3304 - acc: 0.9017 - val_loss: 0.5640 - val_acc: 0.8101\n",
      "Epoch 41/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3302 - acc: 0.8933 - val_loss: 0.3466 - val_acc: 0.9042\n",
      "Epoch 42/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.3293 - acc: 0.8937 - val_loss: 0.3547 - val_acc: 0.8857\n",
      "Epoch 43/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3183 - acc: 0.9025 - val_loss: 0.4637 - val_acc: 0.8706\n",
      "Epoch 44/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3207 - acc: 0.8983 - val_loss: 0.4357 - val_acc: 0.8555\n",
      "Epoch 45/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.3171 - acc: 0.9013 - val_loss: 0.3691 - val_acc: 0.9042\n",
      "Epoch 46/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3145 - acc: 0.9059 - val_loss: 0.3278 - val_acc: 0.8975\n",
      "Epoch 47/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3187 - acc: 0.9025 - val_loss: 0.3854 - val_acc: 0.8739\n",
      "Epoch 48/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3203 - acc: 0.8979 - val_loss: 0.3992 - val_acc: 0.8807\n",
      "Epoch 49/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.3105 - acc: 0.9034 - val_loss: 0.3718 - val_acc: 0.8857\n",
      "Epoch 50/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3033 - acc: 0.9029 - val_loss: 0.3930 - val_acc: 0.8824\n",
      "Epoch 51/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3041 - acc: 0.9076 - val_loss: 0.3221 - val_acc: 0.8941\n",
      "Epoch 52/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3015 - acc: 0.9071 - val_loss: 0.5533 - val_acc: 0.8437\n",
      "Epoch 53/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3030 - acc: 0.9013 - val_loss: 0.3664 - val_acc: 0.8874\n",
      "Epoch 54/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3040 - acc: 0.9008 - val_loss: 0.3189 - val_acc: 0.9025\n",
      "Epoch 55/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.3115 - acc: 0.9046 - val_loss: 0.3278 - val_acc: 0.9042\n",
      "Epoch 56/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2923 - acc: 0.9046 - val_loss: 0.4750 - val_acc: 0.8706\n",
      "Epoch 57/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.3026 - acc: 0.9029 - val_loss: 0.3144 - val_acc: 0.9008\n",
      "Epoch 58/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2893 - acc: 0.9063 - val_loss: 0.3293 - val_acc: 0.8975\n",
      "Epoch 59/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2971 - acc: 0.9097 - val_loss: 0.3375 - val_acc: 0.9076\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2891 - acc: 0.9084 - val_loss: 0.3351 - val_acc: 0.8975\n",
      "Epoch 61/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2838 - acc: 0.9097 - val_loss: 0.3812 - val_acc: 0.8706\n",
      "Epoch 62/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2862 - acc: 0.9113 - val_loss: 0.5111 - val_acc: 0.8202\n",
      "Epoch 63/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.2956 - acc: 0.9050 - val_loss: 0.3137 - val_acc: 0.8992\n",
      "Epoch 64/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2885 - acc: 0.9084 - val_loss: 0.3279 - val_acc: 0.9025\n",
      "Epoch 65/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2799 - acc: 0.9063 - val_loss: 0.3299 - val_acc: 0.9008\n",
      "Epoch 66/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2786 - acc: 0.9109 - val_loss: 0.3114 - val_acc: 0.9076\n",
      "Epoch 67/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.2870 - acc: 0.9050 - val_loss: 0.3506 - val_acc: 0.8992\n",
      "Epoch 68/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2839 - acc: 0.9092 - val_loss: 0.3571 - val_acc: 0.8941\n",
      "Epoch 69/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2772 - acc: 0.9126 - val_loss: 0.3654 - val_acc: 0.8958\n",
      "Epoch 70/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2828 - acc: 0.9071 - val_loss: 0.3555 - val_acc: 0.8941\n",
      "Epoch 71/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2664 - acc: 0.9164 - val_loss: 0.3102 - val_acc: 0.9059\n",
      "Epoch 72/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2739 - acc: 0.9063 - val_loss: 0.3312 - val_acc: 0.8992\n",
      "Epoch 73/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2703 - acc: 0.9151 - val_loss: 0.3162 - val_acc: 0.9076\n",
      "Epoch 74/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2676 - acc: 0.9122 - val_loss: 0.3093 - val_acc: 0.9109\n",
      "Epoch 75/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2660 - acc: 0.9151 - val_loss: 0.3201 - val_acc: 0.9025\n",
      "Epoch 76/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2660 - acc: 0.9105 - val_loss: 0.3732 - val_acc: 0.8857\n",
      "Epoch 77/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2586 - acc: 0.9134 - val_loss: 0.4024 - val_acc: 0.8874\n",
      "Epoch 78/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2613 - acc: 0.9130 - val_loss: 0.3841 - val_acc: 0.8840\n",
      "Epoch 79/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2615 - acc: 0.9126 - val_loss: 0.3144 - val_acc: 0.9059\n",
      "Epoch 80/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2625 - acc: 0.9118 - val_loss: 0.3357 - val_acc: 0.8958\n",
      "Epoch 81/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2550 - acc: 0.9147 - val_loss: 0.3417 - val_acc: 0.8924\n",
      "Epoch 82/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2541 - acc: 0.9172 - val_loss: 0.3402 - val_acc: 0.8941\n",
      "Epoch 83/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2512 - acc: 0.9189 - val_loss: 0.4703 - val_acc: 0.8437\n",
      "Epoch 84/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2649 - acc: 0.9113 - val_loss: 0.4233 - val_acc: 0.8555\n",
      "Epoch 85/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2525 - acc: 0.9155 - val_loss: 0.3308 - val_acc: 0.9042\n",
      "Epoch 86/2000\n",
      "2380/2380 [==============================] - 0s 48us/step - loss: 0.2546 - acc: 0.9147 - val_loss: 0.3812 - val_acc: 0.8723\n",
      "Epoch 87/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.2587 - acc: 0.9189 - val_loss: 0.4047 - val_acc: 0.8857\n",
      "Epoch 88/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2598 - acc: 0.9097 - val_loss: 0.3017 - val_acc: 0.9092\n",
      "Epoch 89/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.2464 - acc: 0.9193 - val_loss: 0.3803 - val_acc: 0.8756\n",
      "Epoch 90/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.2438 - acc: 0.9193 - val_loss: 0.3042 - val_acc: 0.9042\n",
      "Epoch 91/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.2491 - acc: 0.9147 - val_loss: 0.3872 - val_acc: 0.8689\n",
      "Epoch 92/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2498 - acc: 0.9126 - val_loss: 0.3170 - val_acc: 0.9160\n",
      "Epoch 93/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2474 - acc: 0.9155 - val_loss: 0.3875 - val_acc: 0.8840\n",
      "Epoch 94/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2574 - acc: 0.9118 - val_loss: 0.2975 - val_acc: 0.9109\n",
      "Epoch 95/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.2436 - acc: 0.9202 - val_loss: 0.3152 - val_acc: 0.9059\n",
      "Epoch 96/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2416 - acc: 0.9193 - val_loss: 0.5373 - val_acc: 0.8286\n",
      "Epoch 97/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.2555 - acc: 0.9126 - val_loss: 0.3708 - val_acc: 0.8924\n",
      "Epoch 98/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2366 - acc: 0.9206 - val_loss: 0.3179 - val_acc: 0.8992\n",
      "Epoch 99/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.2446 - acc: 0.9218 - val_loss: 0.3540 - val_acc: 0.8941\n",
      "Epoch 100/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2401 - acc: 0.9202 - val_loss: 0.3444 - val_acc: 0.8891\n",
      "Epoch 101/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2414 - acc: 0.9202 - val_loss: 0.3312 - val_acc: 0.8924\n",
      "Epoch 102/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2391 - acc: 0.9231 - val_loss: 0.3256 - val_acc: 0.9025\n",
      "Epoch 103/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2401 - acc: 0.9218 - val_loss: 0.3693 - val_acc: 0.8840\n",
      "Epoch 104/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2412 - acc: 0.9218 - val_loss: 0.3101 - val_acc: 0.9160\n",
      "Epoch 105/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.2330 - acc: 0.9227 - val_loss: 0.4028 - val_acc: 0.8790\n",
      "Epoch 106/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.2307 - acc: 0.9210 - val_loss: 0.4166 - val_acc: 0.8874\n",
      "Epoch 107/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2400 - acc: 0.9193 - val_loss: 0.3347 - val_acc: 0.9126\n",
      "Epoch 108/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2326 - acc: 0.9239 - val_loss: 0.3503 - val_acc: 0.8941\n",
      "Epoch 109/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2397 - acc: 0.9202 - val_loss: 0.3946 - val_acc: 0.8958\n",
      "Epoch 110/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2384 - acc: 0.9197 - val_loss: 0.3142 - val_acc: 0.9109\n",
      "Epoch 111/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2232 - acc: 0.9328 - val_loss: 0.3176 - val_acc: 0.9025\n",
      "Epoch 112/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2348 - acc: 0.9244 - val_loss: 0.3756 - val_acc: 0.8924\n",
      "Epoch 113/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2286 - acc: 0.9261 - val_loss: 0.3350 - val_acc: 0.9008\n",
      "Epoch 114/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2270 - acc: 0.9290 - val_loss: 0.4563 - val_acc: 0.8756\n",
      "Epoch 115/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2317 - acc: 0.9151 - val_loss: 0.3309 - val_acc: 0.9109\n",
      "Epoch 116/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2344 - acc: 0.9197 - val_loss: 0.3443 - val_acc: 0.8992\n",
      "Epoch 117/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2303 - acc: 0.9239 - val_loss: 0.3120 - val_acc: 0.9160\n",
      "Epoch 118/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2201 - acc: 0.9256 - val_loss: 0.2997 - val_acc: 0.9126\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2194 - acc: 0.9269 - val_loss: 0.3269 - val_acc: 0.9092\n",
      "Epoch 120/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2293 - acc: 0.9269 - val_loss: 0.3574 - val_acc: 0.9109\n",
      "Epoch 121/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.2275 - acc: 0.9252 - val_loss: 0.3700 - val_acc: 0.8924\n",
      "Epoch 122/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.2313 - acc: 0.9256 - val_loss: 0.3783 - val_acc: 0.9042\n",
      "Epoch 123/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2188 - acc: 0.9277 - val_loss: 0.2881 - val_acc: 0.9261\n",
      "Epoch 124/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2206 - acc: 0.9298 - val_loss: 0.3248 - val_acc: 0.9109\n",
      "Epoch 125/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2196 - acc: 0.9290 - val_loss: 0.4947 - val_acc: 0.8353\n",
      "Epoch 126/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2258 - acc: 0.9290 - val_loss: 0.3501 - val_acc: 0.9176\n",
      "Epoch 127/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2192 - acc: 0.9277 - val_loss: 0.2949 - val_acc: 0.9210\n",
      "Epoch 128/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2195 - acc: 0.9273 - val_loss: 0.3686 - val_acc: 0.8773\n",
      "Epoch 129/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.2221 - acc: 0.9235 - val_loss: 0.3665 - val_acc: 0.9076\n",
      "Epoch 130/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2231 - acc: 0.9210 - val_loss: 0.3976 - val_acc: 0.8824\n",
      "Epoch 131/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2309 - acc: 0.9244 - val_loss: 0.3371 - val_acc: 0.9042\n",
      "Epoch 132/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2150 - acc: 0.9286 - val_loss: 0.3079 - val_acc: 0.9076\n",
      "Epoch 133/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2202 - acc: 0.9294 - val_loss: 0.3373 - val_acc: 0.9042\n",
      "Epoch 134/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2090 - acc: 0.9311 - val_loss: 0.3227 - val_acc: 0.9092\n",
      "Epoch 135/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.2146 - acc: 0.9277 - val_loss: 0.4463 - val_acc: 0.8840\n",
      "Epoch 136/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2222 - acc: 0.9252 - val_loss: 0.3286 - val_acc: 0.9076\n",
      "Epoch 137/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2132 - acc: 0.9282 - val_loss: 0.3670 - val_acc: 0.9008\n",
      "Epoch 138/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2113 - acc: 0.9303 - val_loss: 0.3770 - val_acc: 0.8908\n",
      "Epoch 139/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2179 - acc: 0.9336 - val_loss: 0.3123 - val_acc: 0.9193\n",
      "Epoch 140/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2127 - acc: 0.9294 - val_loss: 0.4100 - val_acc: 0.8924\n",
      "Epoch 141/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2147 - acc: 0.9290 - val_loss: 0.4715 - val_acc: 0.8975\n",
      "Epoch 142/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2125 - acc: 0.9252 - val_loss: 0.3991 - val_acc: 0.9025\n",
      "Epoch 143/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2123 - acc: 0.9273 - val_loss: 0.3563 - val_acc: 0.8992\n",
      "Epoch 144/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2090 - acc: 0.9256 - val_loss: 0.4880 - val_acc: 0.8874\n",
      "Epoch 145/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2154 - acc: 0.9248 - val_loss: 0.4820 - val_acc: 0.8622\n",
      "Epoch 146/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2023 - acc: 0.9319 - val_loss: 0.3725 - val_acc: 0.8908\n",
      "Epoch 147/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2025 - acc: 0.9239 - val_loss: 0.3553 - val_acc: 0.9176\n",
      "Epoch 148/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1952 - acc: 0.9366 - val_loss: 0.3753 - val_acc: 0.8908\n",
      "Epoch 149/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2123 - acc: 0.9315 - val_loss: 0.3263 - val_acc: 0.9193\n",
      "Epoch 150/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2062 - acc: 0.9307 - val_loss: 0.3333 - val_acc: 0.9160\n",
      "Epoch 151/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2013 - acc: 0.9307 - val_loss: 0.3535 - val_acc: 0.9059\n",
      "Epoch 152/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2069 - acc: 0.9315 - val_loss: 0.3738 - val_acc: 0.9042\n",
      "Epoch 153/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2027 - acc: 0.9324 - val_loss: 0.2927 - val_acc: 0.9294\n",
      "Epoch 154/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2057 - acc: 0.9332 - val_loss: 0.4099 - val_acc: 0.8807\n",
      "Epoch 155/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2021 - acc: 0.9298 - val_loss: 0.3425 - val_acc: 0.9059\n",
      "Epoch 156/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1926 - acc: 0.9336 - val_loss: 0.3874 - val_acc: 0.8739\n",
      "Epoch 157/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2041 - acc: 0.9324 - val_loss: 0.3734 - val_acc: 0.8975\n",
      "Epoch 158/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2002 - acc: 0.9340 - val_loss: 0.3785 - val_acc: 0.8941\n",
      "Epoch 159/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.2039 - acc: 0.9298 - val_loss: 0.3221 - val_acc: 0.9126\n",
      "Epoch 160/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2019 - acc: 0.9319 - val_loss: 0.3268 - val_acc: 0.9143\n",
      "Epoch 161/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2010 - acc: 0.9311 - val_loss: 0.4978 - val_acc: 0.8588\n",
      "Epoch 162/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2021 - acc: 0.9298 - val_loss: 0.3533 - val_acc: 0.9076\n",
      "Epoch 163/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1974 - acc: 0.9345 - val_loss: 0.3445 - val_acc: 0.9193\n",
      "Epoch 164/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.2037 - acc: 0.9303 - val_loss: 0.3124 - val_acc: 0.9193\n",
      "Epoch 165/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1932 - acc: 0.9387 - val_loss: 0.3636 - val_acc: 0.9025\n",
      "Epoch 166/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1921 - acc: 0.9319 - val_loss: 0.3278 - val_acc: 0.9042\n",
      "Epoch 167/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1972 - acc: 0.9332 - val_loss: 0.3706 - val_acc: 0.9176\n",
      "Epoch 168/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1997 - acc: 0.9294 - val_loss: 0.3891 - val_acc: 0.8958\n",
      "Epoch 169/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1937 - acc: 0.9353 - val_loss: 0.3172 - val_acc: 0.9193\n",
      "Epoch 170/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1857 - acc: 0.9357 - val_loss: 0.5657 - val_acc: 0.8605\n",
      "Epoch 171/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1938 - acc: 0.9336 - val_loss: 0.3891 - val_acc: 0.9008\n",
      "Epoch 172/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1994 - acc: 0.9315 - val_loss: 0.3602 - val_acc: 0.9109\n",
      "Epoch 173/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1967 - acc: 0.9370 - val_loss: 0.3628 - val_acc: 0.8975\n",
      "Epoch 174/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1993 - acc: 0.9324 - val_loss: 0.3771 - val_acc: 0.8992\n",
      "Epoch 175/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1944 - acc: 0.9353 - val_loss: 0.3530 - val_acc: 0.9126\n",
      "Epoch 176/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1949 - acc: 0.9307 - val_loss: 0.3597 - val_acc: 0.9227\n",
      "Epoch 177/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1940 - acc: 0.9340 - val_loss: 0.3791 - val_acc: 0.8975\n",
      "Epoch 178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1957 - acc: 0.9345 - val_loss: 0.3642 - val_acc: 0.9076\n",
      "Epoch 179/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1912 - acc: 0.9315 - val_loss: 0.3531 - val_acc: 0.9092\n",
      "Epoch 180/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1930 - acc: 0.9332 - val_loss: 0.3410 - val_acc: 0.9176\n",
      "Epoch 181/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1926 - acc: 0.9328 - val_loss: 0.3690 - val_acc: 0.9042\n",
      "Epoch 182/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1926 - acc: 0.9336 - val_loss: 0.6799 - val_acc: 0.8336\n",
      "Epoch 183/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1899 - acc: 0.9366 - val_loss: 0.3932 - val_acc: 0.9109\n",
      "Epoch 184/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.2035 - acc: 0.9315 - val_loss: 0.3462 - val_acc: 0.9076\n",
      "Epoch 185/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1991 - acc: 0.9298 - val_loss: 0.3361 - val_acc: 0.9126\n",
      "Epoch 186/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1880 - acc: 0.9361 - val_loss: 0.3567 - val_acc: 0.9025\n",
      "Epoch 187/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1829 - acc: 0.9391 - val_loss: 0.3580 - val_acc: 0.9042\n",
      "Epoch 188/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1862 - acc: 0.9378 - val_loss: 0.3434 - val_acc: 0.9008\n",
      "Epoch 189/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1909 - acc: 0.9319 - val_loss: 0.3894 - val_acc: 0.8924\n",
      "Epoch 190/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1882 - acc: 0.9311 - val_loss: 0.3854 - val_acc: 0.8958\n",
      "Epoch 191/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1970 - acc: 0.9332 - val_loss: 0.5131 - val_acc: 0.8504\n",
      "Epoch 192/2000\n",
      "2380/2380 [==============================] - 0s 49us/step - loss: 0.1832 - acc: 0.9349 - val_loss: 0.4165 - val_acc: 0.8891\n",
      "Epoch 193/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1911 - acc: 0.9361 - val_loss: 0.3722 - val_acc: 0.9109\n",
      "Epoch 194/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1765 - acc: 0.9395 - val_loss: 0.3688 - val_acc: 0.9025\n",
      "Epoch 195/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1794 - acc: 0.9374 - val_loss: 0.3640 - val_acc: 0.9244\n",
      "Epoch 196/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1875 - acc: 0.9345 - val_loss: 0.3746 - val_acc: 0.8958\n",
      "Epoch 197/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1819 - acc: 0.9366 - val_loss: 0.3574 - val_acc: 0.9092\n",
      "Epoch 198/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1817 - acc: 0.9366 - val_loss: 0.8066 - val_acc: 0.8185\n",
      "Epoch 199/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1857 - acc: 0.9324 - val_loss: 0.3635 - val_acc: 0.9042\n",
      "Epoch 200/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1773 - acc: 0.9366 - val_loss: 0.4626 - val_acc: 0.8958\n",
      "Epoch 201/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1860 - acc: 0.9357 - val_loss: 0.4736 - val_acc: 0.8840\n",
      "Epoch 202/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1883 - acc: 0.9357 - val_loss: 0.4692 - val_acc: 0.8941\n",
      "Epoch 203/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1818 - acc: 0.9374 - val_loss: 0.3777 - val_acc: 0.8790\n",
      "Epoch 204/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1947 - acc: 0.9361 - val_loss: 0.4124 - val_acc: 0.9092\n",
      "Epoch 205/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1834 - acc: 0.9340 - val_loss: 0.3555 - val_acc: 0.9092\n",
      "Epoch 206/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.2008 - acc: 0.9340 - val_loss: 0.3907 - val_acc: 0.9176\n",
      "Epoch 207/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1803 - acc: 0.9408 - val_loss: 0.4150 - val_acc: 0.9025\n",
      "Epoch 208/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1813 - acc: 0.9387 - val_loss: 0.3413 - val_acc: 0.9160\n",
      "Epoch 209/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1869 - acc: 0.9391 - val_loss: 0.4279 - val_acc: 0.8924\n",
      "Epoch 210/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1872 - acc: 0.9319 - val_loss: 0.3898 - val_acc: 0.8958\n",
      "Epoch 211/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1829 - acc: 0.9340 - val_loss: 0.3867 - val_acc: 0.8975\n",
      "Epoch 212/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1888 - acc: 0.9353 - val_loss: 0.3802 - val_acc: 0.9076\n",
      "Epoch 213/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1772 - acc: 0.9399 - val_loss: 0.3715 - val_acc: 0.9076\n",
      "Epoch 214/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1910 - acc: 0.9324 - val_loss: 0.3647 - val_acc: 0.9076\n",
      "Epoch 215/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1813 - acc: 0.9391 - val_loss: 0.3504 - val_acc: 0.9160\n",
      "Epoch 216/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1800 - acc: 0.9378 - val_loss: 0.4123 - val_acc: 0.8941\n",
      "Epoch 217/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1822 - acc: 0.9357 - val_loss: 0.3398 - val_acc: 0.9176\n",
      "Epoch 218/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1780 - acc: 0.9382 - val_loss: 0.3334 - val_acc: 0.9227\n",
      "Epoch 219/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1717 - acc: 0.9479 - val_loss: 0.3325 - val_acc: 0.9261\n",
      "Epoch 220/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1823 - acc: 0.9366 - val_loss: 0.3529 - val_acc: 0.9109\n",
      "Epoch 221/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1773 - acc: 0.9357 - val_loss: 0.3756 - val_acc: 0.9210\n",
      "Epoch 222/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1762 - acc: 0.9382 - val_loss: 0.3534 - val_acc: 0.9092\n",
      "Epoch 223/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1772 - acc: 0.9340 - val_loss: 0.4062 - val_acc: 0.9042\n",
      "Epoch 224/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1937 - acc: 0.9307 - val_loss: 0.4783 - val_acc: 0.9042\n",
      "Epoch 225/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1748 - acc: 0.9391 - val_loss: 0.3440 - val_acc: 0.9143\n",
      "Epoch 226/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1729 - acc: 0.9416 - val_loss: 0.3824 - val_acc: 0.9042\n",
      "Epoch 227/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1823 - acc: 0.9387 - val_loss: 0.4585 - val_acc: 0.8941\n",
      "Epoch 228/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1807 - acc: 0.9403 - val_loss: 0.3858 - val_acc: 0.8992\n",
      "Epoch 229/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1717 - acc: 0.9403 - val_loss: 0.3473 - val_acc: 0.9160\n",
      "Epoch 230/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1751 - acc: 0.9366 - val_loss: 0.3659 - val_acc: 0.9126\n",
      "Epoch 231/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1758 - acc: 0.9412 - val_loss: 0.3729 - val_acc: 0.9076\n",
      "Epoch 232/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1833 - acc: 0.9399 - val_loss: 0.3313 - val_acc: 0.9227\n",
      "Epoch 233/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1771 - acc: 0.9370 - val_loss: 0.3376 - val_acc: 0.9311\n",
      "Epoch 234/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1757 - acc: 0.9391 - val_loss: 0.5014 - val_acc: 0.8689\n",
      "Epoch 235/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1819 - acc: 0.9345 - val_loss: 0.3375 - val_acc: 0.9277\n",
      "Epoch 236/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1713 - acc: 0.9412 - val_loss: 0.3249 - val_acc: 0.9176\n",
      "Epoch 237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1676 - acc: 0.9458 - val_loss: 0.3773 - val_acc: 0.9193\n",
      "Epoch 238/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1780 - acc: 0.9366 - val_loss: 0.3701 - val_acc: 0.9092\n",
      "Epoch 239/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1781 - acc: 0.9357 - val_loss: 0.3515 - val_acc: 0.9277\n",
      "Epoch 240/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1759 - acc: 0.9387 - val_loss: 0.4532 - val_acc: 0.8958\n",
      "Epoch 241/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1800 - acc: 0.9403 - val_loss: 0.3853 - val_acc: 0.9210\n",
      "Epoch 242/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1781 - acc: 0.9370 - val_loss: 0.4413 - val_acc: 0.9109\n",
      "Epoch 243/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1776 - acc: 0.9374 - val_loss: 0.4203 - val_acc: 0.9092\n",
      "Epoch 244/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1742 - acc: 0.9349 - val_loss: 0.3691 - val_acc: 0.9126\n",
      "Epoch 245/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1747 - acc: 0.9374 - val_loss: 0.3471 - val_acc: 0.9227\n",
      "Epoch 246/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1737 - acc: 0.9399 - val_loss: 0.3365 - val_acc: 0.9244\n",
      "Epoch 247/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1706 - acc: 0.9391 - val_loss: 0.3671 - val_acc: 0.9109\n",
      "Epoch 248/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1754 - acc: 0.9357 - val_loss: 0.3694 - val_acc: 0.9227\n",
      "Epoch 249/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1748 - acc: 0.9391 - val_loss: 0.3735 - val_acc: 0.9092\n",
      "Epoch 250/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1637 - acc: 0.9433 - val_loss: 0.3775 - val_acc: 0.9143\n",
      "Epoch 251/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1653 - acc: 0.9391 - val_loss: 0.3589 - val_acc: 0.9143\n",
      "Epoch 252/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1798 - acc: 0.9357 - val_loss: 0.3763 - val_acc: 0.9059\n",
      "Epoch 253/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1668 - acc: 0.9458 - val_loss: 0.3685 - val_acc: 0.9076\n",
      "Epoch 254/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1700 - acc: 0.9412 - val_loss: 0.3362 - val_acc: 0.9244\n",
      "Epoch 255/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1703 - acc: 0.9424 - val_loss: 0.3749 - val_acc: 0.9092\n",
      "Epoch 256/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1666 - acc: 0.9424 - val_loss: 0.3467 - val_acc: 0.9294\n",
      "Epoch 257/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1648 - acc: 0.9441 - val_loss: 0.3877 - val_acc: 0.9160\n",
      "Epoch 258/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1735 - acc: 0.9387 - val_loss: 0.3859 - val_acc: 0.9025\n",
      "Epoch 259/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1817 - acc: 0.9340 - val_loss: 0.4274 - val_acc: 0.8908\n",
      "Epoch 260/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1722 - acc: 0.9382 - val_loss: 0.4114 - val_acc: 0.9059\n",
      "Epoch 261/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1615 - acc: 0.9420 - val_loss: 0.4348 - val_acc: 0.8992\n",
      "Epoch 262/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1835 - acc: 0.9378 - val_loss: 0.5217 - val_acc: 0.8824\n",
      "Epoch 263/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1624 - acc: 0.9445 - val_loss: 0.3558 - val_acc: 0.9277\n",
      "Epoch 264/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1824 - acc: 0.9382 - val_loss: 0.3742 - val_acc: 0.9042\n",
      "Epoch 265/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1638 - acc: 0.9416 - val_loss: 0.4864 - val_acc: 0.8874\n",
      "Epoch 266/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1711 - acc: 0.9387 - val_loss: 0.3531 - val_acc: 0.9244\n",
      "Epoch 267/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1823 - acc: 0.9328 - val_loss: 0.3518 - val_acc: 0.9227\n",
      "Epoch 268/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1610 - acc: 0.9420 - val_loss: 0.3802 - val_acc: 0.9008\n",
      "Epoch 269/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1680 - acc: 0.9412 - val_loss: 0.3845 - val_acc: 0.9025\n",
      "Epoch 270/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1703 - acc: 0.9395 - val_loss: 0.3989 - val_acc: 0.9059\n",
      "Epoch 271/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1613 - acc: 0.9395 - val_loss: 0.3858 - val_acc: 0.9160\n",
      "Epoch 272/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1771 - acc: 0.9357 - val_loss: 0.3477 - val_acc: 0.9244\n",
      "Epoch 273/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1653 - acc: 0.9408 - val_loss: 0.4754 - val_acc: 0.9042\n",
      "Epoch 274/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1713 - acc: 0.9391 - val_loss: 0.4973 - val_acc: 0.8790\n",
      "Epoch 275/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1686 - acc: 0.9361 - val_loss: 0.3591 - val_acc: 0.9109\n",
      "Epoch 276/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1682 - acc: 0.9412 - val_loss: 0.4050 - val_acc: 0.9227\n",
      "Epoch 277/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1664 - acc: 0.9357 - val_loss: 0.3818 - val_acc: 0.9176\n",
      "Epoch 278/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1668 - acc: 0.9441 - val_loss: 0.3537 - val_acc: 0.9092\n",
      "Epoch 279/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1631 - acc: 0.9395 - val_loss: 0.5170 - val_acc: 0.8824\n",
      "Epoch 280/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1719 - acc: 0.9366 - val_loss: 0.3985 - val_acc: 0.9025\n",
      "Epoch 281/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1687 - acc: 0.9399 - val_loss: 0.4134 - val_acc: 0.9025\n",
      "Epoch 282/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1702 - acc: 0.9412 - val_loss: 0.3689 - val_acc: 0.9227\n",
      "Epoch 283/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1680 - acc: 0.9408 - val_loss: 0.3426 - val_acc: 0.9311\n",
      "Epoch 284/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1669 - acc: 0.9420 - val_loss: 0.3781 - val_acc: 0.9277\n",
      "Epoch 285/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1706 - acc: 0.9403 - val_loss: 0.3424 - val_acc: 0.9277\n",
      "Epoch 286/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1649 - acc: 0.9458 - val_loss: 0.3691 - val_acc: 0.9176\n",
      "Epoch 287/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1620 - acc: 0.9399 - val_loss: 0.5652 - val_acc: 0.8807\n",
      "Epoch 288/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1650 - acc: 0.9479 - val_loss: 0.3574 - val_acc: 0.9244\n",
      "Epoch 289/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1676 - acc: 0.9424 - val_loss: 0.3439 - val_acc: 0.9193\n",
      "Epoch 290/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1613 - acc: 0.9500 - val_loss: 0.3526 - val_acc: 0.9261\n",
      "Epoch 291/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1557 - acc: 0.9475 - val_loss: 0.3418 - val_acc: 0.9160\n",
      "Epoch 292/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1751 - acc: 0.9357 - val_loss: 0.4028 - val_acc: 0.9143\n",
      "Epoch 293/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1589 - acc: 0.9416 - val_loss: 0.4541 - val_acc: 0.8790\n",
      "Epoch 294/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1661 - acc: 0.9433 - val_loss: 0.4460 - val_acc: 0.8891\n",
      "Epoch 295/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1644 - acc: 0.9450 - val_loss: 0.3519 - val_acc: 0.9277\n",
      "Epoch 296/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1733 - acc: 0.9412 - val_loss: 0.3707 - val_acc: 0.9244\n",
      "Epoch 297/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1654 - acc: 0.9433 - val_loss: 0.3507 - val_acc: 0.9143\n",
      "Epoch 298/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1594 - acc: 0.9441 - val_loss: 0.3912 - val_acc: 0.9008\n",
      "Epoch 299/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1632 - acc: 0.9420 - val_loss: 0.3750 - val_acc: 0.9193\n",
      "Epoch 300/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1596 - acc: 0.9437 - val_loss: 0.4429 - val_acc: 0.8958\n",
      "Epoch 301/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1671 - acc: 0.9462 - val_loss: 0.3828 - val_acc: 0.9059\n",
      "Epoch 302/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1664 - acc: 0.9441 - val_loss: 0.4100 - val_acc: 0.9193\n",
      "Epoch 303/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1602 - acc: 0.9433 - val_loss: 0.3682 - val_acc: 0.9193\n",
      "Epoch 304/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1646 - acc: 0.9441 - val_loss: 0.3953 - val_acc: 0.9109\n",
      "Epoch 305/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1604 - acc: 0.9424 - val_loss: 0.3742 - val_acc: 0.9126\n",
      "Epoch 306/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1605 - acc: 0.9433 - val_loss: 0.4310 - val_acc: 0.8975\n",
      "Epoch 307/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1517 - acc: 0.9475 - val_loss: 0.3764 - val_acc: 0.9210\n",
      "Epoch 308/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1555 - acc: 0.9433 - val_loss: 0.3772 - val_acc: 0.9261\n",
      "Epoch 309/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1659 - acc: 0.9412 - val_loss: 0.3730 - val_acc: 0.9227\n",
      "Epoch 310/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1750 - acc: 0.9366 - val_loss: 0.3831 - val_acc: 0.9160\n",
      "Epoch 311/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1654 - acc: 0.9387 - val_loss: 0.4188 - val_acc: 0.9160\n",
      "Epoch 312/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1596 - acc: 0.9483 - val_loss: 0.4446 - val_acc: 0.8941\n",
      "Epoch 313/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1583 - acc: 0.9454 - val_loss: 0.3788 - val_acc: 0.9126\n",
      "Epoch 314/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1623 - acc: 0.9424 - val_loss: 0.4395 - val_acc: 0.8992\n",
      "Epoch 315/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1618 - acc: 0.9412 - val_loss: 0.3691 - val_acc: 0.9294\n",
      "Epoch 316/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1676 - acc: 0.9399 - val_loss: 0.3832 - val_acc: 0.9109\n",
      "Epoch 317/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1677 - acc: 0.9403 - val_loss: 0.3506 - val_acc: 0.9311\n",
      "Epoch 318/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1572 - acc: 0.9433 - val_loss: 0.4353 - val_acc: 0.8790\n",
      "Epoch 319/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1655 - acc: 0.9412 - val_loss: 0.3948 - val_acc: 0.9227\n",
      "Epoch 320/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1620 - acc: 0.9441 - val_loss: 0.4146 - val_acc: 0.9160\n",
      "Epoch 321/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1668 - acc: 0.9424 - val_loss: 0.3687 - val_acc: 0.9143\n",
      "Epoch 322/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1683 - acc: 0.9437 - val_loss: 0.3502 - val_acc: 0.9210\n",
      "Epoch 323/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1672 - acc: 0.9441 - val_loss: 0.3870 - val_acc: 0.9176\n",
      "Epoch 324/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1622 - acc: 0.9445 - val_loss: 0.4017 - val_acc: 0.9143\n",
      "Epoch 325/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1667 - acc: 0.9441 - val_loss: 0.3929 - val_acc: 0.9176\n",
      "Epoch 326/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1627 - acc: 0.9420 - val_loss: 0.4056 - val_acc: 0.9092\n",
      "Epoch 327/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1566 - acc: 0.9437 - val_loss: 0.3525 - val_acc: 0.9277\n",
      "Epoch 328/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1533 - acc: 0.9416 - val_loss: 0.3551 - val_acc: 0.9261\n",
      "Epoch 329/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1618 - acc: 0.9445 - val_loss: 0.3974 - val_acc: 0.9109\n",
      "Epoch 330/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1579 - acc: 0.9454 - val_loss: 0.3887 - val_acc: 0.9059\n",
      "Epoch 331/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1710 - acc: 0.9391 - val_loss: 0.3723 - val_acc: 0.9176\n",
      "Epoch 332/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1619 - acc: 0.9399 - val_loss: 0.3712 - val_acc: 0.9294\n",
      "Epoch 333/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1593 - acc: 0.9433 - val_loss: 0.3865 - val_acc: 0.9109\n",
      "Epoch 334/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1606 - acc: 0.9424 - val_loss: 0.4038 - val_acc: 0.9025\n",
      "Epoch 335/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1451 - acc: 0.9471 - val_loss: 0.4171 - val_acc: 0.9210\n",
      "Epoch 336/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1622 - acc: 0.9424 - val_loss: 0.3447 - val_acc: 0.9345\n",
      "Epoch 337/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1562 - acc: 0.9408 - val_loss: 0.4653 - val_acc: 0.8824\n",
      "Epoch 338/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1611 - acc: 0.9403 - val_loss: 0.3759 - val_acc: 0.9227\n",
      "Epoch 339/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1632 - acc: 0.9416 - val_loss: 0.3774 - val_acc: 0.9261\n",
      "Epoch 340/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1571 - acc: 0.9424 - val_loss: 0.6093 - val_acc: 0.8555\n",
      "Epoch 341/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1622 - acc: 0.9378 - val_loss: 0.3328 - val_acc: 0.9294\n",
      "Epoch 342/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1516 - acc: 0.9475 - val_loss: 0.4561 - val_acc: 0.9059\n",
      "Epoch 343/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1572 - acc: 0.9408 - val_loss: 0.4732 - val_acc: 0.8773\n",
      "Epoch 344/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1525 - acc: 0.9466 - val_loss: 0.4309 - val_acc: 0.8958\n",
      "Epoch 345/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1472 - acc: 0.9479 - val_loss: 0.3882 - val_acc: 0.9227\n",
      "Epoch 346/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1441 - acc: 0.9513 - val_loss: 0.3740 - val_acc: 0.9294\n",
      "Epoch 347/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1556 - acc: 0.9424 - val_loss: 0.3817 - val_acc: 0.9160\n",
      "Epoch 348/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1513 - acc: 0.9450 - val_loss: 0.5067 - val_acc: 0.8958\n",
      "Epoch 349/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1529 - acc: 0.9458 - val_loss: 0.3294 - val_acc: 0.9328\n",
      "Epoch 350/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1557 - acc: 0.9387 - val_loss: 0.4132 - val_acc: 0.9092\n",
      "Epoch 351/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1469 - acc: 0.9450 - val_loss: 0.3758 - val_acc: 0.9126\n",
      "Epoch 352/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1636 - acc: 0.9416 - val_loss: 0.3600 - val_acc: 0.9176\n",
      "Epoch 353/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1540 - acc: 0.9420 - val_loss: 0.3817 - val_acc: 0.9176\n",
      "Epoch 354/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1593 - acc: 0.9399 - val_loss: 0.3715 - val_acc: 0.9126\n",
      "Epoch 355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1530 - acc: 0.9450 - val_loss: 0.3721 - val_acc: 0.9277\n",
      "Epoch 356/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1476 - acc: 0.9462 - val_loss: 0.3453 - val_acc: 0.9311\n",
      "Epoch 357/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1521 - acc: 0.9483 - val_loss: 0.4793 - val_acc: 0.8992\n",
      "Epoch 358/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1496 - acc: 0.9508 - val_loss: 0.4772 - val_acc: 0.8924\n",
      "Epoch 359/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1550 - acc: 0.9466 - val_loss: 0.3708 - val_acc: 0.9193\n",
      "Epoch 360/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1606 - acc: 0.9450 - val_loss: 0.3962 - val_acc: 0.9092\n",
      "Epoch 361/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1459 - acc: 0.9483 - val_loss: 0.4254 - val_acc: 0.9025\n",
      "Epoch 362/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1572 - acc: 0.9424 - val_loss: 0.3948 - val_acc: 0.9193\n",
      "Epoch 363/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1477 - acc: 0.9458 - val_loss: 0.3668 - val_acc: 0.9160\n",
      "Epoch 364/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1495 - acc: 0.9458 - val_loss: 0.3940 - val_acc: 0.9244\n",
      "Epoch 365/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1513 - acc: 0.9479 - val_loss: 0.4024 - val_acc: 0.9076\n",
      "Epoch 366/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1496 - acc: 0.9454 - val_loss: 0.4224 - val_acc: 0.9059\n",
      "Epoch 367/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1534 - acc: 0.9475 - val_loss: 0.3389 - val_acc: 0.9294\n",
      "Epoch 368/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1450 - acc: 0.9450 - val_loss: 0.4050 - val_acc: 0.9193\n",
      "Epoch 369/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1542 - acc: 0.9475 - val_loss: 0.4029 - val_acc: 0.9143\n",
      "Epoch 370/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1607 - acc: 0.9450 - val_loss: 0.3776 - val_acc: 0.9143\n",
      "Epoch 371/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1416 - acc: 0.9517 - val_loss: 0.3811 - val_acc: 0.9210\n",
      "Epoch 372/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1501 - acc: 0.9471 - val_loss: 0.3715 - val_acc: 0.9160\n",
      "Epoch 373/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1449 - acc: 0.9466 - val_loss: 0.3811 - val_acc: 0.9277\n",
      "Epoch 374/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1539 - acc: 0.9483 - val_loss: 0.4222 - val_acc: 0.9261\n",
      "Epoch 375/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1461 - acc: 0.9475 - val_loss: 0.4780 - val_acc: 0.8924\n",
      "Epoch 376/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1415 - acc: 0.9496 - val_loss: 0.4021 - val_acc: 0.9294\n",
      "Epoch 377/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1489 - acc: 0.9475 - val_loss: 0.5138 - val_acc: 0.8958\n",
      "Epoch 378/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1469 - acc: 0.9496 - val_loss: 0.5180 - val_acc: 0.8756\n",
      "Epoch 379/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1510 - acc: 0.9437 - val_loss: 0.3734 - val_acc: 0.9227\n",
      "Epoch 380/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1450 - acc: 0.9454 - val_loss: 0.3700 - val_acc: 0.9143\n",
      "Epoch 381/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1459 - acc: 0.9458 - val_loss: 0.4129 - val_acc: 0.9126\n",
      "Epoch 382/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1521 - acc: 0.9437 - val_loss: 0.4382 - val_acc: 0.9143\n",
      "Epoch 383/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1447 - acc: 0.9483 - val_loss: 0.3529 - val_acc: 0.9277\n",
      "Epoch 384/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1475 - acc: 0.9441 - val_loss: 0.3965 - val_acc: 0.9244\n",
      "Epoch 385/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1530 - acc: 0.9479 - val_loss: 0.4875 - val_acc: 0.8807\n",
      "Epoch 386/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1450 - acc: 0.9458 - val_loss: 0.3942 - val_acc: 0.9092\n",
      "Epoch 387/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1436 - acc: 0.9496 - val_loss: 0.4074 - val_acc: 0.9160\n",
      "Epoch 388/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1394 - acc: 0.9492 - val_loss: 0.4558 - val_acc: 0.9160\n",
      "Epoch 389/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1482 - acc: 0.9445 - val_loss: 0.4149 - val_acc: 0.9210\n",
      "Epoch 390/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1455 - acc: 0.9504 - val_loss: 0.3800 - val_acc: 0.9277\n",
      "Epoch 391/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1546 - acc: 0.9500 - val_loss: 0.3828 - val_acc: 0.9277\n",
      "Epoch 392/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1547 - acc: 0.9479 - val_loss: 0.3929 - val_acc: 0.9227\n",
      "Epoch 393/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1453 - acc: 0.9487 - val_loss: 0.3997 - val_acc: 0.9092\n",
      "Epoch 394/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1504 - acc: 0.9437 - val_loss: 0.5319 - val_acc: 0.9025\n",
      "Epoch 395/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1468 - acc: 0.9462 - val_loss: 0.3791 - val_acc: 0.9311\n",
      "Epoch 396/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1448 - acc: 0.9462 - val_loss: 0.5010 - val_acc: 0.8992\n",
      "Epoch 397/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1489 - acc: 0.9471 - val_loss: 0.3705 - val_acc: 0.9210\n",
      "Epoch 398/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1514 - acc: 0.9475 - val_loss: 0.4089 - val_acc: 0.9126\n",
      "Epoch 399/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1382 - acc: 0.9450 - val_loss: 0.4321 - val_acc: 0.8975\n",
      "Epoch 400/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1410 - acc: 0.9466 - val_loss: 0.3867 - val_acc: 0.9176\n",
      "Epoch 401/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1401 - acc: 0.9445 - val_loss: 0.3811 - val_acc: 0.9294\n",
      "Epoch 402/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1401 - acc: 0.9441 - val_loss: 0.4056 - val_acc: 0.9176\n",
      "Epoch 403/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1521 - acc: 0.9450 - val_loss: 0.4006 - val_acc: 0.9244\n",
      "Epoch 404/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1419 - acc: 0.9475 - val_loss: 0.6081 - val_acc: 0.8487\n",
      "Epoch 405/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1486 - acc: 0.9479 - val_loss: 0.4114 - val_acc: 0.9176\n",
      "Epoch 406/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1445 - acc: 0.9433 - val_loss: 0.4144 - val_acc: 0.9210\n",
      "Epoch 407/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1411 - acc: 0.9483 - val_loss: 0.5529 - val_acc: 0.8908\n",
      "Epoch 408/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1406 - acc: 0.9496 - val_loss: 0.4616 - val_acc: 0.8924\n",
      "Epoch 409/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1410 - acc: 0.9492 - val_loss: 0.4358 - val_acc: 0.8992\n",
      "Epoch 410/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1468 - acc: 0.9454 - val_loss: 0.3927 - val_acc: 0.9244\n",
      "Epoch 411/2000\n",
      "2380/2380 [==============================] - 0s 38us/step - loss: 0.1349 - acc: 0.9525 - val_loss: 0.4303 - val_acc: 0.9109\n",
      "Epoch 412/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1412 - acc: 0.9513 - val_loss: 0.4407 - val_acc: 0.9160\n",
      "Epoch 413/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1429 - acc: 0.9483 - val_loss: 0.4380 - val_acc: 0.9008\n",
      "Epoch 414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1469 - acc: 0.9487 - val_loss: 0.4429 - val_acc: 0.9143\n",
      "Epoch 415/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1471 - acc: 0.9462 - val_loss: 0.3536 - val_acc: 0.9244\n",
      "Epoch 416/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1407 - acc: 0.9454 - val_loss: 0.4289 - val_acc: 0.9176\n",
      "Epoch 417/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1470 - acc: 0.9458 - val_loss: 0.4749 - val_acc: 0.8924\n",
      "Epoch 418/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1378 - acc: 0.9475 - val_loss: 0.4580 - val_acc: 0.8975\n",
      "Epoch 419/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1467 - acc: 0.9454 - val_loss: 0.3736 - val_acc: 0.9143\n",
      "Epoch 420/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1426 - acc: 0.9513 - val_loss: 0.3953 - val_acc: 0.9227\n",
      "Epoch 421/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1433 - acc: 0.9492 - val_loss: 0.4080 - val_acc: 0.9076\n",
      "Epoch 422/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1472 - acc: 0.9496 - val_loss: 0.4041 - val_acc: 0.9193\n",
      "Epoch 423/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1395 - acc: 0.9483 - val_loss: 0.3693 - val_acc: 0.9294\n",
      "Epoch 424/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1352 - acc: 0.9534 - val_loss: 0.3960 - val_acc: 0.9261\n",
      "Epoch 425/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1393 - acc: 0.9542 - val_loss: 0.3705 - val_acc: 0.9261\n",
      "Epoch 426/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1362 - acc: 0.9483 - val_loss: 0.4247 - val_acc: 0.9160\n",
      "Epoch 427/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1333 - acc: 0.9496 - val_loss: 0.5029 - val_acc: 0.8941\n",
      "Epoch 428/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1400 - acc: 0.9483 - val_loss: 0.4207 - val_acc: 0.9092\n",
      "Epoch 429/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1414 - acc: 0.9483 - val_loss: 0.4299 - val_acc: 0.9126\n",
      "Epoch 430/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1405 - acc: 0.9496 - val_loss: 0.4277 - val_acc: 0.9076\n",
      "Epoch 431/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1408 - acc: 0.9454 - val_loss: 0.4203 - val_acc: 0.9193\n",
      "Epoch 432/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1370 - acc: 0.9475 - val_loss: 0.4353 - val_acc: 0.9076\n",
      "Epoch 433/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1457 - acc: 0.9504 - val_loss: 0.4536 - val_acc: 0.9126\n",
      "Epoch 434/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1417 - acc: 0.9483 - val_loss: 0.4461 - val_acc: 0.8992\n",
      "Epoch 435/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1383 - acc: 0.9508 - val_loss: 0.4440 - val_acc: 0.9193\n",
      "Epoch 436/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1420 - acc: 0.9479 - val_loss: 0.3769 - val_acc: 0.9378\n",
      "Epoch 437/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1320 - acc: 0.9500 - val_loss: 0.4160 - val_acc: 0.9126\n",
      "Epoch 438/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1485 - acc: 0.9420 - val_loss: 0.3827 - val_acc: 0.9227\n",
      "Epoch 439/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1333 - acc: 0.9525 - val_loss: 0.4075 - val_acc: 0.9193\n",
      "Epoch 440/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1317 - acc: 0.9517 - val_loss: 0.5154 - val_acc: 0.9042\n",
      "Epoch 441/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1418 - acc: 0.9496 - val_loss: 0.3713 - val_acc: 0.9176\n",
      "Epoch 442/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1379 - acc: 0.9508 - val_loss: 0.4119 - val_acc: 0.9244\n",
      "Epoch 443/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1392 - acc: 0.9521 - val_loss: 0.4044 - val_acc: 0.9143\n",
      "Epoch 444/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1345 - acc: 0.9483 - val_loss: 0.4417 - val_acc: 0.9160\n",
      "Epoch 445/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1331 - acc: 0.9508 - val_loss: 0.7268 - val_acc: 0.8387\n",
      "Epoch 446/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1439 - acc: 0.9483 - val_loss: 0.4798 - val_acc: 0.8958\n",
      "Epoch 447/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1393 - acc: 0.9462 - val_loss: 0.4425 - val_acc: 0.9227\n",
      "Epoch 448/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1357 - acc: 0.9504 - val_loss: 0.4024 - val_acc: 0.9176\n",
      "Epoch 449/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1313 - acc: 0.9563 - val_loss: 0.4954 - val_acc: 0.9126\n",
      "Epoch 450/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1400 - acc: 0.9555 - val_loss: 0.5458 - val_acc: 0.8807\n",
      "Epoch 451/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1289 - acc: 0.9517 - val_loss: 0.5459 - val_acc: 0.8807\n",
      "Epoch 452/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1453 - acc: 0.9471 - val_loss: 0.4011 - val_acc: 0.9227\n",
      "Epoch 453/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1333 - acc: 0.9504 - val_loss: 0.4454 - val_acc: 0.9025\n",
      "Epoch 454/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1343 - acc: 0.9496 - val_loss: 0.4268 - val_acc: 0.9160\n",
      "Epoch 455/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1274 - acc: 0.9584 - val_loss: 0.4403 - val_acc: 0.9160\n",
      "Epoch 456/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1344 - acc: 0.9492 - val_loss: 0.4107 - val_acc: 0.9261\n",
      "Epoch 457/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1445 - acc: 0.9462 - val_loss: 0.5003 - val_acc: 0.8891\n",
      "Epoch 458/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1395 - acc: 0.9437 - val_loss: 0.4197 - val_acc: 0.9059\n",
      "Epoch 459/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1405 - acc: 0.9492 - val_loss: 0.4198 - val_acc: 0.9227\n",
      "Epoch 460/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1371 - acc: 0.9517 - val_loss: 0.4506 - val_acc: 0.9143\n",
      "Epoch 461/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1341 - acc: 0.9496 - val_loss: 0.4548 - val_acc: 0.9025\n",
      "Epoch 462/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1301 - acc: 0.9542 - val_loss: 0.3920 - val_acc: 0.9210\n",
      "Epoch 463/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1367 - acc: 0.9513 - val_loss: 0.4359 - val_acc: 0.9160\n",
      "Epoch 464/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1340 - acc: 0.9496 - val_loss: 0.4958 - val_acc: 0.8941\n",
      "Epoch 465/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1377 - acc: 0.9496 - val_loss: 0.4472 - val_acc: 0.9042\n",
      "Epoch 466/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1407 - acc: 0.9479 - val_loss: 0.4427 - val_acc: 0.9210\n",
      "Epoch 467/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1420 - acc: 0.9483 - val_loss: 0.3994 - val_acc: 0.9227\n",
      "Epoch 468/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1240 - acc: 0.9550 - val_loss: 0.4110 - val_acc: 0.9261\n",
      "Epoch 469/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1274 - acc: 0.9542 - val_loss: 0.4070 - val_acc: 0.9176\n",
      "Epoch 470/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1321 - acc: 0.9517 - val_loss: 0.4191 - val_acc: 0.9193\n",
      "Epoch 471/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1247 - acc: 0.9580 - val_loss: 0.3964 - val_acc: 0.9210\n",
      "Epoch 472/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1290 - acc: 0.9538 - val_loss: 0.4479 - val_acc: 0.9143\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1369 - acc: 0.9517 - val_loss: 0.4631 - val_acc: 0.9076\n",
      "Epoch 474/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1414 - acc: 0.9534 - val_loss: 0.4706 - val_acc: 0.9109\n",
      "Epoch 475/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1326 - acc: 0.9513 - val_loss: 0.4056 - val_acc: 0.9143\n",
      "Epoch 476/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1314 - acc: 0.9517 - val_loss: 0.4602 - val_acc: 0.9076\n",
      "Epoch 477/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1283 - acc: 0.9492 - val_loss: 0.3797 - val_acc: 0.9277\n",
      "Epoch 478/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1284 - acc: 0.9534 - val_loss: 0.4115 - val_acc: 0.9126\n",
      "Epoch 479/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1372 - acc: 0.9559 - val_loss: 0.4104 - val_acc: 0.9160\n",
      "Epoch 480/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1340 - acc: 0.9534 - val_loss: 0.5214 - val_acc: 0.8992\n",
      "Epoch 481/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1324 - acc: 0.9563 - val_loss: 0.4987 - val_acc: 0.9008\n",
      "Epoch 482/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1404 - acc: 0.9550 - val_loss: 0.4395 - val_acc: 0.9160\n",
      "Epoch 483/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1351 - acc: 0.9479 - val_loss: 0.4575 - val_acc: 0.9076\n",
      "Epoch 484/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1324 - acc: 0.9504 - val_loss: 0.5765 - val_acc: 0.8857\n",
      "Epoch 485/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1286 - acc: 0.9534 - val_loss: 0.4375 - val_acc: 0.9042\n",
      "Epoch 486/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1301 - acc: 0.9534 - val_loss: 0.5835 - val_acc: 0.8739\n",
      "Epoch 487/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1385 - acc: 0.9521 - val_loss: 0.4610 - val_acc: 0.9109\n",
      "Epoch 488/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1273 - acc: 0.9559 - val_loss: 0.5387 - val_acc: 0.8824\n",
      "Epoch 489/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1229 - acc: 0.9542 - val_loss: 0.4185 - val_acc: 0.9143\n",
      "Epoch 490/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1432 - acc: 0.9513 - val_loss: 0.4553 - val_acc: 0.8975\n",
      "Epoch 491/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1270 - acc: 0.9525 - val_loss: 0.4154 - val_acc: 0.9109\n",
      "Epoch 492/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1260 - acc: 0.9521 - val_loss: 0.4291 - val_acc: 0.9193\n",
      "Epoch 493/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1311 - acc: 0.9508 - val_loss: 0.4607 - val_acc: 0.9126\n",
      "Epoch 494/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1255 - acc: 0.9538 - val_loss: 0.4694 - val_acc: 0.9109\n",
      "Epoch 495/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1296 - acc: 0.9525 - val_loss: 0.4267 - val_acc: 0.9126\n",
      "Epoch 496/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1252 - acc: 0.9576 - val_loss: 0.4553 - val_acc: 0.9042\n",
      "Epoch 497/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1252 - acc: 0.9584 - val_loss: 0.4478 - val_acc: 0.9176\n",
      "Epoch 498/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1258 - acc: 0.9555 - val_loss: 0.4288 - val_acc: 0.9092\n",
      "Epoch 499/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1339 - acc: 0.9513 - val_loss: 0.4646 - val_acc: 0.9076\n",
      "Epoch 500/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1478 - acc: 0.9513 - val_loss: 0.4070 - val_acc: 0.9193\n",
      "Epoch 501/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1355 - acc: 0.9517 - val_loss: 0.4633 - val_acc: 0.9092\n",
      "Epoch 502/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1425 - acc: 0.9513 - val_loss: 0.4582 - val_acc: 0.9076\n",
      "Epoch 503/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1272 - acc: 0.9508 - val_loss: 0.5059 - val_acc: 0.8891\n",
      "Epoch 504/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1182 - acc: 0.9571 - val_loss: 0.4163 - val_acc: 0.9210\n",
      "Epoch 505/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1297 - acc: 0.9559 - val_loss: 0.5068 - val_acc: 0.9008\n",
      "Epoch 506/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1277 - acc: 0.9571 - val_loss: 0.4624 - val_acc: 0.9126\n",
      "Epoch 507/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1306 - acc: 0.9517 - val_loss: 0.4529 - val_acc: 0.9193\n",
      "Epoch 508/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1289 - acc: 0.9559 - val_loss: 0.4369 - val_acc: 0.9143\n",
      "Epoch 509/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1358 - acc: 0.9475 - val_loss: 0.5234 - val_acc: 0.9176\n",
      "Epoch 510/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1260 - acc: 0.9571 - val_loss: 0.4493 - val_acc: 0.8958\n",
      "Epoch 511/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1311 - acc: 0.9500 - val_loss: 0.5351 - val_acc: 0.8941\n",
      "Epoch 512/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1383 - acc: 0.9521 - val_loss: 0.5830 - val_acc: 0.8891\n",
      "Epoch 513/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1200 - acc: 0.9576 - val_loss: 0.4260 - val_acc: 0.9261\n",
      "Epoch 514/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1266 - acc: 0.9546 - val_loss: 0.4303 - val_acc: 0.9143\n",
      "Epoch 515/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1250 - acc: 0.9580 - val_loss: 0.4952 - val_acc: 0.9076\n",
      "Epoch 516/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1357 - acc: 0.9513 - val_loss: 0.4368 - val_acc: 0.9042\n",
      "Epoch 517/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1299 - acc: 0.9517 - val_loss: 0.4142 - val_acc: 0.9193\n",
      "Epoch 518/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1359 - acc: 0.9483 - val_loss: 0.3889 - val_acc: 0.9328\n",
      "Epoch 519/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1348 - acc: 0.9534 - val_loss: 0.5299 - val_acc: 0.9042\n",
      "Epoch 520/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1340 - acc: 0.9517 - val_loss: 0.4375 - val_acc: 0.9193\n",
      "Epoch 521/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1233 - acc: 0.9542 - val_loss: 0.5149 - val_acc: 0.8924\n",
      "Epoch 522/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1303 - acc: 0.9550 - val_loss: 0.4048 - val_acc: 0.9160\n",
      "Epoch 523/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1220 - acc: 0.9538 - val_loss: 0.4712 - val_acc: 0.9059\n",
      "Epoch 524/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1217 - acc: 0.9567 - val_loss: 0.4103 - val_acc: 0.9210\n",
      "Epoch 525/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1278 - acc: 0.9542 - val_loss: 0.4020 - val_acc: 0.9277\n",
      "Epoch 526/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1268 - acc: 0.9529 - val_loss: 0.5145 - val_acc: 0.9025\n",
      "Epoch 527/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1242 - acc: 0.9542 - val_loss: 0.4155 - val_acc: 0.9143\n",
      "Epoch 528/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1205 - acc: 0.9546 - val_loss: 0.4427 - val_acc: 0.9143\n",
      "Epoch 529/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1307 - acc: 0.9550 - val_loss: 0.4576 - val_acc: 0.9143\n",
      "Epoch 530/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1320 - acc: 0.9538 - val_loss: 0.4833 - val_acc: 0.9042\n",
      "Epoch 531/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1262 - acc: 0.9529 - val_loss: 0.4446 - val_acc: 0.9193\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1319 - acc: 0.9521 - val_loss: 0.4464 - val_acc: 0.9126\n",
      "Epoch 533/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1134 - acc: 0.9538 - val_loss: 0.5144 - val_acc: 0.9076\n",
      "Epoch 534/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1276 - acc: 0.9546 - val_loss: 0.4512 - val_acc: 0.9176\n",
      "Epoch 535/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1263 - acc: 0.9597 - val_loss: 1.4744 - val_acc: 0.7950\n",
      "Epoch 536/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1333 - acc: 0.9567 - val_loss: 0.5551 - val_acc: 0.8908\n",
      "Epoch 537/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1172 - acc: 0.9576 - val_loss: 0.4421 - val_acc: 0.9210\n",
      "Epoch 538/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1205 - acc: 0.9563 - val_loss: 0.4652 - val_acc: 0.9109\n",
      "Epoch 539/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1234 - acc: 0.9559 - val_loss: 0.4230 - val_acc: 0.9210\n",
      "Epoch 540/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1277 - acc: 0.9504 - val_loss: 0.5235 - val_acc: 0.9008\n",
      "Epoch 541/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1361 - acc: 0.9534 - val_loss: 0.4481 - val_acc: 0.9176\n",
      "Epoch 542/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1192 - acc: 0.9550 - val_loss: 0.4412 - val_acc: 0.9143\n",
      "Epoch 543/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1251 - acc: 0.9517 - val_loss: 0.4460 - val_acc: 0.9227\n",
      "Epoch 544/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1228 - acc: 0.9601 - val_loss: 0.4605 - val_acc: 0.9126\n",
      "Epoch 545/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1221 - acc: 0.9550 - val_loss: 0.4263 - val_acc: 0.9126\n",
      "Epoch 546/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1134 - acc: 0.9580 - val_loss: 0.5424 - val_acc: 0.9109\n",
      "Epoch 547/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1342 - acc: 0.9513 - val_loss: 0.4779 - val_acc: 0.9210\n",
      "Epoch 548/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1260 - acc: 0.9550 - val_loss: 0.4281 - val_acc: 0.9143\n",
      "Epoch 549/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1166 - acc: 0.9588 - val_loss: 0.4555 - val_acc: 0.9143\n",
      "Epoch 550/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1207 - acc: 0.9597 - val_loss: 0.4683 - val_acc: 0.9143\n",
      "Epoch 551/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1254 - acc: 0.9555 - val_loss: 0.4795 - val_acc: 0.8958\n",
      "Epoch 552/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1294 - acc: 0.9563 - val_loss: 0.4475 - val_acc: 0.9042\n",
      "Epoch 553/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1199 - acc: 0.9546 - val_loss: 0.4309 - val_acc: 0.9176\n",
      "Epoch 554/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1183 - acc: 0.9546 - val_loss: 0.4436 - val_acc: 0.9210\n",
      "Epoch 555/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1247 - acc: 0.9538 - val_loss: 0.4556 - val_acc: 0.9210\n",
      "Epoch 556/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1238 - acc: 0.9555 - val_loss: 0.4698 - val_acc: 0.9109\n",
      "Epoch 557/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1255 - acc: 0.9571 - val_loss: 0.4541 - val_acc: 0.9109\n",
      "Epoch 558/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1312 - acc: 0.9529 - val_loss: 0.4552 - val_acc: 0.9092\n",
      "Epoch 559/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1257 - acc: 0.9571 - val_loss: 0.4312 - val_acc: 0.9092\n",
      "Epoch 560/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1231 - acc: 0.9580 - val_loss: 0.4937 - val_acc: 0.9092\n",
      "Epoch 561/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1249 - acc: 0.9555 - val_loss: 0.4284 - val_acc: 0.9244\n",
      "Epoch 562/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1214 - acc: 0.9555 - val_loss: 0.4966 - val_acc: 0.9092\n",
      "Epoch 563/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1234 - acc: 0.9529 - val_loss: 0.4412 - val_acc: 0.9210\n",
      "Epoch 564/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1255 - acc: 0.9559 - val_loss: 0.4861 - val_acc: 0.9143\n",
      "Epoch 565/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1344 - acc: 0.9534 - val_loss: 0.4884 - val_acc: 0.9076\n",
      "Epoch 566/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1218 - acc: 0.9576 - val_loss: 0.4914 - val_acc: 0.9143\n",
      "Epoch 567/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1191 - acc: 0.9567 - val_loss: 0.4519 - val_acc: 0.9160\n",
      "Epoch 568/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1316 - acc: 0.9521 - val_loss: 0.5028 - val_acc: 0.9059\n",
      "Epoch 569/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1172 - acc: 0.9576 - val_loss: 0.4939 - val_acc: 0.9076\n",
      "Epoch 570/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1396 - acc: 0.9504 - val_loss: 0.4581 - val_acc: 0.9059\n",
      "Epoch 571/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1172 - acc: 0.9588 - val_loss: 0.4683 - val_acc: 0.9059\n",
      "Epoch 572/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1272 - acc: 0.9555 - val_loss: 0.4491 - val_acc: 0.9193\n",
      "Epoch 573/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1246 - acc: 0.9504 - val_loss: 0.4667 - val_acc: 0.9176\n",
      "Epoch 574/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1291 - acc: 0.9521 - val_loss: 0.4268 - val_acc: 0.9193\n",
      "Epoch 575/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1190 - acc: 0.9555 - val_loss: 0.5098 - val_acc: 0.9143\n",
      "Epoch 576/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1321 - acc: 0.9517 - val_loss: 0.4851 - val_acc: 0.9143\n",
      "Epoch 577/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1173 - acc: 0.9555 - val_loss: 0.5110 - val_acc: 0.9076\n",
      "Epoch 578/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1184 - acc: 0.9567 - val_loss: 0.4529 - val_acc: 0.9261\n",
      "Epoch 579/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1346 - acc: 0.9546 - val_loss: 0.5345 - val_acc: 0.8992\n",
      "Epoch 580/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1260 - acc: 0.9521 - val_loss: 0.5050 - val_acc: 0.9210\n",
      "Epoch 581/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1215 - acc: 0.9542 - val_loss: 0.4746 - val_acc: 0.9092\n",
      "Epoch 582/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1218 - acc: 0.9576 - val_loss: 0.4433 - val_acc: 0.9126\n",
      "Epoch 583/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1226 - acc: 0.9546 - val_loss: 0.4669 - val_acc: 0.9176\n",
      "Epoch 584/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1219 - acc: 0.9588 - val_loss: 0.5208 - val_acc: 0.9076\n",
      "Epoch 585/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1300 - acc: 0.9521 - val_loss: 0.4608 - val_acc: 0.9227\n",
      "Epoch 586/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1188 - acc: 0.9597 - val_loss: 0.4504 - val_acc: 0.9109\n",
      "Epoch 587/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1154 - acc: 0.9584 - val_loss: 0.4441 - val_acc: 0.9244\n",
      "Epoch 588/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1211 - acc: 0.9550 - val_loss: 0.4208 - val_acc: 0.9210\n",
      "Epoch 589/2000\n",
      "2380/2380 [==============================] - 0s 38us/step - loss: 0.1263 - acc: 0.9517 - val_loss: 0.5320 - val_acc: 0.9193\n",
      "Epoch 590/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1167 - acc: 0.9588 - val_loss: 0.5216 - val_acc: 0.8941\n",
      "Epoch 591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1269 - acc: 0.9529 - val_loss: 0.4505 - val_acc: 0.9143\n",
      "Epoch 592/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1201 - acc: 0.9605 - val_loss: 0.5382 - val_acc: 0.8992\n",
      "Epoch 593/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1172 - acc: 0.9563 - val_loss: 0.5564 - val_acc: 0.9025\n",
      "Epoch 594/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1199 - acc: 0.9584 - val_loss: 0.6700 - val_acc: 0.8807\n",
      "Epoch 595/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1142 - acc: 0.9613 - val_loss: 0.4486 - val_acc: 0.9143\n",
      "Epoch 596/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1226 - acc: 0.9546 - val_loss: 0.5181 - val_acc: 0.8958\n",
      "Epoch 597/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1169 - acc: 0.9576 - val_loss: 0.5090 - val_acc: 0.9126\n",
      "Epoch 598/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1219 - acc: 0.9550 - val_loss: 0.4434 - val_acc: 0.9126\n",
      "Epoch 599/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1209 - acc: 0.9571 - val_loss: 0.5282 - val_acc: 0.9076\n",
      "Epoch 600/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1221 - acc: 0.9584 - val_loss: 0.4984 - val_acc: 0.9025\n",
      "Epoch 601/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1215 - acc: 0.9597 - val_loss: 0.5010 - val_acc: 0.9059\n",
      "Epoch 602/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1334 - acc: 0.9525 - val_loss: 0.5012 - val_acc: 0.9126\n",
      "Epoch 603/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1076 - acc: 0.9618 - val_loss: 0.5185 - val_acc: 0.8908\n",
      "Epoch 604/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1138 - acc: 0.9555 - val_loss: 0.6265 - val_acc: 0.8941\n",
      "Epoch 605/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1234 - acc: 0.9567 - val_loss: 0.4850 - val_acc: 0.9176\n",
      "Epoch 606/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1124 - acc: 0.9567 - val_loss: 0.4415 - val_acc: 0.9244\n",
      "Epoch 607/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1205 - acc: 0.9534 - val_loss: 0.5014 - val_acc: 0.9143\n",
      "Epoch 608/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1162 - acc: 0.9567 - val_loss: 0.4646 - val_acc: 0.9176\n",
      "Epoch 609/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1212 - acc: 0.9567 - val_loss: 0.4579 - val_acc: 0.9227\n",
      "Epoch 610/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1139 - acc: 0.9588 - val_loss: 0.4655 - val_acc: 0.9193\n",
      "Epoch 611/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1175 - acc: 0.9588 - val_loss: 0.4442 - val_acc: 0.9193\n",
      "Epoch 612/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1142 - acc: 0.9580 - val_loss: 0.4647 - val_acc: 0.9092\n",
      "Epoch 613/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1280 - acc: 0.9534 - val_loss: 0.5980 - val_acc: 0.8840\n",
      "Epoch 614/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1283 - acc: 0.9563 - val_loss: 0.4804 - val_acc: 0.9092\n",
      "Epoch 615/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1113 - acc: 0.9571 - val_loss: 0.4894 - val_acc: 0.9092\n",
      "Epoch 616/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1132 - acc: 0.9576 - val_loss: 0.5310 - val_acc: 0.9076\n",
      "Epoch 617/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1245 - acc: 0.9567 - val_loss: 0.4460 - val_acc: 0.9126\n",
      "Epoch 618/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1163 - acc: 0.9613 - val_loss: 0.4738 - val_acc: 0.9126\n",
      "Epoch 619/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1269 - acc: 0.9580 - val_loss: 0.4617 - val_acc: 0.9176\n",
      "Epoch 620/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1130 - acc: 0.9584 - val_loss: 0.5266 - val_acc: 0.9042\n",
      "Epoch 621/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1344 - acc: 0.9521 - val_loss: 0.6638 - val_acc: 0.8840\n",
      "Epoch 622/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1203 - acc: 0.9567 - val_loss: 0.5710 - val_acc: 0.8975\n",
      "Epoch 623/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1230 - acc: 0.9534 - val_loss: 0.4656 - val_acc: 0.9059\n",
      "Epoch 624/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1317 - acc: 0.9521 - val_loss: 0.4646 - val_acc: 0.9176\n",
      "Epoch 625/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1160 - acc: 0.9605 - val_loss: 0.4674 - val_acc: 0.9193\n",
      "Epoch 626/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1179 - acc: 0.9584 - val_loss: 0.4790 - val_acc: 0.9126\n",
      "Epoch 627/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1146 - acc: 0.9576 - val_loss: 0.5786 - val_acc: 0.9025\n",
      "Epoch 628/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1225 - acc: 0.9546 - val_loss: 0.5456 - val_acc: 0.9008\n",
      "Epoch 629/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1234 - acc: 0.9592 - val_loss: 0.5137 - val_acc: 0.9143\n",
      "Epoch 630/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1238 - acc: 0.9563 - val_loss: 0.4452 - val_acc: 0.9126\n",
      "Epoch 631/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1185 - acc: 0.9588 - val_loss: 0.4915 - val_acc: 0.8992\n",
      "Epoch 632/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1208 - acc: 0.9592 - val_loss: 0.4709 - val_acc: 0.9193\n",
      "Epoch 633/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1151 - acc: 0.9597 - val_loss: 0.5956 - val_acc: 0.8975\n",
      "Epoch 634/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1228 - acc: 0.9546 - val_loss: 0.5083 - val_acc: 0.9126\n",
      "Epoch 635/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1075 - acc: 0.9601 - val_loss: 0.5114 - val_acc: 0.9092\n",
      "Epoch 636/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1209 - acc: 0.9542 - val_loss: 0.5456 - val_acc: 0.8992\n",
      "Epoch 637/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1242 - acc: 0.9563 - val_loss: 0.4511 - val_acc: 0.9193\n",
      "Epoch 638/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1083 - acc: 0.9588 - val_loss: 0.6021 - val_acc: 0.8874\n",
      "Epoch 639/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1275 - acc: 0.9517 - val_loss: 0.5167 - val_acc: 0.9008\n",
      "Epoch 640/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1083 - acc: 0.9609 - val_loss: 0.5450 - val_acc: 0.8958\n",
      "Epoch 641/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1191 - acc: 0.9550 - val_loss: 0.6966 - val_acc: 0.8790\n",
      "Epoch 642/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1192 - acc: 0.9567 - val_loss: 0.5099 - val_acc: 0.8975\n",
      "Epoch 643/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1237 - acc: 0.9609 - val_loss: 0.4499 - val_acc: 0.9059\n",
      "Epoch 644/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1110 - acc: 0.9567 - val_loss: 0.5730 - val_acc: 0.8958\n",
      "Epoch 645/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1206 - acc: 0.9513 - val_loss: 0.5063 - val_acc: 0.9126\n",
      "Epoch 646/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1189 - acc: 0.9584 - val_loss: 0.5164 - val_acc: 0.9059\n",
      "Epoch 647/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1186 - acc: 0.9571 - val_loss: 0.4852 - val_acc: 0.9008\n",
      "Epoch 648/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1283 - acc: 0.9580 - val_loss: 0.4665 - val_acc: 0.9109\n",
      "Epoch 649/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1243 - acc: 0.9538 - val_loss: 0.5104 - val_acc: 0.9059\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1155 - acc: 0.9567 - val_loss: 0.4453 - val_acc: 0.9143\n",
      "Epoch 651/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1063 - acc: 0.9634 - val_loss: 0.4842 - val_acc: 0.9210\n",
      "Epoch 652/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1112 - acc: 0.9580 - val_loss: 0.4755 - val_acc: 0.9176\n",
      "Epoch 653/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1090 - acc: 0.9626 - val_loss: 0.4957 - val_acc: 0.9025\n",
      "Epoch 654/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1211 - acc: 0.9538 - val_loss: 0.5517 - val_acc: 0.9143\n",
      "Epoch 655/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1209 - acc: 0.9567 - val_loss: 0.4820 - val_acc: 0.9193\n",
      "Epoch 656/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1118 - acc: 0.9580 - val_loss: 0.4722 - val_acc: 0.9176\n",
      "Epoch 657/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1150 - acc: 0.9542 - val_loss: 0.5238 - val_acc: 0.9059\n",
      "Epoch 658/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1202 - acc: 0.9567 - val_loss: 0.5166 - val_acc: 0.9176\n",
      "Epoch 659/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1137 - acc: 0.9559 - val_loss: 0.4715 - val_acc: 0.9193\n",
      "Epoch 660/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1182 - acc: 0.9601 - val_loss: 0.4838 - val_acc: 0.9160\n",
      "Epoch 661/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1239 - acc: 0.9563 - val_loss: 0.4968 - val_acc: 0.9193\n",
      "Epoch 662/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1214 - acc: 0.9550 - val_loss: 0.4930 - val_acc: 0.9092\n",
      "Epoch 663/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1143 - acc: 0.9567 - val_loss: 0.5442 - val_acc: 0.8975\n",
      "Epoch 664/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1220 - acc: 0.9513 - val_loss: 0.5383 - val_acc: 0.9008\n",
      "Epoch 665/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1163 - acc: 0.9601 - val_loss: 0.4924 - val_acc: 0.9193\n",
      "Epoch 666/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1141 - acc: 0.9626 - val_loss: 0.5085 - val_acc: 0.8958\n",
      "Epoch 667/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1251 - acc: 0.9521 - val_loss: 0.4733 - val_acc: 0.9143\n",
      "Epoch 668/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1239 - acc: 0.9584 - val_loss: 0.4765 - val_acc: 0.9193\n",
      "Epoch 669/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1166 - acc: 0.9580 - val_loss: 0.5015 - val_acc: 0.9092\n",
      "Epoch 670/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1110 - acc: 0.9592 - val_loss: 0.4919 - val_acc: 0.9143\n",
      "Epoch 671/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1218 - acc: 0.9546 - val_loss: 0.5080 - val_acc: 0.9143\n",
      "Epoch 672/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1210 - acc: 0.9559 - val_loss: 0.4814 - val_acc: 0.9143\n",
      "Epoch 673/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1148 - acc: 0.9592 - val_loss: 0.5249 - val_acc: 0.9126\n",
      "Epoch 674/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1162 - acc: 0.9597 - val_loss: 0.4686 - val_acc: 0.9143\n",
      "Epoch 675/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1206 - acc: 0.9567 - val_loss: 0.5105 - val_acc: 0.9109\n",
      "Epoch 676/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1255 - acc: 0.9550 - val_loss: 0.4628 - val_acc: 0.9025\n",
      "Epoch 677/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1245 - acc: 0.9567 - val_loss: 0.5321 - val_acc: 0.9008\n",
      "Epoch 678/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1137 - acc: 0.9563 - val_loss: 0.7104 - val_acc: 0.8756\n",
      "Epoch 679/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1213 - acc: 0.9563 - val_loss: 0.5024 - val_acc: 0.9008\n",
      "Epoch 680/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1243 - acc: 0.9559 - val_loss: 0.5500 - val_acc: 0.9227\n",
      "Epoch 681/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1152 - acc: 0.9588 - val_loss: 0.5308 - val_acc: 0.9076\n",
      "Epoch 682/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1063 - acc: 0.9584 - val_loss: 0.5259 - val_acc: 0.9025\n",
      "Epoch 683/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1225 - acc: 0.9550 - val_loss: 0.4699 - val_acc: 0.9193\n",
      "Epoch 684/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1099 - acc: 0.9609 - val_loss: 0.4633 - val_acc: 0.9193\n",
      "Epoch 685/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1109 - acc: 0.9613 - val_loss: 0.4490 - val_acc: 0.9109\n",
      "Epoch 686/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1149 - acc: 0.9592 - val_loss: 0.5422 - val_acc: 0.9109\n",
      "Epoch 687/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1237 - acc: 0.9542 - val_loss: 0.4756 - val_acc: 0.9210\n",
      "Epoch 688/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1190 - acc: 0.9563 - val_loss: 0.5538 - val_acc: 0.8874\n",
      "Epoch 689/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1217 - acc: 0.9550 - val_loss: 0.4976 - val_acc: 0.9059\n",
      "Epoch 690/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1147 - acc: 0.9571 - val_loss: 0.4908 - val_acc: 0.9143\n",
      "Epoch 691/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1080 - acc: 0.9626 - val_loss: 0.4624 - val_acc: 0.9193\n",
      "Epoch 692/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1056 - acc: 0.9605 - val_loss: 0.5075 - val_acc: 0.9126\n",
      "Epoch 693/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1173 - acc: 0.9634 - val_loss: 0.5024 - val_acc: 0.9076\n",
      "Epoch 694/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1234 - acc: 0.9517 - val_loss: 0.4600 - val_acc: 0.9244\n",
      "Epoch 695/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1320 - acc: 0.9525 - val_loss: 0.5234 - val_acc: 0.9160\n",
      "Epoch 696/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1205 - acc: 0.9576 - val_loss: 0.5780 - val_acc: 0.8975\n",
      "Epoch 697/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1206 - acc: 0.9580 - val_loss: 0.4420 - val_acc: 0.9227\n",
      "Epoch 698/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1222 - acc: 0.9626 - val_loss: 0.5098 - val_acc: 0.9092\n",
      "Epoch 699/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1137 - acc: 0.9584 - val_loss: 0.4625 - val_acc: 0.9210\n",
      "Epoch 700/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1082 - acc: 0.9626 - val_loss: 0.4513 - val_acc: 0.9193\n",
      "Epoch 701/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1155 - acc: 0.9597 - val_loss: 0.5832 - val_acc: 0.8992\n",
      "Epoch 702/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1166 - acc: 0.9601 - val_loss: 0.5009 - val_acc: 0.9160\n",
      "Epoch 703/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1144 - acc: 0.9588 - val_loss: 0.4948 - val_acc: 0.9210\n",
      "Epoch 704/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1122 - acc: 0.9588 - val_loss: 0.4933 - val_acc: 0.9109\n",
      "Epoch 705/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1146 - acc: 0.9584 - val_loss: 0.4641 - val_acc: 0.9143\n",
      "Epoch 706/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1116 - acc: 0.9576 - val_loss: 0.5011 - val_acc: 0.9160\n",
      "Epoch 707/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1229 - acc: 0.9550 - val_loss: 0.5894 - val_acc: 0.9076\n",
      "Epoch 708/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1184 - acc: 0.9567 - val_loss: 0.4507 - val_acc: 0.9193\n",
      "Epoch 709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1150 - acc: 0.9609 - val_loss: 0.5282 - val_acc: 0.9126\n",
      "Epoch 710/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1101 - acc: 0.9639 - val_loss: 0.5315 - val_acc: 0.9143\n",
      "Epoch 711/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1307 - acc: 0.9550 - val_loss: 0.4889 - val_acc: 0.9210\n",
      "Epoch 712/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1236 - acc: 0.9546 - val_loss: 0.4600 - val_acc: 0.9277\n",
      "Epoch 713/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1221 - acc: 0.9546 - val_loss: 0.4938 - val_acc: 0.9160\n",
      "Epoch 714/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1158 - acc: 0.9609 - val_loss: 0.5254 - val_acc: 0.9210\n",
      "Epoch 715/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1080 - acc: 0.9601 - val_loss: 0.4591 - val_acc: 0.9294\n",
      "Epoch 716/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1171 - acc: 0.9626 - val_loss: 0.4953 - val_acc: 0.9176\n",
      "Epoch 717/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1130 - acc: 0.9613 - val_loss: 0.4979 - val_acc: 0.9193\n",
      "Epoch 718/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1176 - acc: 0.9559 - val_loss: 0.5329 - val_acc: 0.8975\n",
      "Epoch 719/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1195 - acc: 0.9567 - val_loss: 0.5038 - val_acc: 0.9042\n",
      "Epoch 720/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1156 - acc: 0.9542 - val_loss: 0.4728 - val_acc: 0.9227\n",
      "Epoch 721/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1211 - acc: 0.9588 - val_loss: 0.5036 - val_acc: 0.9076\n",
      "Epoch 722/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1175 - acc: 0.9588 - val_loss: 0.5488 - val_acc: 0.8975\n",
      "Epoch 723/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1142 - acc: 0.9626 - val_loss: 0.4943 - val_acc: 0.9277\n",
      "Epoch 724/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1174 - acc: 0.9609 - val_loss: 0.4731 - val_acc: 0.9076\n",
      "Epoch 725/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1082 - acc: 0.9618 - val_loss: 0.5946 - val_acc: 0.9025\n",
      "Epoch 726/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1132 - acc: 0.9592 - val_loss: 0.5479 - val_acc: 0.9143\n",
      "Epoch 727/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1207 - acc: 0.9529 - val_loss: 0.5203 - val_acc: 0.9126\n",
      "Epoch 728/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1110 - acc: 0.9576 - val_loss: 0.5308 - val_acc: 0.9092\n",
      "Epoch 729/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1220 - acc: 0.9529 - val_loss: 0.4677 - val_acc: 0.9176\n",
      "Epoch 730/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1137 - acc: 0.9605 - val_loss: 0.5193 - val_acc: 0.9160\n",
      "Epoch 731/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1129 - acc: 0.9605 - val_loss: 0.4994 - val_acc: 0.9143\n",
      "Epoch 732/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1131 - acc: 0.9576 - val_loss: 0.5716 - val_acc: 0.9025\n",
      "Epoch 733/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1165 - acc: 0.9618 - val_loss: 0.5025 - val_acc: 0.9227\n",
      "Epoch 734/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1143 - acc: 0.9601 - val_loss: 0.5031 - val_acc: 0.9025\n",
      "Epoch 735/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1279 - acc: 0.9542 - val_loss: 0.5200 - val_acc: 0.9025\n",
      "Epoch 736/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1180 - acc: 0.9592 - val_loss: 0.4661 - val_acc: 0.9193\n",
      "Epoch 737/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1139 - acc: 0.9613 - val_loss: 0.4681 - val_acc: 0.9210\n",
      "Epoch 738/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1094 - acc: 0.9630 - val_loss: 0.6023 - val_acc: 0.8975\n",
      "Epoch 739/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1099 - acc: 0.9580 - val_loss: 0.5717 - val_acc: 0.8992\n",
      "Epoch 740/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1211 - acc: 0.9534 - val_loss: 0.5060 - val_acc: 0.9059\n",
      "Epoch 741/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1146 - acc: 0.9559 - val_loss: 0.5001 - val_acc: 0.9109\n",
      "Epoch 742/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1147 - acc: 0.9622 - val_loss: 0.5296 - val_acc: 0.9059\n",
      "Epoch 743/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1270 - acc: 0.9513 - val_loss: 0.5647 - val_acc: 0.9109\n",
      "Epoch 744/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1103 - acc: 0.9542 - val_loss: 0.6025 - val_acc: 0.9042\n",
      "Epoch 745/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1063 - acc: 0.9592 - val_loss: 0.5179 - val_acc: 0.9143\n",
      "Epoch 746/2000\n",
      "2380/2380 [==============================] - 0s 38us/step - loss: 0.1191 - acc: 0.9613 - val_loss: 0.4908 - val_acc: 0.9210\n",
      "Epoch 747/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1079 - acc: 0.9580 - val_loss: 0.5069 - val_acc: 0.9176\n",
      "Epoch 748/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1198 - acc: 0.9576 - val_loss: 0.5085 - val_acc: 0.9160\n",
      "Epoch 749/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1133 - acc: 0.9576 - val_loss: 0.4880 - val_acc: 0.9261\n",
      "Epoch 750/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1096 - acc: 0.9609 - val_loss: 0.5093 - val_acc: 0.9160\n",
      "Epoch 751/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1092 - acc: 0.9571 - val_loss: 0.5006 - val_acc: 0.9143\n",
      "Epoch 752/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1126 - acc: 0.9563 - val_loss: 0.4656 - val_acc: 0.9109\n",
      "Epoch 753/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1185 - acc: 0.9605 - val_loss: 0.5573 - val_acc: 0.8874\n",
      "Epoch 754/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1156 - acc: 0.9580 - val_loss: 0.5123 - val_acc: 0.9244\n",
      "Epoch 755/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1095 - acc: 0.9613 - val_loss: 0.5208 - val_acc: 0.8992\n",
      "Epoch 756/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1136 - acc: 0.9592 - val_loss: 0.4990 - val_acc: 0.9176\n",
      "Epoch 757/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1228 - acc: 0.9563 - val_loss: 0.5033 - val_acc: 0.9109\n",
      "Epoch 758/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1126 - acc: 0.9601 - val_loss: 0.5406 - val_acc: 0.9143\n",
      "Epoch 759/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1120 - acc: 0.9601 - val_loss: 0.6428 - val_acc: 0.8857\n",
      "Epoch 760/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1188 - acc: 0.9576 - val_loss: 0.4556 - val_acc: 0.9311\n",
      "Epoch 761/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1096 - acc: 0.9597 - val_loss: 0.5075 - val_acc: 0.9143\n",
      "Epoch 762/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1171 - acc: 0.9609 - val_loss: 0.4880 - val_acc: 0.9277\n",
      "Epoch 763/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1085 - acc: 0.9609 - val_loss: 0.4938 - val_acc: 0.9143\n",
      "Epoch 764/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1143 - acc: 0.9576 - val_loss: 0.4823 - val_acc: 0.9244\n",
      "Epoch 765/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0964 - acc: 0.9626 - val_loss: 0.5312 - val_acc: 0.9059\n",
      "Epoch 766/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1099 - acc: 0.9622 - val_loss: 0.5425 - val_acc: 0.8941\n",
      "Epoch 767/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1138 - acc: 0.9567 - val_loss: 0.5104 - val_acc: 0.8975\n",
      "Epoch 768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1177 - acc: 0.9588 - val_loss: 0.5369 - val_acc: 0.9176\n",
      "Epoch 769/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1083 - acc: 0.9630 - val_loss: 0.5329 - val_acc: 0.9126\n",
      "Epoch 770/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1109 - acc: 0.9588 - val_loss: 0.5352 - val_acc: 0.9244\n",
      "Epoch 771/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1133 - acc: 0.9592 - val_loss: 0.5489 - val_acc: 0.9143\n",
      "Epoch 772/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1041 - acc: 0.9613 - val_loss: 0.6005 - val_acc: 0.9042\n",
      "Epoch 773/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1109 - acc: 0.9601 - val_loss: 0.5185 - val_acc: 0.9143\n",
      "Epoch 774/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1253 - acc: 0.9601 - val_loss: 0.5078 - val_acc: 0.9244\n",
      "Epoch 775/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1171 - acc: 0.9559 - val_loss: 0.4916 - val_acc: 0.9244\n",
      "Epoch 776/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1186 - acc: 0.9601 - val_loss: 0.4798 - val_acc: 0.9244\n",
      "Epoch 777/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1009 - acc: 0.9651 - val_loss: 0.5895 - val_acc: 0.9042\n",
      "Epoch 778/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1182 - acc: 0.9601 - val_loss: 0.5262 - val_acc: 0.9210\n",
      "Epoch 779/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1155 - acc: 0.9584 - val_loss: 0.4880 - val_acc: 0.9210\n",
      "Epoch 780/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1082 - acc: 0.9597 - val_loss: 0.4945 - val_acc: 0.9126\n",
      "Epoch 781/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1086 - acc: 0.9622 - val_loss: 0.5809 - val_acc: 0.9160\n",
      "Epoch 782/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1133 - acc: 0.9613 - val_loss: 0.5091 - val_acc: 0.9244\n",
      "Epoch 783/2000\n",
      "2380/2380 [==============================] - 0s 58us/step - loss: 0.1119 - acc: 0.9563 - val_loss: 0.4844 - val_acc: 0.9193\n",
      "Epoch 784/2000\n",
      "2380/2380 [==============================] - 0s 60us/step - loss: 0.1062 - acc: 0.9647 - val_loss: 0.5812 - val_acc: 0.9109\n",
      "Epoch 785/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1171 - acc: 0.9546 - val_loss: 0.5195 - val_acc: 0.8992\n",
      "Epoch 786/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1079 - acc: 0.9613 - val_loss: 0.4787 - val_acc: 0.9261\n",
      "Epoch 787/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1053 - acc: 0.9609 - val_loss: 0.5228 - val_acc: 0.9126\n",
      "Epoch 788/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1187 - acc: 0.9576 - val_loss: 0.5054 - val_acc: 0.9244\n",
      "Epoch 789/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1135 - acc: 0.9576 - val_loss: 0.5407 - val_acc: 0.9143\n",
      "Epoch 790/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1059 - acc: 0.9630 - val_loss: 0.5421 - val_acc: 0.9193\n",
      "Epoch 791/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1177 - acc: 0.9576 - val_loss: 0.5561 - val_acc: 0.8924\n",
      "Epoch 792/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1232 - acc: 0.9618 - val_loss: 0.4955 - val_acc: 0.9176\n",
      "Epoch 793/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1184 - acc: 0.9571 - val_loss: 0.5391 - val_acc: 0.9193\n",
      "Epoch 794/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0993 - acc: 0.9626 - val_loss: 0.5043 - val_acc: 0.9227\n",
      "Epoch 795/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1180 - acc: 0.9618 - val_loss: 0.4792 - val_acc: 0.9261\n",
      "Epoch 796/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1082 - acc: 0.9618 - val_loss: 0.4900 - val_acc: 0.9092\n",
      "Epoch 797/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1149 - acc: 0.9609 - val_loss: 0.6291 - val_acc: 0.8992\n",
      "Epoch 798/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1235 - acc: 0.9597 - val_loss: 0.5370 - val_acc: 0.9210\n",
      "Epoch 799/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1137 - acc: 0.9626 - val_loss: 0.5057 - val_acc: 0.9193\n",
      "Epoch 800/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1069 - acc: 0.9622 - val_loss: 0.5301 - val_acc: 0.9210\n",
      "Epoch 801/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1190 - acc: 0.9592 - val_loss: 0.5863 - val_acc: 0.9008\n",
      "Epoch 802/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1078 - acc: 0.9592 - val_loss: 0.6449 - val_acc: 0.8975\n",
      "Epoch 803/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1209 - acc: 0.9630 - val_loss: 0.5249 - val_acc: 0.9076\n",
      "Epoch 804/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1089 - acc: 0.9622 - val_loss: 0.5530 - val_acc: 0.9109\n",
      "Epoch 805/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1197 - acc: 0.9618 - val_loss: 0.5764 - val_acc: 0.9092\n",
      "Epoch 806/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1188 - acc: 0.9542 - val_loss: 0.5409 - val_acc: 0.8992\n",
      "Epoch 807/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1142 - acc: 0.9567 - val_loss: 0.5331 - val_acc: 0.9160\n",
      "Epoch 808/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1141 - acc: 0.9597 - val_loss: 0.5327 - val_acc: 0.9109\n",
      "Epoch 809/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1067 - acc: 0.9660 - val_loss: 0.5315 - val_acc: 0.9076\n",
      "Epoch 810/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1084 - acc: 0.9597 - val_loss: 0.5239 - val_acc: 0.9227\n",
      "Epoch 811/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1052 - acc: 0.9639 - val_loss: 0.6386 - val_acc: 0.8790\n",
      "Epoch 812/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1052 - acc: 0.9601 - val_loss: 0.5347 - val_acc: 0.9008\n",
      "Epoch 813/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1131 - acc: 0.9618 - val_loss: 0.5011 - val_acc: 0.9109\n",
      "Epoch 814/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0991 - acc: 0.9639 - val_loss: 0.5483 - val_acc: 0.9076\n",
      "Epoch 815/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1140 - acc: 0.9576 - val_loss: 0.5372 - val_acc: 0.9109\n",
      "Epoch 816/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1138 - acc: 0.9576 - val_loss: 0.5151 - val_acc: 0.9176\n",
      "Epoch 817/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1124 - acc: 0.9592 - val_loss: 0.5261 - val_acc: 0.9193\n",
      "Epoch 818/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1082 - acc: 0.9609 - val_loss: 0.5549 - val_acc: 0.9076\n",
      "Epoch 819/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1039 - acc: 0.9672 - val_loss: 0.4926 - val_acc: 0.9143\n",
      "Epoch 820/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1143 - acc: 0.9584 - val_loss: 0.6524 - val_acc: 0.8807\n",
      "Epoch 821/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1080 - acc: 0.9655 - val_loss: 0.6446 - val_acc: 0.9059\n",
      "Epoch 822/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1057 - acc: 0.9643 - val_loss: 0.4885 - val_acc: 0.9227\n",
      "Epoch 823/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1185 - acc: 0.9567 - val_loss: 0.5157 - val_acc: 0.9109\n",
      "Epoch 824/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1132 - acc: 0.9647 - val_loss: 0.5648 - val_acc: 0.9076\n",
      "Epoch 825/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1120 - acc: 0.9588 - val_loss: 0.5778 - val_acc: 0.9076\n",
      "Epoch 826/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1120 - acc: 0.9626 - val_loss: 0.5102 - val_acc: 0.9227\n",
      "Epoch 827/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1059 - acc: 0.9584 - val_loss: 0.5736 - val_acc: 0.9126\n",
      "Epoch 828/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1201 - acc: 0.9584 - val_loss: 0.5014 - val_acc: 0.9227\n",
      "Epoch 829/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1038 - acc: 0.9601 - val_loss: 0.5277 - val_acc: 0.9143\n",
      "Epoch 830/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1066 - acc: 0.9571 - val_loss: 0.5752 - val_acc: 0.9008\n",
      "Epoch 831/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1037 - acc: 0.9609 - val_loss: 0.5365 - val_acc: 0.9227\n",
      "Epoch 832/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1054 - acc: 0.9622 - val_loss: 0.5361 - val_acc: 0.9193\n",
      "Epoch 833/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1128 - acc: 0.9580 - val_loss: 0.5008 - val_acc: 0.9210\n",
      "Epoch 834/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1141 - acc: 0.9592 - val_loss: 0.6175 - val_acc: 0.8924\n",
      "Epoch 835/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1090 - acc: 0.9580 - val_loss: 0.5293 - val_acc: 0.9193\n",
      "Epoch 836/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1101 - acc: 0.9618 - val_loss: 0.5408 - val_acc: 0.9160\n",
      "Epoch 837/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1049 - acc: 0.9634 - val_loss: 0.5734 - val_acc: 0.9210\n",
      "Epoch 838/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1065 - acc: 0.9639 - val_loss: 0.5570 - val_acc: 0.9160\n",
      "Epoch 839/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1074 - acc: 0.9588 - val_loss: 0.5646 - val_acc: 0.9059\n",
      "Epoch 840/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0968 - acc: 0.9660 - val_loss: 0.5138 - val_acc: 0.9126\n",
      "Epoch 841/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1092 - acc: 0.9588 - val_loss: 0.5224 - val_acc: 0.9126\n",
      "Epoch 842/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1163 - acc: 0.9550 - val_loss: 0.5048 - val_acc: 0.9227\n",
      "Epoch 843/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1144 - acc: 0.9626 - val_loss: 0.5753 - val_acc: 0.9160\n",
      "Epoch 844/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1017 - acc: 0.9634 - val_loss: 0.5497 - val_acc: 0.9210\n",
      "Epoch 845/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1114 - acc: 0.9626 - val_loss: 0.5826 - val_acc: 0.9109\n",
      "Epoch 846/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1135 - acc: 0.9580 - val_loss: 0.4984 - val_acc: 0.9193\n",
      "Epoch 847/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1066 - acc: 0.9605 - val_loss: 0.6602 - val_acc: 0.8908\n",
      "Epoch 848/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1079 - acc: 0.9613 - val_loss: 0.5556 - val_acc: 0.8857\n",
      "Epoch 849/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1190 - acc: 0.9576 - val_loss: 0.5523 - val_acc: 0.9076\n",
      "Epoch 850/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1049 - acc: 0.9655 - val_loss: 0.6476 - val_acc: 0.8975\n",
      "Epoch 851/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1014 - acc: 0.9634 - val_loss: 0.5025 - val_acc: 0.9193\n",
      "Epoch 852/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1141 - acc: 0.9618 - val_loss: 0.5172 - val_acc: 0.9092\n",
      "Epoch 853/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1138 - acc: 0.9529 - val_loss: 0.5229 - val_acc: 0.9126\n",
      "Epoch 854/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1024 - acc: 0.9601 - val_loss: 0.5020 - val_acc: 0.9193\n",
      "Epoch 855/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1090 - acc: 0.9643 - val_loss: 0.5712 - val_acc: 0.9109\n",
      "Epoch 856/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1001 - acc: 0.9609 - val_loss: 0.5363 - val_acc: 0.9160\n",
      "Epoch 857/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1159 - acc: 0.9563 - val_loss: 0.4891 - val_acc: 0.9227\n",
      "Epoch 858/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1098 - acc: 0.9601 - val_loss: 0.5385 - val_acc: 0.9176\n",
      "Epoch 859/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0996 - acc: 0.9660 - val_loss: 0.5216 - val_acc: 0.9092\n",
      "Epoch 860/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1116 - acc: 0.9605 - val_loss: 0.5242 - val_acc: 0.9210\n",
      "Epoch 861/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0973 - acc: 0.9630 - val_loss: 0.6501 - val_acc: 0.9059\n",
      "Epoch 862/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1173 - acc: 0.9588 - val_loss: 0.6533 - val_acc: 0.8891\n",
      "Epoch 863/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1070 - acc: 0.9609 - val_loss: 0.5498 - val_acc: 0.9059\n",
      "Epoch 864/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1105 - acc: 0.9622 - val_loss: 0.5184 - val_acc: 0.9210\n",
      "Epoch 865/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1100 - acc: 0.9601 - val_loss: 0.5655 - val_acc: 0.9109\n",
      "Epoch 866/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1070 - acc: 0.9622 - val_loss: 0.5766 - val_acc: 0.9042\n",
      "Epoch 867/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1046 - acc: 0.9613 - val_loss: 0.5767 - val_acc: 0.8941\n",
      "Epoch 868/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1188 - acc: 0.9618 - val_loss: 0.6999 - val_acc: 0.8723\n",
      "Epoch 869/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1008 - acc: 0.9630 - val_loss: 0.5560 - val_acc: 0.9193\n",
      "Epoch 870/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1071 - acc: 0.9618 - val_loss: 0.5985 - val_acc: 0.9025\n",
      "Epoch 871/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1099 - acc: 0.9576 - val_loss: 0.6192 - val_acc: 0.8941\n",
      "Epoch 872/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1157 - acc: 0.9597 - val_loss: 0.5320 - val_acc: 0.9210\n",
      "Epoch 873/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1110 - acc: 0.9622 - val_loss: 0.5131 - val_acc: 0.9193\n",
      "Epoch 874/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1174 - acc: 0.9542 - val_loss: 0.4914 - val_acc: 0.9176\n",
      "Epoch 875/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1045 - acc: 0.9592 - val_loss: 0.4939 - val_acc: 0.9328\n",
      "Epoch 876/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1060 - acc: 0.9672 - val_loss: 0.5756 - val_acc: 0.9176\n",
      "Epoch 877/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1184 - acc: 0.9609 - val_loss: 0.6407 - val_acc: 0.9008\n",
      "Epoch 878/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1026 - acc: 0.9609 - val_loss: 0.5300 - val_acc: 0.9227\n",
      "Epoch 879/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0978 - acc: 0.9651 - val_loss: 0.6302 - val_acc: 0.9059\n",
      "Epoch 880/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1285 - acc: 0.9580 - val_loss: 0.5859 - val_acc: 0.9109\n",
      "Epoch 881/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0961 - acc: 0.9651 - val_loss: 0.5214 - val_acc: 0.9193\n",
      "Epoch 882/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1062 - acc: 0.9622 - val_loss: 0.6184 - val_acc: 0.8992\n",
      "Epoch 883/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1075 - acc: 0.9613 - val_loss: 0.5308 - val_acc: 0.9160\n",
      "Epoch 884/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0934 - acc: 0.9639 - val_loss: 0.5575 - val_acc: 0.9059\n",
      "Epoch 885/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1153 - acc: 0.9601 - val_loss: 0.5378 - val_acc: 0.9008\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0964 - acc: 0.9622 - val_loss: 0.5706 - val_acc: 0.9193\n",
      "Epoch 887/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1006 - acc: 0.9647 - val_loss: 0.6455 - val_acc: 0.8992\n",
      "Epoch 888/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1198 - acc: 0.9605 - val_loss: 0.5353 - val_acc: 0.9227\n",
      "Epoch 889/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1156 - acc: 0.9597 - val_loss: 0.5194 - val_acc: 0.9210\n",
      "Epoch 890/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1052 - acc: 0.9613 - val_loss: 0.5374 - val_acc: 0.9176\n",
      "Epoch 891/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1086 - acc: 0.9576 - val_loss: 0.4989 - val_acc: 0.9126\n",
      "Epoch 892/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1069 - acc: 0.9651 - val_loss: 0.5651 - val_acc: 0.9126\n",
      "Epoch 893/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1033 - acc: 0.9613 - val_loss: 0.5338 - val_acc: 0.9042\n",
      "Epoch 894/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1165 - acc: 0.9563 - val_loss: 0.5106 - val_acc: 0.9176\n",
      "Epoch 895/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1060 - acc: 0.9651 - val_loss: 0.4955 - val_acc: 0.9210\n",
      "Epoch 896/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1044 - acc: 0.9613 - val_loss: 0.5080 - val_acc: 0.9160\n",
      "Epoch 897/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1096 - acc: 0.9626 - val_loss: 0.5308 - val_acc: 0.9143\n",
      "Epoch 898/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1037 - acc: 0.9647 - val_loss: 0.5776 - val_acc: 0.9042\n",
      "Epoch 899/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1112 - acc: 0.9588 - val_loss: 0.5283 - val_acc: 0.9109\n",
      "Epoch 900/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1068 - acc: 0.9613 - val_loss: 0.6155 - val_acc: 0.8975\n",
      "Epoch 901/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1074 - acc: 0.9609 - val_loss: 0.5715 - val_acc: 0.9059\n",
      "Epoch 902/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1074 - acc: 0.9634 - val_loss: 0.5400 - val_acc: 0.9193\n",
      "Epoch 903/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1154 - acc: 0.9609 - val_loss: 0.5963 - val_acc: 0.9143\n",
      "Epoch 904/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1095 - acc: 0.9634 - val_loss: 0.6257 - val_acc: 0.8992\n",
      "Epoch 905/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1254 - acc: 0.9613 - val_loss: 0.5155 - val_acc: 0.9227\n",
      "Epoch 906/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1077 - acc: 0.9626 - val_loss: 0.5510 - val_acc: 0.9025\n",
      "Epoch 907/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1066 - acc: 0.9626 - val_loss: 0.5326 - val_acc: 0.9277\n",
      "Epoch 908/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1178 - acc: 0.9584 - val_loss: 0.5800 - val_acc: 0.9143\n",
      "Epoch 909/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1049 - acc: 0.9584 - val_loss: 0.6383 - val_acc: 0.8958\n",
      "Epoch 910/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1090 - acc: 0.9630 - val_loss: 0.5030 - val_acc: 0.9143\n",
      "Epoch 911/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1010 - acc: 0.9626 - val_loss: 0.5252 - val_acc: 0.9160\n",
      "Epoch 912/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1065 - acc: 0.9592 - val_loss: 0.5463 - val_acc: 0.9126\n",
      "Epoch 913/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1122 - acc: 0.9597 - val_loss: 0.6735 - val_acc: 0.9059\n",
      "Epoch 914/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1002 - acc: 0.9651 - val_loss: 0.5755 - val_acc: 0.9109\n",
      "Epoch 915/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1134 - acc: 0.9580 - val_loss: 0.5188 - val_acc: 0.9244\n",
      "Epoch 916/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1176 - acc: 0.9550 - val_loss: 0.5164 - val_acc: 0.9126\n",
      "Epoch 917/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1094 - acc: 0.9609 - val_loss: 0.5405 - val_acc: 0.9244\n",
      "Epoch 918/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1129 - acc: 0.9643 - val_loss: 0.5611 - val_acc: 0.9126\n",
      "Epoch 919/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1054 - acc: 0.9622 - val_loss: 0.5742 - val_acc: 0.9143\n",
      "Epoch 920/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1129 - acc: 0.9584 - val_loss: 0.5212 - val_acc: 0.9227\n",
      "Epoch 921/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1296 - acc: 0.9576 - val_loss: 0.5857 - val_acc: 0.8908\n",
      "Epoch 922/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1061 - acc: 0.9651 - val_loss: 0.5156 - val_acc: 0.9244\n",
      "Epoch 923/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1240 - acc: 0.9592 - val_loss: 0.5822 - val_acc: 0.9059\n",
      "Epoch 924/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0985 - acc: 0.9626 - val_loss: 0.5352 - val_acc: 0.9076\n",
      "Epoch 925/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1111 - acc: 0.9622 - val_loss: 0.5571 - val_acc: 0.9143\n",
      "Epoch 926/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1062 - acc: 0.9630 - val_loss: 0.5227 - val_acc: 0.9092\n",
      "Epoch 927/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1186 - acc: 0.9563 - val_loss: 0.5381 - val_acc: 0.9193\n",
      "Epoch 928/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0937 - acc: 0.9626 - val_loss: 0.5745 - val_acc: 0.9025\n",
      "Epoch 929/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1058 - acc: 0.9626 - val_loss: 0.5982 - val_acc: 0.9059\n",
      "Epoch 930/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1067 - acc: 0.9639 - val_loss: 0.5622 - val_acc: 0.9109\n",
      "Epoch 931/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1070 - acc: 0.9639 - val_loss: 0.5438 - val_acc: 0.9160\n",
      "Epoch 932/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1094 - acc: 0.9618 - val_loss: 0.6211 - val_acc: 0.9092\n",
      "Epoch 933/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1056 - acc: 0.9664 - val_loss: 0.5565 - val_acc: 0.9092\n",
      "Epoch 934/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1071 - acc: 0.9626 - val_loss: 0.6272 - val_acc: 0.9076\n",
      "Epoch 935/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0899 - acc: 0.9706 - val_loss: 0.5798 - val_acc: 0.9160\n",
      "Epoch 936/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1127 - acc: 0.9597 - val_loss: 0.5545 - val_acc: 0.9109\n",
      "Epoch 937/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1180 - acc: 0.9592 - val_loss: 0.5972 - val_acc: 0.9126\n",
      "Epoch 938/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1079 - acc: 0.9630 - val_loss: 0.5690 - val_acc: 0.9143\n",
      "Epoch 939/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1061 - acc: 0.9588 - val_loss: 0.5951 - val_acc: 0.9126\n",
      "Epoch 940/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1079 - acc: 0.9626 - val_loss: 0.5293 - val_acc: 0.9261\n",
      "Epoch 941/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1110 - acc: 0.9605 - val_loss: 0.5526 - val_acc: 0.9143\n",
      "Epoch 942/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1013 - acc: 0.9643 - val_loss: 0.6572 - val_acc: 0.9076\n",
      "Epoch 943/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1039 - acc: 0.9643 - val_loss: 0.6852 - val_acc: 0.9025\n",
      "Epoch 944/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1076 - acc: 0.9618 - val_loss: 0.5046 - val_acc: 0.9294\n",
      "Epoch 945/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1090 - acc: 0.9597 - val_loss: 0.5195 - val_acc: 0.9311\n",
      "Epoch 946/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1255 - acc: 0.9550 - val_loss: 0.7516 - val_acc: 0.8840\n",
      "Epoch 947/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1228 - acc: 0.9584 - val_loss: 0.5418 - val_acc: 0.9227\n",
      "Epoch 948/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1077 - acc: 0.9584 - val_loss: 0.6029 - val_acc: 0.8992\n",
      "Epoch 949/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1132 - acc: 0.9576 - val_loss: 0.6176 - val_acc: 0.8992\n",
      "Epoch 950/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1055 - acc: 0.9647 - val_loss: 0.5398 - val_acc: 0.9210\n",
      "Epoch 951/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1081 - acc: 0.9555 - val_loss: 0.5490 - val_acc: 0.9244\n",
      "Epoch 952/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0977 - acc: 0.9660 - val_loss: 0.5984 - val_acc: 0.9092\n",
      "Epoch 953/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1101 - acc: 0.9622 - val_loss: 0.5765 - val_acc: 0.9160\n",
      "Epoch 954/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1081 - acc: 0.9639 - val_loss: 0.5233 - val_acc: 0.9210\n",
      "Epoch 955/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1041 - acc: 0.9613 - val_loss: 0.5950 - val_acc: 0.9092\n",
      "Epoch 956/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1115 - acc: 0.9559 - val_loss: 0.5380 - val_acc: 0.9160\n",
      "Epoch 957/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1058 - acc: 0.9643 - val_loss: 0.5367 - val_acc: 0.9109\n",
      "Epoch 958/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1035 - acc: 0.9622 - val_loss: 0.6119 - val_acc: 0.9210\n",
      "Epoch 959/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1077 - acc: 0.9634 - val_loss: 0.6380 - val_acc: 0.9143\n",
      "Epoch 960/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1048 - acc: 0.9634 - val_loss: 0.5687 - val_acc: 0.9059\n",
      "Epoch 961/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1077 - acc: 0.9634 - val_loss: 0.5557 - val_acc: 0.9176\n",
      "Epoch 962/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1051 - acc: 0.9634 - val_loss: 0.5913 - val_acc: 0.9109\n",
      "Epoch 963/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1028 - acc: 0.9697 - val_loss: 0.5954 - val_acc: 0.9126\n",
      "Epoch 964/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1073 - acc: 0.9618 - val_loss: 0.5684 - val_acc: 0.9092\n",
      "Epoch 965/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1063 - acc: 0.9588 - val_loss: 0.5481 - val_acc: 0.9244\n",
      "Epoch 966/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1036 - acc: 0.9647 - val_loss: 0.6040 - val_acc: 0.9008\n",
      "Epoch 967/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0941 - acc: 0.9643 - val_loss: 0.5585 - val_acc: 0.9126\n",
      "Epoch 968/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1071 - acc: 0.9647 - val_loss: 0.5476 - val_acc: 0.9160\n",
      "Epoch 969/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1093 - acc: 0.9597 - val_loss: 0.5267 - val_acc: 0.9126\n",
      "Epoch 970/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1079 - acc: 0.9592 - val_loss: 0.5565 - val_acc: 0.9193\n",
      "Epoch 971/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1075 - acc: 0.9647 - val_loss: 0.5613 - val_acc: 0.9109\n",
      "Epoch 972/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1163 - acc: 0.9626 - val_loss: 0.5440 - val_acc: 0.9143\n",
      "Epoch 973/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0999 - acc: 0.9647 - val_loss: 0.5718 - val_acc: 0.9160\n",
      "Epoch 974/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1032 - acc: 0.9634 - val_loss: 0.5687 - val_acc: 0.9227\n",
      "Epoch 975/2000\n",
      "2380/2380 [==============================] - 0s 70us/step - loss: 0.1093 - acc: 0.9643 - val_loss: 0.5322 - val_acc: 0.9244\n",
      "Epoch 976/2000\n",
      "2380/2380 [==============================] - 0s 52us/step - loss: 0.1061 - acc: 0.9609 - val_loss: 0.5643 - val_acc: 0.9126\n",
      "Epoch 977/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1105 - acc: 0.9601 - val_loss: 0.6359 - val_acc: 0.9042\n",
      "Epoch 978/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1139 - acc: 0.9639 - val_loss: 0.5540 - val_acc: 0.9076\n",
      "Epoch 979/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1040 - acc: 0.9643 - val_loss: 0.5873 - val_acc: 0.9008\n",
      "Epoch 980/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1119 - acc: 0.9618 - val_loss: 0.5803 - val_acc: 0.9176\n",
      "Epoch 981/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0957 - acc: 0.9618 - val_loss: 0.5908 - val_acc: 0.9160\n",
      "Epoch 982/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1030 - acc: 0.9634 - val_loss: 0.7131 - val_acc: 0.8958\n",
      "Epoch 983/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1037 - acc: 0.9668 - val_loss: 0.5862 - val_acc: 0.9109\n",
      "Epoch 984/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1191 - acc: 0.9563 - val_loss: 0.5545 - val_acc: 0.9261\n",
      "Epoch 985/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0941 - acc: 0.9613 - val_loss: 0.6749 - val_acc: 0.8975\n",
      "Epoch 986/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1221 - acc: 0.9550 - val_loss: 0.6672 - val_acc: 0.8891\n",
      "Epoch 987/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1150 - acc: 0.9597 - val_loss: 0.5230 - val_acc: 0.9176\n",
      "Epoch 988/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1077 - acc: 0.9643 - val_loss: 0.5261 - val_acc: 0.9210\n",
      "Epoch 989/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0872 - acc: 0.9676 - val_loss: 0.5843 - val_acc: 0.8958\n",
      "Epoch 990/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1120 - acc: 0.9592 - val_loss: 0.7045 - val_acc: 0.9076\n",
      "Epoch 991/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1125 - acc: 0.9618 - val_loss: 0.5094 - val_acc: 0.9160\n",
      "Epoch 992/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1074 - acc: 0.9605 - val_loss: 0.6334 - val_acc: 0.9059\n",
      "Epoch 993/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1007 - acc: 0.9622 - val_loss: 0.6100 - val_acc: 0.9092\n",
      "Epoch 994/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1063 - acc: 0.9664 - val_loss: 0.6135 - val_acc: 0.9042\n",
      "Epoch 995/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0889 - acc: 0.9723 - val_loss: 0.6003 - val_acc: 0.9210\n",
      "Epoch 996/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1077 - acc: 0.9651 - val_loss: 0.6415 - val_acc: 0.9008\n",
      "Epoch 997/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1052 - acc: 0.9626 - val_loss: 0.5789 - val_acc: 0.9092\n",
      "Epoch 998/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1145 - acc: 0.9634 - val_loss: 0.5745 - val_acc: 0.9126\n",
      "Epoch 999/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1070 - acc: 0.9613 - val_loss: 0.7163 - val_acc: 0.8739\n",
      "Epoch 1000/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1179 - acc: 0.9651 - val_loss: 0.5542 - val_acc: 0.9176\n",
      "Epoch 1001/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1094 - acc: 0.9622 - val_loss: 0.5578 - val_acc: 0.9193\n",
      "Epoch 1002/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1049 - acc: 0.9630 - val_loss: 0.5942 - val_acc: 0.9160\n",
      "Epoch 1003/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1029 - acc: 0.9643 - val_loss: 0.6539 - val_acc: 0.8992\n",
      "Epoch 1004/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0992 - acc: 0.9626 - val_loss: 0.5823 - val_acc: 0.9210\n",
      "Epoch 1005/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1129 - acc: 0.9613 - val_loss: 0.5809 - val_acc: 0.9210\n",
      "Epoch 1006/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1090 - acc: 0.9664 - val_loss: 0.5991 - val_acc: 0.9210\n",
      "Epoch 1007/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1105 - acc: 0.9609 - val_loss: 0.5777 - val_acc: 0.9126\n",
      "Epoch 1008/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1116 - acc: 0.9622 - val_loss: 0.5399 - val_acc: 0.9126\n",
      "Epoch 1009/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0959 - acc: 0.9676 - val_loss: 0.5882 - val_acc: 0.9143\n",
      "Epoch 1010/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1031 - acc: 0.9668 - val_loss: 0.5455 - val_acc: 0.9277\n",
      "Epoch 1011/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1164 - acc: 0.9609 - val_loss: 0.5465 - val_acc: 0.9193\n",
      "Epoch 1012/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1034 - acc: 0.9651 - val_loss: 0.6360 - val_acc: 0.8891\n",
      "Epoch 1013/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1052 - acc: 0.9643 - val_loss: 0.5638 - val_acc: 0.9244\n",
      "Epoch 1014/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1009 - acc: 0.9697 - val_loss: 0.5655 - val_acc: 0.9193\n",
      "Epoch 1015/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1104 - acc: 0.9605 - val_loss: 0.5985 - val_acc: 0.9042\n",
      "Epoch 1016/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1009 - acc: 0.9626 - val_loss: 0.5741 - val_acc: 0.9025\n",
      "Epoch 1017/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1061 - acc: 0.9630 - val_loss: 0.5312 - val_acc: 0.9227\n",
      "Epoch 1018/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0915 - acc: 0.9685 - val_loss: 0.6824 - val_acc: 0.9092\n",
      "Epoch 1019/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1077 - acc: 0.9605 - val_loss: 0.5838 - val_acc: 0.9109\n",
      "Epoch 1020/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0989 - acc: 0.9681 - val_loss: 0.6855 - val_acc: 0.8857\n",
      "Epoch 1021/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1056 - acc: 0.9643 - val_loss: 0.5601 - val_acc: 0.9160\n",
      "Epoch 1022/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1080 - acc: 0.9630 - val_loss: 0.5833 - val_acc: 0.9076\n",
      "Epoch 1023/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1000 - acc: 0.9639 - val_loss: 0.5811 - val_acc: 0.9092\n",
      "Epoch 1024/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1016 - acc: 0.9681 - val_loss: 0.6106 - val_acc: 0.9227\n",
      "Epoch 1025/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1016 - acc: 0.9622 - val_loss: 0.5891 - val_acc: 0.9076\n",
      "Epoch 1026/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1072 - acc: 0.9605 - val_loss: 0.5863 - val_acc: 0.9042\n",
      "Epoch 1027/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1046 - acc: 0.9676 - val_loss: 0.6420 - val_acc: 0.8941\n",
      "Epoch 1028/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1134 - acc: 0.9622 - val_loss: 0.5913 - val_acc: 0.9092\n",
      "Epoch 1029/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1096 - acc: 0.9605 - val_loss: 0.6208 - val_acc: 0.9092\n",
      "Epoch 1030/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0939 - acc: 0.9643 - val_loss: 0.5979 - val_acc: 0.9126\n",
      "Epoch 1031/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1063 - acc: 0.9651 - val_loss: 0.5519 - val_acc: 0.9160\n",
      "Epoch 1032/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0982 - acc: 0.9672 - val_loss: 0.6017 - val_acc: 0.9176\n",
      "Epoch 1033/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1044 - acc: 0.9660 - val_loss: 0.5944 - val_acc: 0.9059\n",
      "Epoch 1034/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1115 - acc: 0.9639 - val_loss: 0.6479 - val_acc: 0.9160\n",
      "Epoch 1035/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1058 - acc: 0.9647 - val_loss: 0.6773 - val_acc: 0.9059\n",
      "Epoch 1036/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1010 - acc: 0.9639 - val_loss: 0.6268 - val_acc: 0.9092\n",
      "Epoch 1037/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1118 - acc: 0.9609 - val_loss: 0.5465 - val_acc: 0.9092\n",
      "Epoch 1038/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1138 - acc: 0.9622 - val_loss: 0.5696 - val_acc: 0.9176\n",
      "Epoch 1039/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1139 - acc: 0.9630 - val_loss: 0.5309 - val_acc: 0.9176\n",
      "Epoch 1040/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1007 - acc: 0.9626 - val_loss: 0.5245 - val_acc: 0.9092\n",
      "Epoch 1041/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1053 - acc: 0.9647 - val_loss: 0.5843 - val_acc: 0.9076\n",
      "Epoch 1042/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1069 - acc: 0.9647 - val_loss: 0.6534 - val_acc: 0.9109\n",
      "Epoch 1043/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0949 - acc: 0.9655 - val_loss: 0.7089 - val_acc: 0.8824\n",
      "Epoch 1044/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1017 - acc: 0.9651 - val_loss: 0.6396 - val_acc: 0.9059\n",
      "Epoch 1045/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1071 - acc: 0.9584 - val_loss: 0.6132 - val_acc: 0.8975\n",
      "Epoch 1046/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0954 - acc: 0.9681 - val_loss: 0.6119 - val_acc: 0.9176\n",
      "Epoch 1047/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1187 - acc: 0.9618 - val_loss: 0.6049 - val_acc: 0.9092\n",
      "Epoch 1048/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0948 - acc: 0.9664 - val_loss: 0.5824 - val_acc: 0.9193\n",
      "Epoch 1049/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1106 - acc: 0.9622 - val_loss: 0.5260 - val_acc: 0.9143\n",
      "Epoch 1050/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1048 - acc: 0.9647 - val_loss: 0.6783 - val_acc: 0.8975\n",
      "Epoch 1051/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1050 - acc: 0.9626 - val_loss: 0.6551 - val_acc: 0.9076\n",
      "Epoch 1052/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0935 - acc: 0.9664 - val_loss: 0.5595 - val_acc: 0.9143\n",
      "Epoch 1053/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1029 - acc: 0.9702 - val_loss: 0.6024 - val_acc: 0.9008\n",
      "Epoch 1054/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1004 - acc: 0.9647 - val_loss: 0.5619 - val_acc: 0.9160\n",
      "Epoch 1055/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1054 - acc: 0.9651 - val_loss: 0.6370 - val_acc: 0.9025\n",
      "Epoch 1056/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0991 - acc: 0.9647 - val_loss: 0.5629 - val_acc: 0.9143\n",
      "Epoch 1057/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1052 - acc: 0.9630 - val_loss: 0.5960 - val_acc: 0.9176\n",
      "Epoch 1058/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1011 - acc: 0.9681 - val_loss: 0.5625 - val_acc: 0.9176\n",
      "Epoch 1059/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1013 - acc: 0.9655 - val_loss: 0.5652 - val_acc: 0.9143\n",
      "Epoch 1060/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1123 - acc: 0.9630 - val_loss: 0.6127 - val_acc: 0.9042\n",
      "Epoch 1061/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0938 - acc: 0.9702 - val_loss: 0.5842 - val_acc: 0.9109\n",
      "Epoch 1062/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1088 - acc: 0.9651 - val_loss: 0.5694 - val_acc: 0.9261\n",
      "Epoch 1063/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1125 - acc: 0.9618 - val_loss: 0.6113 - val_acc: 0.9176\n",
      "Epoch 1064/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0978 - acc: 0.9622 - val_loss: 0.6819 - val_acc: 0.8891\n",
      "Epoch 1065/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1103 - acc: 0.9651 - val_loss: 0.5711 - val_acc: 0.9143\n",
      "Epoch 1066/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1044 - acc: 0.9634 - val_loss: 0.5767 - val_acc: 0.9126\n",
      "Epoch 1067/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0999 - acc: 0.9660 - val_loss: 0.6158 - val_acc: 0.9160\n",
      "Epoch 1068/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1206 - acc: 0.9618 - val_loss: 0.5684 - val_acc: 0.9076\n",
      "Epoch 1069/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0923 - acc: 0.9668 - val_loss: 0.7085 - val_acc: 0.9076\n",
      "Epoch 1070/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0979 - acc: 0.9655 - val_loss: 0.6759 - val_acc: 0.8941\n",
      "Epoch 1071/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0970 - acc: 0.9660 - val_loss: 0.6527 - val_acc: 0.9059\n",
      "Epoch 1072/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0994 - acc: 0.9618 - val_loss: 0.7198 - val_acc: 0.8824\n",
      "Epoch 1073/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1099 - acc: 0.9622 - val_loss: 0.5736 - val_acc: 0.9126\n",
      "Epoch 1074/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0989 - acc: 0.9618 - val_loss: 0.6127 - val_acc: 0.9109\n",
      "Epoch 1075/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1019 - acc: 0.9626 - val_loss: 0.6801 - val_acc: 0.9076\n",
      "Epoch 1076/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1078 - acc: 0.9639 - val_loss: 0.6568 - val_acc: 0.9076\n",
      "Epoch 1077/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1038 - acc: 0.9630 - val_loss: 0.6114 - val_acc: 0.9059\n",
      "Epoch 1078/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0958 - acc: 0.9664 - val_loss: 0.6518 - val_acc: 0.8975\n",
      "Epoch 1079/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1002 - acc: 0.9643 - val_loss: 0.6880 - val_acc: 0.9059\n",
      "Epoch 1080/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1092 - acc: 0.9630 - val_loss: 0.5946 - val_acc: 0.9143\n",
      "Epoch 1081/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1100 - acc: 0.9626 - val_loss: 0.5380 - val_acc: 0.9193\n",
      "Epoch 1082/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1021 - acc: 0.9643 - val_loss: 0.6093 - val_acc: 0.9059\n",
      "Epoch 1083/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0988 - acc: 0.9660 - val_loss: 0.6245 - val_acc: 0.9160\n",
      "Epoch 1084/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1132 - acc: 0.9618 - val_loss: 0.6484 - val_acc: 0.9109\n",
      "Epoch 1085/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1029 - acc: 0.9664 - val_loss: 0.5647 - val_acc: 0.9160\n",
      "Epoch 1086/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1034 - acc: 0.9630 - val_loss: 0.6021 - val_acc: 0.8941\n",
      "Epoch 1087/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1168 - acc: 0.9601 - val_loss: 0.5585 - val_acc: 0.9176\n",
      "Epoch 1088/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1131 - acc: 0.9655 - val_loss: 0.6088 - val_acc: 0.9076\n",
      "Epoch 1089/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1045 - acc: 0.9660 - val_loss: 0.6138 - val_acc: 0.9076\n",
      "Epoch 1090/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0994 - acc: 0.9647 - val_loss: 0.5965 - val_acc: 0.9126\n",
      "Epoch 1091/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0921 - acc: 0.9672 - val_loss: 0.6114 - val_acc: 0.9092\n",
      "Epoch 1092/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1217 - acc: 0.9613 - val_loss: 0.5644 - val_acc: 0.9176\n",
      "Epoch 1093/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1111 - acc: 0.9630 - val_loss: 0.5431 - val_acc: 0.9227\n",
      "Epoch 1094/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1136 - acc: 0.9605 - val_loss: 0.5893 - val_acc: 0.9008\n",
      "Epoch 1095/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0958 - acc: 0.9647 - val_loss: 0.6175 - val_acc: 0.9092\n",
      "Epoch 1096/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0989 - acc: 0.9681 - val_loss: 0.5886 - val_acc: 0.9092\n",
      "Epoch 1097/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0980 - acc: 0.9681 - val_loss: 0.6091 - val_acc: 0.9042\n",
      "Epoch 1098/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0986 - acc: 0.9643 - val_loss: 0.5630 - val_acc: 0.9227\n",
      "Epoch 1099/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1028 - acc: 0.9647 - val_loss: 0.6960 - val_acc: 0.9008\n",
      "Epoch 1100/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0993 - acc: 0.9660 - val_loss: 0.6354 - val_acc: 0.8941\n",
      "Epoch 1101/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1057 - acc: 0.9668 - val_loss: 0.5077 - val_acc: 0.9176\n",
      "Epoch 1102/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1104 - acc: 0.9660 - val_loss: 0.6140 - val_acc: 0.9109\n",
      "Epoch 1103/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1189 - acc: 0.9634 - val_loss: 0.5719 - val_acc: 0.9025\n",
      "Epoch 1104/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1032 - acc: 0.9639 - val_loss: 0.5496 - val_acc: 0.9176\n",
      "Epoch 1105/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1187 - acc: 0.9609 - val_loss: 0.5935 - val_acc: 0.9126\n",
      "Epoch 1106/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1144 - acc: 0.9655 - val_loss: 0.6575 - val_acc: 0.9076\n",
      "Epoch 1107/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1121 - acc: 0.9647 - val_loss: 0.5598 - val_acc: 0.9126\n",
      "Epoch 1108/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0988 - acc: 0.9651 - val_loss: 0.6457 - val_acc: 0.9076\n",
      "Epoch 1109/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1147 - acc: 0.9622 - val_loss: 0.6255 - val_acc: 0.9008\n",
      "Epoch 1110/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0994 - acc: 0.9668 - val_loss: 0.6334 - val_acc: 0.9176\n",
      "Epoch 1111/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0959 - acc: 0.9676 - val_loss: 0.6490 - val_acc: 0.9025\n",
      "Epoch 1112/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0998 - acc: 0.9647 - val_loss: 0.5456 - val_acc: 0.9176\n",
      "Epoch 1113/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1149 - acc: 0.9660 - val_loss: 0.6612 - val_acc: 0.9042\n",
      "Epoch 1114/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1020 - acc: 0.9643 - val_loss: 0.6397 - val_acc: 0.9109\n",
      "Epoch 1115/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1001 - acc: 0.9630 - val_loss: 0.5433 - val_acc: 0.9193\n",
      "Epoch 1116/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1056 - acc: 0.9651 - val_loss: 0.5368 - val_acc: 0.9076\n",
      "Epoch 1117/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1089 - acc: 0.9643 - val_loss: 0.6185 - val_acc: 0.9008\n",
      "Epoch 1118/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0908 - acc: 0.9676 - val_loss: 0.5959 - val_acc: 0.9092\n",
      "Epoch 1119/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1013 - acc: 0.9639 - val_loss: 0.6312 - val_acc: 0.9176\n",
      "Epoch 1120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1036 - acc: 0.9609 - val_loss: 0.6099 - val_acc: 0.9210\n",
      "Epoch 1121/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1040 - acc: 0.9681 - val_loss: 0.6116 - val_acc: 0.9143\n",
      "Epoch 1122/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1021 - acc: 0.9664 - val_loss: 0.5914 - val_acc: 0.9160\n",
      "Epoch 1123/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1024 - acc: 0.9660 - val_loss: 0.6901 - val_acc: 0.8924\n",
      "Epoch 1124/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1123 - acc: 0.9622 - val_loss: 0.5438 - val_acc: 0.9193\n",
      "Epoch 1125/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1016 - acc: 0.9639 - val_loss: 0.5713 - val_acc: 0.9126\n",
      "Epoch 1126/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0995 - acc: 0.9651 - val_loss: 0.6037 - val_acc: 0.9126\n",
      "Epoch 1127/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1054 - acc: 0.9630 - val_loss: 0.5859 - val_acc: 0.9160\n",
      "Epoch 1128/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1110 - acc: 0.9626 - val_loss: 0.6907 - val_acc: 0.8891\n",
      "Epoch 1129/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0924 - acc: 0.9689 - val_loss: 0.5918 - val_acc: 0.9059\n",
      "Epoch 1130/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1081 - acc: 0.9634 - val_loss: 0.6075 - val_acc: 0.9109\n",
      "Epoch 1131/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0916 - acc: 0.9668 - val_loss: 0.6433 - val_acc: 0.9076\n",
      "Epoch 1132/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1165 - acc: 0.9626 - val_loss: 0.6081 - val_acc: 0.8958\n",
      "Epoch 1133/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1042 - acc: 0.9643 - val_loss: 0.6221 - val_acc: 0.8941\n",
      "Epoch 1134/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0966 - acc: 0.9668 - val_loss: 0.5892 - val_acc: 0.9193\n",
      "Epoch 1135/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1008 - acc: 0.9651 - val_loss: 0.5823 - val_acc: 0.9092\n",
      "Epoch 1136/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1037 - acc: 0.9634 - val_loss: 0.5807 - val_acc: 0.9092\n",
      "Epoch 1137/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1076 - acc: 0.9651 - val_loss: 0.7663 - val_acc: 0.8824\n",
      "Epoch 1138/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1091 - acc: 0.9634 - val_loss: 0.5971 - val_acc: 0.9092\n",
      "Epoch 1139/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0998 - acc: 0.9613 - val_loss: 0.5997 - val_acc: 0.9176\n",
      "Epoch 1140/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1051 - acc: 0.9613 - val_loss: 0.5869 - val_acc: 0.9059\n",
      "Epoch 1141/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0910 - acc: 0.9689 - val_loss: 0.6044 - val_acc: 0.9008\n",
      "Epoch 1142/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1033 - acc: 0.9647 - val_loss: 0.5718 - val_acc: 0.9193\n",
      "Epoch 1143/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1065 - acc: 0.9664 - val_loss: 0.6256 - val_acc: 0.8992\n",
      "Epoch 1144/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1035 - acc: 0.9664 - val_loss: 0.5516 - val_acc: 0.9160\n",
      "Epoch 1145/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1149 - acc: 0.9676 - val_loss: 0.6304 - val_acc: 0.9008\n",
      "Epoch 1146/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0994 - acc: 0.9676 - val_loss: 0.5967 - val_acc: 0.9109\n",
      "Epoch 1147/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1103 - acc: 0.9639 - val_loss: 0.6254 - val_acc: 0.9126\n",
      "Epoch 1148/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0980 - acc: 0.9655 - val_loss: 0.5565 - val_acc: 0.9076\n",
      "Epoch 1149/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0999 - acc: 0.9630 - val_loss: 0.6246 - val_acc: 0.9126\n",
      "Epoch 1150/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0972 - acc: 0.9727 - val_loss: 0.5869 - val_acc: 0.9143\n",
      "Epoch 1151/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1041 - acc: 0.9668 - val_loss: 0.5818 - val_acc: 0.9176\n",
      "Epoch 1152/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1130 - acc: 0.9639 - val_loss: 0.5427 - val_acc: 0.9227\n",
      "Epoch 1153/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0978 - acc: 0.9697 - val_loss: 0.6310 - val_acc: 0.9092\n",
      "Epoch 1154/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1056 - acc: 0.9643 - val_loss: 0.6232 - val_acc: 0.9008\n",
      "Epoch 1155/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0969 - acc: 0.9647 - val_loss: 0.6240 - val_acc: 0.9059\n",
      "Epoch 1156/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1101 - acc: 0.9630 - val_loss: 0.6501 - val_acc: 0.8924\n",
      "Epoch 1157/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0988 - acc: 0.9693 - val_loss: 0.7842 - val_acc: 0.8908\n",
      "Epoch 1158/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0971 - acc: 0.9672 - val_loss: 0.5796 - val_acc: 0.8992\n",
      "Epoch 1159/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1014 - acc: 0.9685 - val_loss: 0.5987 - val_acc: 0.9059\n",
      "Epoch 1160/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0930 - acc: 0.9706 - val_loss: 0.6840 - val_acc: 0.8874\n",
      "Epoch 1161/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0985 - acc: 0.9710 - val_loss: 0.6020 - val_acc: 0.8958\n",
      "Epoch 1162/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1150 - acc: 0.9655 - val_loss: 0.5456 - val_acc: 0.9227\n",
      "Epoch 1163/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1031 - acc: 0.9651 - val_loss: 0.5937 - val_acc: 0.9109\n",
      "Epoch 1164/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1033 - acc: 0.9668 - val_loss: 0.6103 - val_acc: 0.9109\n",
      "Epoch 1165/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1029 - acc: 0.9597 - val_loss: 0.6243 - val_acc: 0.9092\n",
      "Epoch 1166/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0932 - acc: 0.9689 - val_loss: 0.6098 - val_acc: 0.9160\n",
      "Epoch 1167/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1079 - acc: 0.9622 - val_loss: 0.5426 - val_acc: 0.9143\n",
      "Epoch 1168/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0980 - acc: 0.9655 - val_loss: 0.7510 - val_acc: 0.8840\n",
      "Epoch 1169/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1012 - acc: 0.9634 - val_loss: 0.5811 - val_acc: 0.9244\n",
      "Epoch 1170/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0975 - acc: 0.9672 - val_loss: 0.5695 - val_acc: 0.9143\n",
      "Epoch 1171/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1151 - acc: 0.9630 - val_loss: 0.6138 - val_acc: 0.9092\n",
      "Epoch 1172/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0982 - acc: 0.9647 - val_loss: 0.6188 - val_acc: 0.9143\n",
      "Epoch 1173/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1048 - acc: 0.9664 - val_loss: 0.5859 - val_acc: 0.9176\n",
      "Epoch 1174/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0904 - acc: 0.9735 - val_loss: 0.5810 - val_acc: 0.9109\n",
      "Epoch 1175/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1083 - acc: 0.9626 - val_loss: 0.6725 - val_acc: 0.9076\n",
      "Epoch 1176/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1085 - acc: 0.9676 - val_loss: 0.6168 - val_acc: 0.8975\n",
      "Epoch 1177/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0969 - acc: 0.9647 - val_loss: 0.5869 - val_acc: 0.9092\n",
      "Epoch 1178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0974 - acc: 0.9639 - val_loss: 0.7366 - val_acc: 0.8975\n",
      "Epoch 1179/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0978 - acc: 0.9660 - val_loss: 0.5583 - val_acc: 0.9210\n",
      "Epoch 1180/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1074 - acc: 0.9647 - val_loss: 0.6528 - val_acc: 0.9126\n",
      "Epoch 1181/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1029 - acc: 0.9609 - val_loss: 0.5775 - val_acc: 0.9126\n",
      "Epoch 1182/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1076 - acc: 0.9630 - val_loss: 0.5671 - val_acc: 0.9176\n",
      "Epoch 1183/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1027 - acc: 0.9693 - val_loss: 0.6216 - val_acc: 0.9193\n",
      "Epoch 1184/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0999 - acc: 0.9655 - val_loss: 0.6631 - val_acc: 0.9008\n",
      "Epoch 1185/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0940 - acc: 0.9651 - val_loss: 0.6016 - val_acc: 0.9076\n",
      "Epoch 1186/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1072 - acc: 0.9643 - val_loss: 0.7186 - val_acc: 0.8739\n",
      "Epoch 1187/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1007 - acc: 0.9630 - val_loss: 0.6884 - val_acc: 0.8992\n",
      "Epoch 1188/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1007 - acc: 0.9655 - val_loss: 0.6633 - val_acc: 0.9042\n",
      "Epoch 1189/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1002 - acc: 0.9689 - val_loss: 0.6252 - val_acc: 0.9092\n",
      "Epoch 1190/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1014 - acc: 0.9668 - val_loss: 0.5973 - val_acc: 0.9092\n",
      "Epoch 1191/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0987 - acc: 0.9643 - val_loss: 0.7061 - val_acc: 0.9059\n",
      "Epoch 1192/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0987 - acc: 0.9702 - val_loss: 0.6111 - val_acc: 0.9126\n",
      "Epoch 1193/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1118 - acc: 0.9613 - val_loss: 0.6830 - val_acc: 0.9025\n",
      "Epoch 1194/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1013 - acc: 0.9664 - val_loss: 0.5942 - val_acc: 0.9076\n",
      "Epoch 1195/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0928 - acc: 0.9668 - val_loss: 0.7405 - val_acc: 0.9042\n",
      "Epoch 1196/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1012 - acc: 0.9672 - val_loss: 0.7231 - val_acc: 0.8992\n",
      "Epoch 1197/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1097 - acc: 0.9634 - val_loss: 0.7302 - val_acc: 0.9008\n",
      "Epoch 1198/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0976 - acc: 0.9647 - val_loss: 0.5894 - val_acc: 0.9126\n",
      "Epoch 1199/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0905 - acc: 0.9706 - val_loss: 0.5858 - val_acc: 0.9193\n",
      "Epoch 1200/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0943 - acc: 0.9651 - val_loss: 0.6245 - val_acc: 0.9076\n",
      "Epoch 1201/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0959 - acc: 0.9672 - val_loss: 0.6333 - val_acc: 0.9193\n",
      "Epoch 1202/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1041 - acc: 0.9672 - val_loss: 0.6020 - val_acc: 0.9076\n",
      "Epoch 1203/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1006 - acc: 0.9668 - val_loss: 0.6384 - val_acc: 0.9042\n",
      "Epoch 1204/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0952 - acc: 0.9660 - val_loss: 0.6334 - val_acc: 0.9109\n",
      "Epoch 1205/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1030 - acc: 0.9655 - val_loss: 0.7289 - val_acc: 0.8908\n",
      "Epoch 1206/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0892 - acc: 0.9672 - val_loss: 0.6315 - val_acc: 0.9008\n",
      "Epoch 1207/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1091 - acc: 0.9622 - val_loss: 0.7738 - val_acc: 0.8807\n",
      "Epoch 1208/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1044 - acc: 0.9664 - val_loss: 0.6567 - val_acc: 0.9143\n",
      "Epoch 1209/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0929 - acc: 0.9689 - val_loss: 0.6222 - val_acc: 0.9008\n",
      "Epoch 1210/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1024 - acc: 0.9676 - val_loss: 0.5845 - val_acc: 0.9092\n",
      "Epoch 1211/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1154 - acc: 0.9668 - val_loss: 0.8255 - val_acc: 0.8723\n",
      "Epoch 1212/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0984 - acc: 0.9702 - val_loss: 0.6835 - val_acc: 0.9076\n",
      "Epoch 1213/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1048 - acc: 0.9626 - val_loss: 0.6122 - val_acc: 0.8992\n",
      "Epoch 1214/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0943 - acc: 0.9702 - val_loss: 0.7017 - val_acc: 0.9008\n",
      "Epoch 1215/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0962 - acc: 0.9668 - val_loss: 0.6705 - val_acc: 0.9042\n",
      "Epoch 1216/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1214 - acc: 0.9605 - val_loss: 0.8701 - val_acc: 0.8824\n",
      "Epoch 1217/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1006 - acc: 0.9651 - val_loss: 0.6141 - val_acc: 0.9176\n",
      "Epoch 1218/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1006 - acc: 0.9647 - val_loss: 0.6654 - val_acc: 0.9092\n",
      "Epoch 1219/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0907 - acc: 0.9693 - val_loss: 0.7008 - val_acc: 0.8992\n",
      "Epoch 1220/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1019 - acc: 0.9664 - val_loss: 0.6242 - val_acc: 0.9059\n",
      "Epoch 1221/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0921 - acc: 0.9660 - val_loss: 0.6348 - val_acc: 0.9059\n",
      "Epoch 1222/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1009 - acc: 0.9660 - val_loss: 0.6193 - val_acc: 0.9059\n",
      "Epoch 1223/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1015 - acc: 0.9651 - val_loss: 0.7211 - val_acc: 0.8958\n",
      "Epoch 1224/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1100 - acc: 0.9664 - val_loss: 0.6206 - val_acc: 0.9109\n",
      "Epoch 1225/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0913 - acc: 0.9647 - val_loss: 0.6460 - val_acc: 0.9126\n",
      "Epoch 1226/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0963 - acc: 0.9672 - val_loss: 0.5992 - val_acc: 0.9025\n",
      "Epoch 1227/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1049 - acc: 0.9651 - val_loss: 0.6312 - val_acc: 0.9092\n",
      "Epoch 1228/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1078 - acc: 0.9689 - val_loss: 0.6557 - val_acc: 0.9008\n",
      "Epoch 1229/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.1051 - acc: 0.9660 - val_loss: 0.6597 - val_acc: 0.9025\n",
      "Epoch 1230/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0897 - acc: 0.9693 - val_loss: 0.7083 - val_acc: 0.9092\n",
      "Epoch 1231/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0863 - acc: 0.9693 - val_loss: 0.7602 - val_acc: 0.8975\n",
      "Epoch 1232/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0902 - acc: 0.9685 - val_loss: 0.6161 - val_acc: 0.9059\n",
      "Epoch 1233/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0997 - acc: 0.9651 - val_loss: 0.6202 - val_acc: 0.9059\n",
      "Epoch 1234/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0972 - acc: 0.9660 - val_loss: 0.5956 - val_acc: 0.9059\n",
      "Epoch 1235/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1100 - acc: 0.9622 - val_loss: 0.6560 - val_acc: 0.9092\n",
      "Epoch 1236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1111 - acc: 0.9639 - val_loss: 0.6149 - val_acc: 0.9143\n",
      "Epoch 1237/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1017 - acc: 0.9672 - val_loss: 0.6632 - val_acc: 0.8958\n",
      "Epoch 1238/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1026 - acc: 0.9634 - val_loss: 0.6008 - val_acc: 0.9160\n",
      "Epoch 1239/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1063 - acc: 0.9676 - val_loss: 0.7274 - val_acc: 0.8874\n",
      "Epoch 1240/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1018 - acc: 0.9660 - val_loss: 0.6546 - val_acc: 0.9126\n",
      "Epoch 1241/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0969 - acc: 0.9664 - val_loss: 0.6353 - val_acc: 0.9092\n",
      "Epoch 1242/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0909 - acc: 0.9660 - val_loss: 0.6598 - val_acc: 0.9126\n",
      "Epoch 1243/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1019 - acc: 0.9685 - val_loss: 0.6762 - val_acc: 0.9042\n",
      "Epoch 1244/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0955 - acc: 0.9681 - val_loss: 0.7654 - val_acc: 0.8874\n",
      "Epoch 1245/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1085 - acc: 0.9693 - val_loss: 0.7481 - val_acc: 0.8874\n",
      "Epoch 1246/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0959 - acc: 0.9702 - val_loss: 0.6377 - val_acc: 0.9076\n",
      "Epoch 1247/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0972 - acc: 0.9697 - val_loss: 0.7673 - val_acc: 0.8739\n",
      "Epoch 1248/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0925 - acc: 0.9655 - val_loss: 0.6174 - val_acc: 0.9059\n",
      "Epoch 1249/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0927 - acc: 0.9702 - val_loss: 0.7023 - val_acc: 0.8924\n",
      "Epoch 1250/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0991 - acc: 0.9664 - val_loss: 0.6882 - val_acc: 0.9092\n",
      "Epoch 1251/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1138 - acc: 0.9634 - val_loss: 0.6941 - val_acc: 0.8975\n",
      "Epoch 1252/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0985 - acc: 0.9655 - val_loss: 0.6187 - val_acc: 0.9092\n",
      "Epoch 1253/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1106 - acc: 0.9613 - val_loss: 0.7176 - val_acc: 0.8840\n",
      "Epoch 1254/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0978 - acc: 0.9664 - val_loss: 0.5875 - val_acc: 0.9143\n",
      "Epoch 1255/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1028 - acc: 0.9622 - val_loss: 0.6116 - val_acc: 0.9059\n",
      "Epoch 1256/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0950 - acc: 0.9676 - val_loss: 0.6607 - val_acc: 0.9109\n",
      "Epoch 1257/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1034 - acc: 0.9618 - val_loss: 0.6283 - val_acc: 0.9092\n",
      "Epoch 1258/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0991 - acc: 0.9676 - val_loss: 0.7410 - val_acc: 0.9008\n",
      "Epoch 1259/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1026 - acc: 0.9685 - val_loss: 0.5719 - val_acc: 0.9126\n",
      "Epoch 1260/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1043 - acc: 0.9668 - val_loss: 0.6462 - val_acc: 0.9042\n",
      "Epoch 1261/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1014 - acc: 0.9672 - val_loss: 0.6493 - val_acc: 0.9042\n",
      "Epoch 1262/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0914 - acc: 0.9672 - val_loss: 0.6709 - val_acc: 0.9042\n",
      "Epoch 1263/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1034 - acc: 0.9668 - val_loss: 0.7499 - val_acc: 0.9008\n",
      "Epoch 1264/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0847 - acc: 0.9697 - val_loss: 0.6428 - val_acc: 0.9092\n",
      "Epoch 1265/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0990 - acc: 0.9639 - val_loss: 0.6332 - val_acc: 0.9092\n",
      "Epoch 1266/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1056 - acc: 0.9664 - val_loss: 0.6969 - val_acc: 0.9025\n",
      "Epoch 1267/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1063 - acc: 0.9643 - val_loss: 0.6136 - val_acc: 0.9143\n",
      "Epoch 1268/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0952 - acc: 0.9676 - val_loss: 0.6288 - val_acc: 0.9160\n",
      "Epoch 1269/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1074 - acc: 0.9634 - val_loss: 0.5676 - val_acc: 0.9193\n",
      "Epoch 1270/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0929 - acc: 0.9660 - val_loss: 0.8066 - val_acc: 0.8941\n",
      "Epoch 1271/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0968 - acc: 0.9727 - val_loss: 0.5417 - val_acc: 0.9126\n",
      "Epoch 1272/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1020 - acc: 0.9693 - val_loss: 0.6532 - val_acc: 0.9025\n",
      "Epoch 1273/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0981 - acc: 0.9668 - val_loss: 0.6970 - val_acc: 0.9059\n",
      "Epoch 1274/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0962 - acc: 0.9643 - val_loss: 0.6282 - val_acc: 0.8992\n",
      "Epoch 1275/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0941 - acc: 0.9697 - val_loss: 0.6011 - val_acc: 0.9109\n",
      "Epoch 1276/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1125 - acc: 0.9643 - val_loss: 0.6103 - val_acc: 0.9059\n",
      "Epoch 1277/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0964 - acc: 0.9681 - val_loss: 0.6044 - val_acc: 0.9059\n",
      "Epoch 1278/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0984 - acc: 0.9668 - val_loss: 0.6378 - val_acc: 0.9042\n",
      "Epoch 1279/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0955 - acc: 0.9676 - val_loss: 0.5691 - val_acc: 0.9160\n",
      "Epoch 1280/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1033 - acc: 0.9639 - val_loss: 0.7068 - val_acc: 0.8975\n",
      "Epoch 1281/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0993 - acc: 0.9651 - val_loss: 0.5678 - val_acc: 0.9008\n",
      "Epoch 1282/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0913 - acc: 0.9664 - val_loss: 0.5584 - val_acc: 0.9109\n",
      "Epoch 1283/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0915 - acc: 0.9710 - val_loss: 0.5841 - val_acc: 0.9109\n",
      "Epoch 1284/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1000 - acc: 0.9647 - val_loss: 0.6323 - val_acc: 0.9109\n",
      "Epoch 1285/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0948 - acc: 0.9714 - val_loss: 0.6783 - val_acc: 0.8908\n",
      "Epoch 1286/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1103 - acc: 0.9664 - val_loss: 0.6626 - val_acc: 0.8992\n",
      "Epoch 1287/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0955 - acc: 0.9672 - val_loss: 0.6910 - val_acc: 0.8975\n",
      "Epoch 1288/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0999 - acc: 0.9672 - val_loss: 0.8180 - val_acc: 0.8706\n",
      "Epoch 1289/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0894 - acc: 0.9672 - val_loss: 0.6667 - val_acc: 0.9059\n",
      "Epoch 1290/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1030 - acc: 0.9655 - val_loss: 0.7931 - val_acc: 0.8891\n",
      "Epoch 1291/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1171 - acc: 0.9630 - val_loss: 0.6532 - val_acc: 0.9008\n",
      "Epoch 1292/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0941 - acc: 0.9668 - val_loss: 0.5949 - val_acc: 0.9126\n",
      "Epoch 1293/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1015 - acc: 0.9655 - val_loss: 0.5592 - val_acc: 0.9176\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0970 - acc: 0.9643 - val_loss: 0.6120 - val_acc: 0.9109\n",
      "Epoch 1295/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1013 - acc: 0.9639 - val_loss: 0.6059 - val_acc: 0.9076\n",
      "Epoch 1296/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0986 - acc: 0.9668 - val_loss: 0.6773 - val_acc: 0.8975\n",
      "Epoch 1297/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1077 - acc: 0.9651 - val_loss: 0.6334 - val_acc: 0.8992\n",
      "Epoch 1298/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1022 - acc: 0.9676 - val_loss: 0.7148 - val_acc: 0.9076\n",
      "Epoch 1299/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0962 - acc: 0.9702 - val_loss: 0.6097 - val_acc: 0.9042\n",
      "Epoch 1300/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0957 - acc: 0.9672 - val_loss: 0.6224 - val_acc: 0.9059\n",
      "Epoch 1301/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1066 - acc: 0.9664 - val_loss: 0.6125 - val_acc: 0.9109\n",
      "Epoch 1302/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0964 - acc: 0.9668 - val_loss: 0.7626 - val_acc: 0.8958\n",
      "Epoch 1303/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1055 - acc: 0.9655 - val_loss: 0.6853 - val_acc: 0.9076\n",
      "Epoch 1304/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1025 - acc: 0.9613 - val_loss: 0.6010 - val_acc: 0.9076\n",
      "Epoch 1305/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0974 - acc: 0.9647 - val_loss: 0.5694 - val_acc: 0.9059\n",
      "Epoch 1306/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0798 - acc: 0.9739 - val_loss: 0.5969 - val_acc: 0.9092\n",
      "Epoch 1307/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1155 - acc: 0.9660 - val_loss: 0.6127 - val_acc: 0.9042\n",
      "Epoch 1308/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1006 - acc: 0.9664 - val_loss: 0.5609 - val_acc: 0.9092\n",
      "Epoch 1309/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0967 - acc: 0.9685 - val_loss: 0.6150 - val_acc: 0.9042\n",
      "Epoch 1310/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0942 - acc: 0.9681 - val_loss: 0.6502 - val_acc: 0.9025\n",
      "Epoch 1311/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0897 - acc: 0.9668 - val_loss: 0.6074 - val_acc: 0.9143\n",
      "Epoch 1312/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1055 - acc: 0.9647 - val_loss: 0.6282 - val_acc: 0.9143\n",
      "Epoch 1313/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1011 - acc: 0.9689 - val_loss: 0.6616 - val_acc: 0.9025\n",
      "Epoch 1314/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0946 - acc: 0.9676 - val_loss: 0.6059 - val_acc: 0.9042\n",
      "Epoch 1315/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1041 - acc: 0.9655 - val_loss: 0.6037 - val_acc: 0.9092\n",
      "Epoch 1316/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0927 - acc: 0.9651 - val_loss: 0.6318 - val_acc: 0.9126\n",
      "Epoch 1317/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1002 - acc: 0.9664 - val_loss: 0.6492 - val_acc: 0.9109\n",
      "Epoch 1318/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1023 - acc: 0.9651 - val_loss: 0.6078 - val_acc: 0.9092\n",
      "Epoch 1319/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1003 - acc: 0.9668 - val_loss: 0.6613 - val_acc: 0.9042\n",
      "Epoch 1320/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0918 - acc: 0.9706 - val_loss: 0.6687 - val_acc: 0.8824\n",
      "Epoch 1321/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0962 - acc: 0.9664 - val_loss: 0.6377 - val_acc: 0.9160\n",
      "Epoch 1322/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0921 - acc: 0.9706 - val_loss: 0.6568 - val_acc: 0.9143\n",
      "Epoch 1323/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0956 - acc: 0.9697 - val_loss: 0.6956 - val_acc: 0.8975\n",
      "Epoch 1324/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0975 - acc: 0.9651 - val_loss: 0.6777 - val_acc: 0.9092\n",
      "Epoch 1325/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0989 - acc: 0.9681 - val_loss: 0.8789 - val_acc: 0.8840\n",
      "Epoch 1326/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1001 - acc: 0.9651 - val_loss: 0.6276 - val_acc: 0.8975\n",
      "Epoch 1327/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1074 - acc: 0.9702 - val_loss: 0.6610 - val_acc: 0.9076\n",
      "Epoch 1328/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1066 - acc: 0.9643 - val_loss: 0.7022 - val_acc: 0.8924\n",
      "Epoch 1329/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0884 - acc: 0.9693 - val_loss: 0.6616 - val_acc: 0.9025\n",
      "Epoch 1330/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0949 - acc: 0.9693 - val_loss: 0.7323 - val_acc: 0.9008\n",
      "Epoch 1331/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0875 - acc: 0.9706 - val_loss: 0.6151 - val_acc: 0.9042\n",
      "Epoch 1332/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0931 - acc: 0.9689 - val_loss: 0.6434 - val_acc: 0.9042\n",
      "Epoch 1333/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0881 - acc: 0.9672 - val_loss: 0.6786 - val_acc: 0.9042\n",
      "Epoch 1334/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0948 - acc: 0.9697 - val_loss: 0.6280 - val_acc: 0.9025\n",
      "Epoch 1335/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1075 - acc: 0.9685 - val_loss: 0.6589 - val_acc: 0.8975\n",
      "Epoch 1336/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0909 - acc: 0.9660 - val_loss: 0.6682 - val_acc: 0.9025\n",
      "Epoch 1337/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1019 - acc: 0.9689 - val_loss: 0.7342 - val_acc: 0.8874\n",
      "Epoch 1338/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0993 - acc: 0.9681 - val_loss: 0.6219 - val_acc: 0.8975\n",
      "Epoch 1339/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1079 - acc: 0.9693 - val_loss: 0.6366 - val_acc: 0.9059\n",
      "Epoch 1340/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0955 - acc: 0.9672 - val_loss: 0.6602 - val_acc: 0.9059\n",
      "Epoch 1341/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0923 - acc: 0.9672 - val_loss: 0.6101 - val_acc: 0.9126\n",
      "Epoch 1342/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0984 - acc: 0.9639 - val_loss: 0.7963 - val_acc: 0.8992\n",
      "Epoch 1343/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0995 - acc: 0.9626 - val_loss: 0.7124 - val_acc: 0.8891\n",
      "Epoch 1344/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0903 - acc: 0.9702 - val_loss: 0.6284 - val_acc: 0.9109\n",
      "Epoch 1345/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0993 - acc: 0.9651 - val_loss: 0.5985 - val_acc: 0.9143\n",
      "Epoch 1346/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0972 - acc: 0.9685 - val_loss: 0.6046 - val_acc: 0.9025\n",
      "Epoch 1347/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0956 - acc: 0.9706 - val_loss: 0.5861 - val_acc: 0.9143\n",
      "Epoch 1348/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1120 - acc: 0.9697 - val_loss: 0.5834 - val_acc: 0.9076\n",
      "Epoch 1349/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0901 - acc: 0.9664 - val_loss: 0.6929 - val_acc: 0.9109\n",
      "Epoch 1350/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1035 - acc: 0.9714 - val_loss: 0.7015 - val_acc: 0.8840\n",
      "Epoch 1351/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0997 - acc: 0.9664 - val_loss: 0.6514 - val_acc: 0.8992\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0993 - acc: 0.9676 - val_loss: 0.6684 - val_acc: 0.9025\n",
      "Epoch 1353/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1002 - acc: 0.9651 - val_loss: 0.7273 - val_acc: 0.9076\n",
      "Epoch 1354/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0890 - acc: 0.9756 - val_loss: 0.6058 - val_acc: 0.9076\n",
      "Epoch 1355/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1100 - acc: 0.9672 - val_loss: 0.7330 - val_acc: 0.8941\n",
      "Epoch 1356/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0917 - acc: 0.9685 - val_loss: 0.6913 - val_acc: 0.9008\n",
      "Epoch 1357/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1137 - acc: 0.9622 - val_loss: 0.5891 - val_acc: 0.9042\n",
      "Epoch 1358/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0880 - acc: 0.9702 - val_loss: 0.5928 - val_acc: 0.9025\n",
      "Epoch 1359/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0967 - acc: 0.9702 - val_loss: 0.6577 - val_acc: 0.9059\n",
      "Epoch 1360/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0860 - acc: 0.9676 - val_loss: 0.6307 - val_acc: 0.9160\n",
      "Epoch 1361/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0951 - acc: 0.9664 - val_loss: 0.6831 - val_acc: 0.9008\n",
      "Epoch 1362/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0999 - acc: 0.9643 - val_loss: 0.6462 - val_acc: 0.8992\n",
      "Epoch 1363/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0885 - acc: 0.9681 - val_loss: 0.8138 - val_acc: 0.8756\n",
      "Epoch 1364/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0962 - acc: 0.9685 - val_loss: 0.7098 - val_acc: 0.8924\n",
      "Epoch 1365/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1112 - acc: 0.9664 - val_loss: 0.6891 - val_acc: 0.9008\n",
      "Epoch 1366/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0962 - acc: 0.9664 - val_loss: 0.6432 - val_acc: 0.9092\n",
      "Epoch 1367/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1081 - acc: 0.9668 - val_loss: 0.6312 - val_acc: 0.8992\n",
      "Epoch 1368/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0951 - acc: 0.9676 - val_loss: 0.6333 - val_acc: 0.9025\n",
      "Epoch 1369/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0960 - acc: 0.9672 - val_loss: 0.5857 - val_acc: 0.9025\n",
      "Epoch 1370/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1005 - acc: 0.9672 - val_loss: 0.6645 - val_acc: 0.9092\n",
      "Epoch 1371/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1017 - acc: 0.9664 - val_loss: 0.6366 - val_acc: 0.9059\n",
      "Epoch 1372/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0904 - acc: 0.9723 - val_loss: 0.7332 - val_acc: 0.9008\n",
      "Epoch 1373/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0908 - acc: 0.9681 - val_loss: 0.6398 - val_acc: 0.9076\n",
      "Epoch 1374/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1053 - acc: 0.9660 - val_loss: 0.7404 - val_acc: 0.8992\n",
      "Epoch 1375/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0952 - acc: 0.9668 - val_loss: 0.7964 - val_acc: 0.8840\n",
      "Epoch 1376/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1002 - acc: 0.9643 - val_loss: 0.6167 - val_acc: 0.9076\n",
      "Epoch 1377/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1181 - acc: 0.9664 - val_loss: 0.6440 - val_acc: 0.9092\n",
      "Epoch 1378/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0819 - acc: 0.9706 - val_loss: 0.7678 - val_acc: 0.8790\n",
      "Epoch 1379/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0864 - acc: 0.9634 - val_loss: 0.6947 - val_acc: 0.8908\n",
      "Epoch 1380/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0954 - acc: 0.9685 - val_loss: 0.6896 - val_acc: 0.9092\n",
      "Epoch 1381/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1031 - acc: 0.9655 - val_loss: 0.8443 - val_acc: 0.8908\n",
      "Epoch 1382/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0930 - acc: 0.9685 - val_loss: 0.6325 - val_acc: 0.9025\n",
      "Epoch 1383/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0794 - acc: 0.9706 - val_loss: 0.7243 - val_acc: 0.9076\n",
      "Epoch 1384/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1046 - acc: 0.9676 - val_loss: 0.6392 - val_acc: 0.9076\n",
      "Epoch 1385/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1036 - acc: 0.9668 - val_loss: 0.6932 - val_acc: 0.8992\n",
      "Epoch 1386/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0889 - acc: 0.9672 - val_loss: 0.6569 - val_acc: 0.9059\n",
      "Epoch 1387/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0931 - acc: 0.9651 - val_loss: 0.7253 - val_acc: 0.9042\n",
      "Epoch 1388/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0825 - acc: 0.9731 - val_loss: 0.6896 - val_acc: 0.8958\n",
      "Epoch 1389/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1071 - acc: 0.9643 - val_loss: 0.6894 - val_acc: 0.8924\n",
      "Epoch 1390/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0871 - acc: 0.9664 - val_loss: 0.6569 - val_acc: 0.9042\n",
      "Epoch 1391/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0973 - acc: 0.9681 - val_loss: 0.6746 - val_acc: 0.9042\n",
      "Epoch 1392/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1008 - acc: 0.9685 - val_loss: 0.6245 - val_acc: 0.9109\n",
      "Epoch 1393/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0924 - acc: 0.9655 - val_loss: 0.6599 - val_acc: 0.9008\n",
      "Epoch 1394/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1003 - acc: 0.9664 - val_loss: 0.6024 - val_acc: 0.9059\n",
      "Epoch 1395/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0887 - acc: 0.9697 - val_loss: 0.6378 - val_acc: 0.9160\n",
      "Epoch 1396/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0995 - acc: 0.9647 - val_loss: 0.6499 - val_acc: 0.9008\n",
      "Epoch 1397/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0927 - acc: 0.9655 - val_loss: 0.6600 - val_acc: 0.8992\n",
      "Epoch 1398/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1040 - acc: 0.9718 - val_loss: 0.5549 - val_acc: 0.9109\n",
      "Epoch 1399/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0936 - acc: 0.9676 - val_loss: 0.6769 - val_acc: 0.8924\n",
      "Epoch 1400/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0975 - acc: 0.9668 - val_loss: 0.6156 - val_acc: 0.9092\n",
      "Epoch 1401/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1026 - acc: 0.9651 - val_loss: 0.6719 - val_acc: 0.9042\n",
      "Epoch 1402/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0981 - acc: 0.9689 - val_loss: 0.6653 - val_acc: 0.9025\n",
      "Epoch 1403/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0881 - acc: 0.9689 - val_loss: 0.6030 - val_acc: 0.9042\n",
      "Epoch 1404/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0923 - acc: 0.9655 - val_loss: 0.7130 - val_acc: 0.8975\n",
      "Epoch 1405/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0970 - acc: 0.9689 - val_loss: 0.5823 - val_acc: 0.9025\n",
      "Epoch 1406/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1037 - acc: 0.9689 - val_loss: 0.6720 - val_acc: 0.9042\n",
      "Epoch 1407/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0867 - acc: 0.9744 - val_loss: 0.6382 - val_acc: 0.8941\n",
      "Epoch 1408/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0886 - acc: 0.9689 - val_loss: 0.6794 - val_acc: 0.9008\n",
      "Epoch 1409/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1033 - acc: 0.9664 - val_loss: 0.7127 - val_acc: 0.8908\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0908 - acc: 0.9693 - val_loss: 0.6800 - val_acc: 0.9042\n",
      "Epoch 1411/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0952 - acc: 0.9714 - val_loss: 0.6298 - val_acc: 0.9076\n",
      "Epoch 1412/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0990 - acc: 0.9651 - val_loss: 0.6072 - val_acc: 0.9076\n",
      "Epoch 1413/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1014 - acc: 0.9685 - val_loss: 0.5964 - val_acc: 0.9008\n",
      "Epoch 1414/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0882 - acc: 0.9761 - val_loss: 0.6858 - val_acc: 0.9042\n",
      "Epoch 1415/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1077 - acc: 0.9622 - val_loss: 0.5853 - val_acc: 0.9109\n",
      "Epoch 1416/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0909 - acc: 0.9718 - val_loss: 0.6135 - val_acc: 0.9126\n",
      "Epoch 1417/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0972 - acc: 0.9664 - val_loss: 0.6185 - val_acc: 0.9025\n",
      "Epoch 1418/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1017 - acc: 0.9702 - val_loss: 0.6684 - val_acc: 0.9042\n",
      "Epoch 1419/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0909 - acc: 0.9744 - val_loss: 0.6621 - val_acc: 0.9042\n",
      "Epoch 1420/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0946 - acc: 0.9706 - val_loss: 0.6490 - val_acc: 0.9092\n",
      "Epoch 1421/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0837 - acc: 0.9710 - val_loss: 0.6610 - val_acc: 0.9076\n",
      "Epoch 1422/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0953 - acc: 0.9702 - val_loss: 0.6727 - val_acc: 0.9025\n",
      "Epoch 1423/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0979 - acc: 0.9660 - val_loss: 0.6174 - val_acc: 0.9076\n",
      "Epoch 1424/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0929 - acc: 0.9668 - val_loss: 0.6669 - val_acc: 0.8975\n",
      "Epoch 1425/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0949 - acc: 0.9668 - val_loss: 0.6706 - val_acc: 0.9008\n",
      "Epoch 1426/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0962 - acc: 0.9702 - val_loss: 0.6708 - val_acc: 0.8958\n",
      "Epoch 1427/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0903 - acc: 0.9685 - val_loss: 0.5765 - val_acc: 0.9092\n",
      "Epoch 1428/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0999 - acc: 0.9689 - val_loss: 0.7329 - val_acc: 0.8891\n",
      "Epoch 1429/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0894 - acc: 0.9681 - val_loss: 0.5697 - val_acc: 0.9059\n",
      "Epoch 1430/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0949 - acc: 0.9668 - val_loss: 0.6503 - val_acc: 0.8891\n",
      "Epoch 1431/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1040 - acc: 0.9685 - val_loss: 0.7595 - val_acc: 0.8891\n",
      "Epoch 1432/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0975 - acc: 0.9697 - val_loss: 0.6746 - val_acc: 0.9025\n",
      "Epoch 1433/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0938 - acc: 0.9706 - val_loss: 0.5963 - val_acc: 0.9059\n",
      "Epoch 1434/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0990 - acc: 0.9655 - val_loss: 0.7207 - val_acc: 0.8958\n",
      "Epoch 1435/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0962 - acc: 0.9697 - val_loss: 0.6658 - val_acc: 0.8874\n",
      "Epoch 1436/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0965 - acc: 0.9685 - val_loss: 0.6745 - val_acc: 0.8975\n",
      "Epoch 1437/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0858 - acc: 0.9706 - val_loss: 0.6618 - val_acc: 0.8924\n",
      "Epoch 1438/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0998 - acc: 0.9685 - val_loss: 0.6753 - val_acc: 0.9025\n",
      "Epoch 1439/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0926 - acc: 0.9689 - val_loss: 0.6719 - val_acc: 0.9042\n",
      "Epoch 1440/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0923 - acc: 0.9689 - val_loss: 0.6945 - val_acc: 0.9042\n",
      "Epoch 1441/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0948 - acc: 0.9727 - val_loss: 0.6093 - val_acc: 0.9076\n",
      "Epoch 1442/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0813 - acc: 0.9702 - val_loss: 0.7254 - val_acc: 0.9025\n",
      "Epoch 1443/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0924 - acc: 0.9702 - val_loss: 0.6344 - val_acc: 0.8924\n",
      "Epoch 1444/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1119 - acc: 0.9647 - val_loss: 0.6809 - val_acc: 0.9059\n",
      "Epoch 1445/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0932 - acc: 0.9672 - val_loss: 0.6906 - val_acc: 0.9059\n",
      "Epoch 1446/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1008 - acc: 0.9651 - val_loss: 0.7200 - val_acc: 0.8992\n",
      "Epoch 1447/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0907 - acc: 0.9706 - val_loss: 0.7465 - val_acc: 0.8992\n",
      "Epoch 1448/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1022 - acc: 0.9601 - val_loss: 0.8002 - val_acc: 0.8824\n",
      "Epoch 1449/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0976 - acc: 0.9685 - val_loss: 0.7058 - val_acc: 0.9143\n",
      "Epoch 1450/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0923 - acc: 0.9651 - val_loss: 0.6624 - val_acc: 0.9160\n",
      "Epoch 1451/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0913 - acc: 0.9672 - val_loss: 0.7944 - val_acc: 0.8958\n",
      "Epoch 1452/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0934 - acc: 0.9668 - val_loss: 0.6477 - val_acc: 0.9008\n",
      "Epoch 1453/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0977 - acc: 0.9676 - val_loss: 0.6735 - val_acc: 0.8941\n",
      "Epoch 1454/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0899 - acc: 0.9710 - val_loss: 0.6413 - val_acc: 0.8975\n",
      "Epoch 1455/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0937 - acc: 0.9689 - val_loss: 0.6665 - val_acc: 0.9008\n",
      "Epoch 1456/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0867 - acc: 0.9714 - val_loss: 0.6836 - val_acc: 0.9126\n",
      "Epoch 1457/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0989 - acc: 0.9689 - val_loss: 0.6842 - val_acc: 0.9126\n",
      "Epoch 1458/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0934 - acc: 0.9706 - val_loss: 0.6596 - val_acc: 0.9008\n",
      "Epoch 1459/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0930 - acc: 0.9668 - val_loss: 0.6551 - val_acc: 0.8958\n",
      "Epoch 1460/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0908 - acc: 0.9689 - val_loss: 0.6373 - val_acc: 0.9008\n",
      "Epoch 1461/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0998 - acc: 0.9660 - val_loss: 0.6323 - val_acc: 0.8908\n",
      "Epoch 1462/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0858 - acc: 0.9714 - val_loss: 0.7904 - val_acc: 0.8958\n",
      "Epoch 1463/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1067 - acc: 0.9651 - val_loss: 0.7109 - val_acc: 0.8975\n",
      "Epoch 1464/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1050 - acc: 0.9655 - val_loss: 0.6498 - val_acc: 0.9008\n",
      "Epoch 1465/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0821 - acc: 0.9727 - val_loss: 0.7135 - val_acc: 0.8941\n",
      "Epoch 1466/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0972 - acc: 0.9664 - val_loss: 0.7241 - val_acc: 0.8857\n",
      "Epoch 1467/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1308 - acc: 0.9643 - val_loss: 0.6288 - val_acc: 0.9076\n",
      "Epoch 1468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0969 - acc: 0.9664 - val_loss: 0.6768 - val_acc: 0.8958\n",
      "Epoch 1469/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0837 - acc: 0.9702 - val_loss: 0.7274 - val_acc: 0.8975\n",
      "Epoch 1470/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0918 - acc: 0.9689 - val_loss: 0.7978 - val_acc: 0.9008\n",
      "Epoch 1471/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0901 - acc: 0.9697 - val_loss: 0.7422 - val_acc: 0.8908\n",
      "Epoch 1472/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0890 - acc: 0.9710 - val_loss: 0.6730 - val_acc: 0.8975\n",
      "Epoch 1473/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0949 - acc: 0.9702 - val_loss: 0.6740 - val_acc: 0.9092\n",
      "Epoch 1474/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0847 - acc: 0.9714 - val_loss: 0.6491 - val_acc: 0.9059\n",
      "Epoch 1475/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1123 - acc: 0.9651 - val_loss: 0.5866 - val_acc: 0.9143\n",
      "Epoch 1476/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0998 - acc: 0.9685 - val_loss: 0.7578 - val_acc: 0.8824\n",
      "Epoch 1477/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0950 - acc: 0.9689 - val_loss: 0.7840 - val_acc: 0.8908\n",
      "Epoch 1478/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1116 - acc: 0.9660 - val_loss: 0.7154 - val_acc: 0.8924\n",
      "Epoch 1479/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1007 - acc: 0.9702 - val_loss: 0.6209 - val_acc: 0.9025\n",
      "Epoch 1480/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0910 - acc: 0.9710 - val_loss: 0.6378 - val_acc: 0.8975\n",
      "Epoch 1481/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0899 - acc: 0.9681 - val_loss: 0.6587 - val_acc: 0.9025\n",
      "Epoch 1482/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0941 - acc: 0.9660 - val_loss: 0.6021 - val_acc: 0.9076\n",
      "Epoch 1483/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0781 - acc: 0.9748 - val_loss: 0.5905 - val_acc: 0.8975\n",
      "Epoch 1484/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0993 - acc: 0.9647 - val_loss: 0.5899 - val_acc: 0.9109\n",
      "Epoch 1485/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0856 - acc: 0.9685 - val_loss: 0.6689 - val_acc: 0.9025\n",
      "Epoch 1486/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0868 - acc: 0.9714 - val_loss: 0.6995 - val_acc: 0.8992\n",
      "Epoch 1487/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1003 - acc: 0.9647 - val_loss: 0.6916 - val_acc: 0.8992\n",
      "Epoch 1488/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0897 - acc: 0.9689 - val_loss: 0.6715 - val_acc: 0.9042\n",
      "Epoch 1489/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0952 - acc: 0.9689 - val_loss: 0.7786 - val_acc: 0.8924\n",
      "Epoch 1490/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1011 - acc: 0.9706 - val_loss: 0.5852 - val_acc: 0.9126\n",
      "Epoch 1491/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0914 - acc: 0.9697 - val_loss: 0.6969 - val_acc: 0.9008\n",
      "Epoch 1492/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0874 - acc: 0.9697 - val_loss: 0.6561 - val_acc: 0.9025\n",
      "Epoch 1493/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0914 - acc: 0.9735 - val_loss: 0.6665 - val_acc: 0.8941\n",
      "Epoch 1494/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0971 - acc: 0.9672 - val_loss: 0.7699 - val_acc: 0.9025\n",
      "Epoch 1495/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0878 - acc: 0.9718 - val_loss: 0.6065 - val_acc: 0.9143\n",
      "Epoch 1496/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1085 - acc: 0.9672 - val_loss: 0.5873 - val_acc: 0.9109\n",
      "Epoch 1497/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1030 - acc: 0.9655 - val_loss: 0.6719 - val_acc: 0.8992\n",
      "Epoch 1498/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0932 - acc: 0.9706 - val_loss: 0.8602 - val_acc: 0.8807\n",
      "Epoch 1499/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1144 - acc: 0.9651 - val_loss: 0.8868 - val_acc: 0.8840\n",
      "Epoch 1500/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0870 - acc: 0.9727 - val_loss: 0.6945 - val_acc: 0.9008\n",
      "Epoch 1501/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0988 - acc: 0.9702 - val_loss: 0.6452 - val_acc: 0.9126\n",
      "Epoch 1502/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0918 - acc: 0.9693 - val_loss: 0.6673 - val_acc: 0.9076\n",
      "Epoch 1503/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0910 - acc: 0.9706 - val_loss: 0.6227 - val_acc: 0.9025\n",
      "Epoch 1504/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1027 - acc: 0.9664 - val_loss: 0.7052 - val_acc: 0.9008\n",
      "Epoch 1505/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0829 - acc: 0.9727 - val_loss: 0.6768 - val_acc: 0.9042\n",
      "Epoch 1506/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1069 - acc: 0.9655 - val_loss: 0.6199 - val_acc: 0.9143\n",
      "Epoch 1507/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1075 - acc: 0.9639 - val_loss: 0.6515 - val_acc: 0.9109\n",
      "Epoch 1508/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0913 - acc: 0.9685 - val_loss: 0.6776 - val_acc: 0.9092\n",
      "Epoch 1509/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0847 - acc: 0.9681 - val_loss: 0.6323 - val_acc: 0.9008\n",
      "Epoch 1510/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1055 - acc: 0.9651 - val_loss: 0.7084 - val_acc: 0.8891\n",
      "Epoch 1511/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1004 - acc: 0.9685 - val_loss: 0.6081 - val_acc: 0.9076\n",
      "Epoch 1512/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0995 - acc: 0.9693 - val_loss: 0.6718 - val_acc: 0.9008\n",
      "Epoch 1513/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0852 - acc: 0.9697 - val_loss: 0.6755 - val_acc: 0.9025\n",
      "Epoch 1514/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0916 - acc: 0.9718 - val_loss: 0.7139 - val_acc: 0.9008\n",
      "Epoch 1515/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0931 - acc: 0.9697 - val_loss: 0.6214 - val_acc: 0.9160\n",
      "Epoch 1516/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1054 - acc: 0.9660 - val_loss: 0.7715 - val_acc: 0.8992\n",
      "Epoch 1517/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0882 - acc: 0.9735 - val_loss: 0.6619 - val_acc: 0.9042\n",
      "Epoch 1518/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0848 - acc: 0.9706 - val_loss: 0.6875 - val_acc: 0.8941\n",
      "Epoch 1519/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0966 - acc: 0.9689 - val_loss: 0.6859 - val_acc: 0.8958\n",
      "Epoch 1520/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1026 - acc: 0.9697 - val_loss: 0.7527 - val_acc: 0.8891\n",
      "Epoch 1521/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0995 - acc: 0.9668 - val_loss: 0.7247 - val_acc: 0.8992\n",
      "Epoch 1522/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0907 - acc: 0.9689 - val_loss: 0.6128 - val_acc: 0.9059\n",
      "Epoch 1523/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0792 - acc: 0.9756 - val_loss: 0.6976 - val_acc: 0.9076\n",
      "Epoch 1524/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0865 - acc: 0.9702 - val_loss: 0.6207 - val_acc: 0.9092\n",
      "Epoch 1525/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0893 - acc: 0.9744 - val_loss: 0.6361 - val_acc: 0.9092\n",
      "Epoch 1526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0919 - acc: 0.9685 - val_loss: 0.6568 - val_acc: 0.9176\n",
      "Epoch 1527/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0852 - acc: 0.9702 - val_loss: 0.6456 - val_acc: 0.9025\n",
      "Epoch 1528/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0891 - acc: 0.9685 - val_loss: 0.6333 - val_acc: 0.9109\n",
      "Epoch 1529/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1047 - acc: 0.9689 - val_loss: 0.6643 - val_acc: 0.9025\n",
      "Epoch 1530/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0965 - acc: 0.9706 - val_loss: 0.7060 - val_acc: 0.8857\n",
      "Epoch 1531/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1036 - acc: 0.9702 - val_loss: 0.7368 - val_acc: 0.8941\n",
      "Epoch 1532/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0835 - acc: 0.9714 - val_loss: 0.6935 - val_acc: 0.9092\n",
      "Epoch 1533/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0997 - acc: 0.9660 - val_loss: 0.6609 - val_acc: 0.9076\n",
      "Epoch 1534/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0921 - acc: 0.9710 - val_loss: 0.6912 - val_acc: 0.9092\n",
      "Epoch 1535/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0921 - acc: 0.9676 - val_loss: 0.7542 - val_acc: 0.9008\n",
      "Epoch 1536/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0887 - acc: 0.9710 - val_loss: 0.6249 - val_acc: 0.9025\n",
      "Epoch 1537/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1002 - acc: 0.9718 - val_loss: 0.7521 - val_acc: 0.8958\n",
      "Epoch 1538/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0974 - acc: 0.9655 - val_loss: 0.6699 - val_acc: 0.8992\n",
      "Epoch 1539/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0928 - acc: 0.9693 - val_loss: 0.7286 - val_acc: 0.8992\n",
      "Epoch 1540/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0973 - acc: 0.9651 - val_loss: 0.7349 - val_acc: 0.8975\n",
      "Epoch 1541/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0955 - acc: 0.9676 - val_loss: 0.6670 - val_acc: 0.8992\n",
      "Epoch 1542/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0930 - acc: 0.9693 - val_loss: 0.6975 - val_acc: 0.8941\n",
      "Epoch 1543/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1046 - acc: 0.9668 - val_loss: 0.6008 - val_acc: 0.9042\n",
      "Epoch 1544/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0938 - acc: 0.9651 - val_loss: 0.6798 - val_acc: 0.9076\n",
      "Epoch 1545/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0925 - acc: 0.9676 - val_loss: 0.6157 - val_acc: 0.9025\n",
      "Epoch 1546/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1037 - acc: 0.9672 - val_loss: 0.5588 - val_acc: 0.9059\n",
      "Epoch 1547/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0954 - acc: 0.9697 - val_loss: 0.7558 - val_acc: 0.8908\n",
      "Epoch 1548/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.1108 - acc: 0.9672 - val_loss: 0.6504 - val_acc: 0.9059\n",
      "Epoch 1549/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0955 - acc: 0.9693 - val_loss: 0.6795 - val_acc: 0.9025\n",
      "Epoch 1550/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0846 - acc: 0.9718 - val_loss: 0.6748 - val_acc: 0.9042\n",
      "Epoch 1551/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1134 - acc: 0.9668 - val_loss: 0.6710 - val_acc: 0.9076\n",
      "Epoch 1552/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0766 - acc: 0.9718 - val_loss: 0.6913 - val_acc: 0.9092\n",
      "Epoch 1553/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0906 - acc: 0.9761 - val_loss: 0.8405 - val_acc: 0.8924\n",
      "Epoch 1554/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0991 - acc: 0.9660 - val_loss: 0.6774 - val_acc: 0.9076\n",
      "Epoch 1555/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0987 - acc: 0.9651 - val_loss: 0.8259 - val_acc: 0.8908\n",
      "Epoch 1556/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1150 - acc: 0.9672 - val_loss: 0.6533 - val_acc: 0.9143\n",
      "Epoch 1557/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0914 - acc: 0.9718 - val_loss: 0.6847 - val_acc: 0.8908\n",
      "Epoch 1558/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1062 - acc: 0.9714 - val_loss: 0.7133 - val_acc: 0.8958\n",
      "Epoch 1559/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0988 - acc: 0.9676 - val_loss: 0.7622 - val_acc: 0.8723\n",
      "Epoch 1560/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1020 - acc: 0.9685 - val_loss: 0.5880 - val_acc: 0.9176\n",
      "Epoch 1561/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0878 - acc: 0.9693 - val_loss: 0.6886 - val_acc: 0.9008\n",
      "Epoch 1562/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0917 - acc: 0.9697 - val_loss: 0.6508 - val_acc: 0.8958\n",
      "Epoch 1563/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0910 - acc: 0.9710 - val_loss: 0.7903 - val_acc: 0.8975\n",
      "Epoch 1564/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0993 - acc: 0.9676 - val_loss: 0.6926 - val_acc: 0.8975\n",
      "Epoch 1565/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0875 - acc: 0.9702 - val_loss: 0.6084 - val_acc: 0.9076\n",
      "Epoch 1566/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0954 - acc: 0.9706 - val_loss: 0.6609 - val_acc: 0.8941\n",
      "Epoch 1567/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0964 - acc: 0.9697 - val_loss: 0.6976 - val_acc: 0.9025\n",
      "Epoch 1568/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0971 - acc: 0.9689 - val_loss: 0.7206 - val_acc: 0.8924\n",
      "Epoch 1569/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0992 - acc: 0.9651 - val_loss: 0.6682 - val_acc: 0.8975\n",
      "Epoch 1570/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0918 - acc: 0.9697 - val_loss: 0.6254 - val_acc: 0.9160\n",
      "Epoch 1571/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0960 - acc: 0.9735 - val_loss: 0.6687 - val_acc: 0.8924\n",
      "Epoch 1572/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0876 - acc: 0.9693 - val_loss: 0.6502 - val_acc: 0.8958\n",
      "Epoch 1573/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0904 - acc: 0.9727 - val_loss: 0.7319 - val_acc: 0.8874\n",
      "Epoch 1574/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1005 - acc: 0.9660 - val_loss: 0.7361 - val_acc: 0.8941\n",
      "Epoch 1575/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0859 - acc: 0.9689 - val_loss: 0.6191 - val_acc: 0.9059\n",
      "Epoch 1576/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1044 - acc: 0.9681 - val_loss: 0.7346 - val_acc: 0.8891\n",
      "Epoch 1577/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0955 - acc: 0.9672 - val_loss: 0.6936 - val_acc: 0.8941\n",
      "Epoch 1578/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1046 - acc: 0.9651 - val_loss: 0.6560 - val_acc: 0.8874\n",
      "Epoch 1579/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1090 - acc: 0.9643 - val_loss: 0.6629 - val_acc: 0.8941\n",
      "Epoch 1580/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0877 - acc: 0.9714 - val_loss: 0.6546 - val_acc: 0.8975\n",
      "Epoch 1581/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0951 - acc: 0.9723 - val_loss: 0.6811 - val_acc: 0.9025\n",
      "Epoch 1582/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0866 - acc: 0.9689 - val_loss: 0.6745 - val_acc: 0.9042\n",
      "Epoch 1583/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0851 - acc: 0.9706 - val_loss: 0.6710 - val_acc: 0.9059\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1071 - acc: 0.9668 - val_loss: 0.6357 - val_acc: 0.9076\n",
      "Epoch 1585/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0956 - acc: 0.9706 - val_loss: 0.7758 - val_acc: 0.8975\n",
      "Epoch 1586/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0945 - acc: 0.9702 - val_loss: 0.6617 - val_acc: 0.9092\n",
      "Epoch 1587/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1063 - acc: 0.9685 - val_loss: 0.7096 - val_acc: 0.9059\n",
      "Epoch 1588/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0888 - acc: 0.9685 - val_loss: 0.8721 - val_acc: 0.8874\n",
      "Epoch 1589/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1040 - acc: 0.9672 - val_loss: 0.7508 - val_acc: 0.8958\n",
      "Epoch 1590/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1088 - acc: 0.9668 - val_loss: 0.6315 - val_acc: 0.9092\n",
      "Epoch 1591/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1009 - acc: 0.9693 - val_loss: 0.6563 - val_acc: 0.9042\n",
      "Epoch 1592/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1026 - acc: 0.9697 - val_loss: 0.6463 - val_acc: 0.9059\n",
      "Epoch 1593/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1023 - acc: 0.9647 - val_loss: 0.6353 - val_acc: 0.9143\n",
      "Epoch 1594/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1047 - acc: 0.9727 - val_loss: 0.6683 - val_acc: 0.9076\n",
      "Epoch 1595/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0932 - acc: 0.9672 - val_loss: 0.6884 - val_acc: 0.9008\n",
      "Epoch 1596/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1001 - acc: 0.9643 - val_loss: 0.6852 - val_acc: 0.9076\n",
      "Epoch 1597/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0970 - acc: 0.9655 - val_loss: 0.7060 - val_acc: 0.8958\n",
      "Epoch 1598/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0997 - acc: 0.9685 - val_loss: 0.6721 - val_acc: 0.8941\n",
      "Epoch 1599/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0848 - acc: 0.9718 - val_loss: 0.6947 - val_acc: 0.9042\n",
      "Epoch 1600/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1007 - acc: 0.9660 - val_loss: 0.6037 - val_acc: 0.9059\n",
      "Epoch 1601/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0930 - acc: 0.9702 - val_loss: 0.7143 - val_acc: 0.8891\n",
      "Epoch 1602/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0913 - acc: 0.9714 - val_loss: 0.7160 - val_acc: 0.8992\n",
      "Epoch 1603/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1041 - acc: 0.9672 - val_loss: 0.7173 - val_acc: 0.9008\n",
      "Epoch 1604/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0829 - acc: 0.9689 - val_loss: 0.7083 - val_acc: 0.9008\n",
      "Epoch 1605/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0912 - acc: 0.9685 - val_loss: 0.6161 - val_acc: 0.9059\n",
      "Epoch 1606/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1008 - acc: 0.9693 - val_loss: 0.6430 - val_acc: 0.9126\n",
      "Epoch 1607/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0871 - acc: 0.9723 - val_loss: 0.6781 - val_acc: 0.8941\n",
      "Epoch 1608/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0923 - acc: 0.9689 - val_loss: 0.7343 - val_acc: 0.8941\n",
      "Epoch 1609/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0824 - acc: 0.9714 - val_loss: 0.7143 - val_acc: 0.9059\n",
      "Epoch 1610/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0895 - acc: 0.9735 - val_loss: 0.7110 - val_acc: 0.9008\n",
      "Epoch 1611/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1161 - acc: 0.9655 - val_loss: 0.6507 - val_acc: 0.8975\n",
      "Epoch 1612/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1027 - acc: 0.9647 - val_loss: 0.6569 - val_acc: 0.9059\n",
      "Epoch 1613/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0879 - acc: 0.9676 - val_loss: 0.5769 - val_acc: 0.9143\n",
      "Epoch 1614/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0893 - acc: 0.9655 - val_loss: 0.6730 - val_acc: 0.9076\n",
      "Epoch 1615/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0818 - acc: 0.9697 - val_loss: 0.6402 - val_acc: 0.9126\n",
      "Epoch 1616/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0904 - acc: 0.9702 - val_loss: 0.6697 - val_acc: 0.8958\n",
      "Epoch 1617/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0793 - acc: 0.9723 - val_loss: 0.6196 - val_acc: 0.9092\n",
      "Epoch 1618/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0964 - acc: 0.9706 - val_loss: 0.6861 - val_acc: 0.9109\n",
      "Epoch 1619/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0820 - acc: 0.9710 - val_loss: 0.7159 - val_acc: 0.8941\n",
      "Epoch 1620/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0955 - acc: 0.9693 - val_loss: 0.7027 - val_acc: 0.8958\n",
      "Epoch 1621/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0868 - acc: 0.9693 - val_loss: 0.6825 - val_acc: 0.9109\n",
      "Epoch 1622/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1060 - acc: 0.9706 - val_loss: 0.6593 - val_acc: 0.9025\n",
      "Epoch 1623/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1027 - acc: 0.9693 - val_loss: 0.6330 - val_acc: 0.9076\n",
      "Epoch 1624/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0866 - acc: 0.9689 - val_loss: 0.5901 - val_acc: 0.9126\n",
      "Epoch 1625/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0836 - acc: 0.9727 - val_loss: 0.7073 - val_acc: 0.8891\n",
      "Epoch 1626/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0936 - acc: 0.9693 - val_loss: 0.6820 - val_acc: 0.9076\n",
      "Epoch 1627/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0903 - acc: 0.9697 - val_loss: 0.6856 - val_acc: 0.9126\n",
      "Epoch 1628/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1052 - acc: 0.9706 - val_loss: 0.7266 - val_acc: 0.8992\n",
      "Epoch 1629/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0870 - acc: 0.9727 - val_loss: 0.5953 - val_acc: 0.9126\n",
      "Epoch 1630/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1011 - acc: 0.9651 - val_loss: 0.6646 - val_acc: 0.9160\n",
      "Epoch 1631/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0994 - acc: 0.9702 - val_loss: 0.6665 - val_acc: 0.9008\n",
      "Epoch 1632/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0958 - acc: 0.9702 - val_loss: 0.7690 - val_acc: 0.8992\n",
      "Epoch 1633/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1049 - acc: 0.9639 - val_loss: 0.6319 - val_acc: 0.9092\n",
      "Epoch 1634/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0943 - acc: 0.9643 - val_loss: 0.6963 - val_acc: 0.9059\n",
      "Epoch 1635/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0790 - acc: 0.9769 - val_loss: 0.6419 - val_acc: 0.9126\n",
      "Epoch 1636/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1100 - acc: 0.9639 - val_loss: 0.6595 - val_acc: 0.9059\n",
      "Epoch 1637/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1065 - acc: 0.9655 - val_loss: 0.6460 - val_acc: 0.9042\n",
      "Epoch 1638/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0936 - acc: 0.9693 - val_loss: 0.6906 - val_acc: 0.9059\n",
      "Epoch 1639/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1065 - acc: 0.9630 - val_loss: 0.7861 - val_acc: 0.8891\n",
      "Epoch 1640/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0869 - acc: 0.9714 - val_loss: 0.6246 - val_acc: 0.9042\n",
      "Epoch 1641/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0984 - acc: 0.9685 - val_loss: 0.7017 - val_acc: 0.9025\n",
      "Epoch 1642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1000 - acc: 0.9744 - val_loss: 0.6367 - val_acc: 0.9008\n",
      "Epoch 1643/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0984 - acc: 0.9702 - val_loss: 0.6352 - val_acc: 0.9059\n",
      "Epoch 1644/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0831 - acc: 0.9718 - val_loss: 0.6974 - val_acc: 0.8941\n",
      "Epoch 1645/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0966 - acc: 0.9685 - val_loss: 0.6902 - val_acc: 0.8992\n",
      "Epoch 1646/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0745 - acc: 0.9735 - val_loss: 0.6609 - val_acc: 0.9092\n",
      "Epoch 1647/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1000 - acc: 0.9735 - val_loss: 0.6572 - val_acc: 0.9042\n",
      "Epoch 1648/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1078 - acc: 0.9672 - val_loss: 0.5666 - val_acc: 0.9109\n",
      "Epoch 1649/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0975 - acc: 0.9710 - val_loss: 0.7247 - val_acc: 0.8941\n",
      "Epoch 1650/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0805 - acc: 0.9748 - val_loss: 0.7691 - val_acc: 0.8975\n",
      "Epoch 1651/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0973 - acc: 0.9697 - val_loss: 0.6903 - val_acc: 0.9008\n",
      "Epoch 1652/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0872 - acc: 0.9718 - val_loss: 0.6496 - val_acc: 0.8975\n",
      "Epoch 1653/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0926 - acc: 0.9664 - val_loss: 0.6831 - val_acc: 0.8958\n",
      "Epoch 1654/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1016 - acc: 0.9668 - val_loss: 0.6810 - val_acc: 0.8958\n",
      "Epoch 1655/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0882 - acc: 0.9689 - val_loss: 0.6989 - val_acc: 0.8992\n",
      "Epoch 1656/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0991 - acc: 0.9714 - val_loss: 0.6835 - val_acc: 0.8958\n",
      "Epoch 1657/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0923 - acc: 0.9676 - val_loss: 0.6828 - val_acc: 0.9008\n",
      "Epoch 1658/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1097 - acc: 0.9681 - val_loss: 0.8087 - val_acc: 0.8891\n",
      "Epoch 1659/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0932 - acc: 0.9697 - val_loss: 0.6004 - val_acc: 0.9143\n",
      "Epoch 1660/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0841 - acc: 0.9731 - val_loss: 0.6913 - val_acc: 0.9042\n",
      "Epoch 1661/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1033 - acc: 0.9668 - val_loss: 0.6451 - val_acc: 0.8975\n",
      "Epoch 1662/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0916 - acc: 0.9685 - val_loss: 0.6307 - val_acc: 0.9109\n",
      "Epoch 1663/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0995 - acc: 0.9714 - val_loss: 0.6314 - val_acc: 0.8992\n",
      "Epoch 1664/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1034 - acc: 0.9706 - val_loss: 0.6563 - val_acc: 0.9008\n",
      "Epoch 1665/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0932 - acc: 0.9664 - val_loss: 0.6882 - val_acc: 0.8975\n",
      "Epoch 1666/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0842 - acc: 0.9706 - val_loss: 0.6465 - val_acc: 0.8941\n",
      "Epoch 1667/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0942 - acc: 0.9689 - val_loss: 0.6097 - val_acc: 0.9092\n",
      "Epoch 1668/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0880 - acc: 0.9706 - val_loss: 0.6184 - val_acc: 0.9059\n",
      "Epoch 1669/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0932 - acc: 0.9697 - val_loss: 0.6623 - val_acc: 0.8958\n",
      "Epoch 1670/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0964 - acc: 0.9706 - val_loss: 0.6302 - val_acc: 0.9025\n",
      "Epoch 1671/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0985 - acc: 0.9693 - val_loss: 0.6264 - val_acc: 0.9042\n",
      "Epoch 1672/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1061 - acc: 0.9676 - val_loss: 0.7538 - val_acc: 0.8807\n",
      "Epoch 1673/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0817 - acc: 0.9714 - val_loss: 0.6176 - val_acc: 0.9143\n",
      "Epoch 1674/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0946 - acc: 0.9697 - val_loss: 0.6585 - val_acc: 0.9025\n",
      "Epoch 1675/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0909 - acc: 0.9706 - val_loss: 0.6075 - val_acc: 0.9076\n",
      "Epoch 1676/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0935 - acc: 0.9689 - val_loss: 0.6766 - val_acc: 0.9008\n",
      "Epoch 1677/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0824 - acc: 0.9714 - val_loss: 0.6550 - val_acc: 0.9008\n",
      "Epoch 1678/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0988 - acc: 0.9664 - val_loss: 0.6348 - val_acc: 0.8992\n",
      "Epoch 1679/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0849 - acc: 0.9723 - val_loss: 0.7542 - val_acc: 0.9042\n",
      "Epoch 1680/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1000 - acc: 0.9676 - val_loss: 0.5982 - val_acc: 0.9160\n",
      "Epoch 1681/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0897 - acc: 0.9697 - val_loss: 0.8263 - val_acc: 0.8924\n",
      "Epoch 1682/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0860 - acc: 0.9697 - val_loss: 0.6271 - val_acc: 0.9126\n",
      "Epoch 1683/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0970 - acc: 0.9660 - val_loss: 0.8160 - val_acc: 0.8891\n",
      "Epoch 1684/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0942 - acc: 0.9676 - val_loss: 0.6699 - val_acc: 0.9126\n",
      "Epoch 1685/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0799 - acc: 0.9714 - val_loss: 0.6630 - val_acc: 0.8992\n",
      "Epoch 1686/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1149 - acc: 0.9706 - val_loss: 0.6877 - val_acc: 0.9076\n",
      "Epoch 1687/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0966 - acc: 0.9672 - val_loss: 0.6360 - val_acc: 0.9143\n",
      "Epoch 1688/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0855 - acc: 0.9664 - val_loss: 0.8357 - val_acc: 0.8790\n",
      "Epoch 1689/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0965 - acc: 0.9668 - val_loss: 0.5936 - val_acc: 0.9160\n",
      "Epoch 1690/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1119 - acc: 0.9681 - val_loss: 0.7029 - val_acc: 0.9008\n",
      "Epoch 1691/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1088 - acc: 0.9685 - val_loss: 0.6691 - val_acc: 0.9109\n",
      "Epoch 1692/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1002 - acc: 0.9664 - val_loss: 0.6083 - val_acc: 0.9059\n",
      "Epoch 1693/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0847 - acc: 0.9710 - val_loss: 0.6141 - val_acc: 0.9092\n",
      "Epoch 1694/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0888 - acc: 0.9731 - val_loss: 0.7290 - val_acc: 0.8924\n",
      "Epoch 1695/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0995 - acc: 0.9689 - val_loss: 0.7943 - val_acc: 0.8908\n",
      "Epoch 1696/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1008 - acc: 0.9714 - val_loss: 0.6632 - val_acc: 0.9025\n",
      "Epoch 1697/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0971 - acc: 0.9706 - val_loss: 0.6743 - val_acc: 0.9092\n",
      "Epoch 1698/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0902 - acc: 0.9735 - val_loss: 0.6495 - val_acc: 0.9059\n",
      "Epoch 1699/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1048 - acc: 0.9668 - val_loss: 0.6347 - val_acc: 0.9076\n",
      "Epoch 1700/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0816 - acc: 0.9739 - val_loss: 0.7015 - val_acc: 0.9008\n",
      "Epoch 1701/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1011 - acc: 0.9702 - val_loss: 0.6619 - val_acc: 0.9025\n",
      "Epoch 1702/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0993 - acc: 0.9689 - val_loss: 0.6560 - val_acc: 0.9160\n",
      "Epoch 1703/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0984 - acc: 0.9681 - val_loss: 0.7601 - val_acc: 0.9025\n",
      "Epoch 1704/2000\n",
      "2380/2380 [==============================] - 0s 49us/step - loss: 0.0929 - acc: 0.9655 - val_loss: 0.7800 - val_acc: 0.9008\n",
      "Epoch 1705/2000\n",
      "2380/2380 [==============================] - 0s 48us/step - loss: 0.0922 - acc: 0.9668 - val_loss: 0.7028 - val_acc: 0.8975\n",
      "Epoch 1706/2000\n",
      "2380/2380 [==============================] - 0s 54us/step - loss: 0.0858 - acc: 0.9693 - val_loss: 0.7159 - val_acc: 0.8992\n",
      "Epoch 1707/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0897 - acc: 0.9702 - val_loss: 0.7157 - val_acc: 0.9025\n",
      "Epoch 1708/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0935 - acc: 0.9681 - val_loss: 0.6986 - val_acc: 0.9059\n",
      "Epoch 1709/2000\n",
      "2380/2380 [==============================] - 0s 50us/step - loss: 0.0925 - acc: 0.9697 - val_loss: 0.6178 - val_acc: 0.9008\n",
      "Epoch 1710/2000\n",
      "2380/2380 [==============================] - 0s 48us/step - loss: 0.0942 - acc: 0.9672 - val_loss: 0.6671 - val_acc: 0.9092\n",
      "Epoch 1711/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0953 - acc: 0.9744 - val_loss: 0.6503 - val_acc: 0.8975\n",
      "Epoch 1712/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0875 - acc: 0.9697 - val_loss: 0.6199 - val_acc: 0.9092\n",
      "Epoch 1713/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0853 - acc: 0.9706 - val_loss: 0.6499 - val_acc: 0.9143\n",
      "Epoch 1714/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0956 - acc: 0.9718 - val_loss: 0.6941 - val_acc: 0.9008\n",
      "Epoch 1715/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0877 - acc: 0.9782 - val_loss: 0.6941 - val_acc: 0.9025\n",
      "Epoch 1716/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0954 - acc: 0.9664 - val_loss: 0.7381 - val_acc: 0.9042\n",
      "Epoch 1717/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0929 - acc: 0.9664 - val_loss: 0.7686 - val_acc: 0.9008\n",
      "Epoch 1718/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0922 - acc: 0.9702 - val_loss: 0.7183 - val_acc: 0.8874\n",
      "Epoch 1719/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0892 - acc: 0.9685 - val_loss: 0.6950 - val_acc: 0.9076\n",
      "Epoch 1720/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0917 - acc: 0.9706 - val_loss: 0.6861 - val_acc: 0.9076\n",
      "Epoch 1721/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0946 - acc: 0.9714 - val_loss: 0.6887 - val_acc: 0.8941\n",
      "Epoch 1722/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0892 - acc: 0.9693 - val_loss: 0.6467 - val_acc: 0.8941\n",
      "Epoch 1723/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1040 - acc: 0.9685 - val_loss: 0.7114 - val_acc: 0.9042\n",
      "Epoch 1724/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0798 - acc: 0.9702 - val_loss: 0.6760 - val_acc: 0.9025\n",
      "Epoch 1725/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0954 - acc: 0.9672 - val_loss: 0.6466 - val_acc: 0.9176\n",
      "Epoch 1726/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0888 - acc: 0.9689 - val_loss: 0.6500 - val_acc: 0.9092\n",
      "Epoch 1727/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0802 - acc: 0.9710 - val_loss: 0.6478 - val_acc: 0.9109\n",
      "Epoch 1728/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0892 - acc: 0.9681 - val_loss: 0.7215 - val_acc: 0.9008\n",
      "Epoch 1729/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0966 - acc: 0.9685 - val_loss: 0.6871 - val_acc: 0.9092\n",
      "Epoch 1730/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0876 - acc: 0.9693 - val_loss: 0.6331 - val_acc: 0.9042\n",
      "Epoch 1731/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1002 - acc: 0.9714 - val_loss: 0.7199 - val_acc: 0.9008\n",
      "Epoch 1732/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0805 - acc: 0.9739 - val_loss: 0.6461 - val_acc: 0.9059\n",
      "Epoch 1733/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0773 - acc: 0.9748 - val_loss: 0.7438 - val_acc: 0.8924\n",
      "Epoch 1734/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1001 - acc: 0.9664 - val_loss: 0.6257 - val_acc: 0.9076\n",
      "Epoch 1735/2000\n",
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0909 - acc: 0.9710 - val_loss: 0.7790 - val_acc: 0.8857\n",
      "Epoch 1736/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0773 - acc: 0.9731 - val_loss: 0.6775 - val_acc: 0.9025\n",
      "Epoch 1737/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0951 - acc: 0.9697 - val_loss: 0.7749 - val_acc: 0.8874\n",
      "Epoch 1738/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0826 - acc: 0.9702 - val_loss: 0.6132 - val_acc: 0.9076\n",
      "Epoch 1739/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1166 - acc: 0.9651 - val_loss: 0.7457 - val_acc: 0.8992\n",
      "Epoch 1740/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0851 - acc: 0.9748 - val_loss: 0.6413 - val_acc: 0.9210\n",
      "Epoch 1741/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0919 - acc: 0.9710 - val_loss: 0.6935 - val_acc: 0.9008\n",
      "Epoch 1742/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0966 - acc: 0.9689 - val_loss: 0.7417 - val_acc: 0.8975\n",
      "Epoch 1743/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0851 - acc: 0.9714 - val_loss: 0.7007 - val_acc: 0.9042\n",
      "Epoch 1744/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0924 - acc: 0.9723 - val_loss: 0.7106 - val_acc: 0.9025\n",
      "Epoch 1745/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0934 - acc: 0.9681 - val_loss: 0.7208 - val_acc: 0.8924\n",
      "Epoch 1746/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0921 - acc: 0.9710 - val_loss: 0.7170 - val_acc: 0.9025\n",
      "Epoch 1747/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0977 - acc: 0.9718 - val_loss: 0.6476 - val_acc: 0.9109\n",
      "Epoch 1748/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0942 - acc: 0.9727 - val_loss: 0.7288 - val_acc: 0.9092\n",
      "Epoch 1749/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1010 - acc: 0.9689 - val_loss: 0.7059 - val_acc: 0.9160\n",
      "Epoch 1750/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0958 - acc: 0.9681 - val_loss: 0.8527 - val_acc: 0.8857\n",
      "Epoch 1751/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1030 - acc: 0.9681 - val_loss: 0.6940 - val_acc: 0.8941\n",
      "Epoch 1752/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0939 - acc: 0.9693 - val_loss: 0.6311 - val_acc: 0.9160\n",
      "Epoch 1753/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1109 - acc: 0.9668 - val_loss: 0.7278 - val_acc: 0.8924\n",
      "Epoch 1754/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0841 - acc: 0.9710 - val_loss: 0.8118 - val_acc: 0.8975\n",
      "Epoch 1755/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0847 - acc: 0.9710 - val_loss: 0.6622 - val_acc: 0.9092\n",
      "Epoch 1756/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1002 - acc: 0.9681 - val_loss: 0.6652 - val_acc: 0.9092\n",
      "Epoch 1757/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0870 - acc: 0.9723 - val_loss: 0.6724 - val_acc: 0.9008\n",
      "Epoch 1758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 39us/step - loss: 0.0992 - acc: 0.9710 - val_loss: 0.6611 - val_acc: 0.9109\n",
      "Epoch 1759/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0803 - acc: 0.9681 - val_loss: 0.8646 - val_acc: 0.8773\n",
      "Epoch 1760/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0902 - acc: 0.9672 - val_loss: 0.7217 - val_acc: 0.8958\n",
      "Epoch 1761/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1033 - acc: 0.9643 - val_loss: 0.7320 - val_acc: 0.9025\n",
      "Epoch 1762/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0905 - acc: 0.9706 - val_loss: 0.6976 - val_acc: 0.8958\n",
      "Epoch 1763/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0971 - acc: 0.9693 - val_loss: 0.6060 - val_acc: 0.9160\n",
      "Epoch 1764/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0890 - acc: 0.9714 - val_loss: 0.7436 - val_acc: 0.8992\n",
      "Epoch 1765/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0974 - acc: 0.9714 - val_loss: 0.7262 - val_acc: 0.9025\n",
      "Epoch 1766/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0816 - acc: 0.9752 - val_loss: 0.6453 - val_acc: 0.9160\n",
      "Epoch 1767/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0902 - acc: 0.9685 - val_loss: 0.6640 - val_acc: 0.9025\n",
      "Epoch 1768/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0891 - acc: 0.9702 - val_loss: 0.6680 - val_acc: 0.9092\n",
      "Epoch 1769/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0896 - acc: 0.9731 - val_loss: 0.6921 - val_acc: 0.8924\n",
      "Epoch 1770/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0913 - acc: 0.9727 - val_loss: 0.6725 - val_acc: 0.9059\n",
      "Epoch 1771/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0885 - acc: 0.9727 - val_loss: 0.7656 - val_acc: 0.9008\n",
      "Epoch 1772/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1076 - acc: 0.9689 - val_loss: 0.6094 - val_acc: 0.9109\n",
      "Epoch 1773/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0776 - acc: 0.9727 - val_loss: 0.6890 - val_acc: 0.9076\n",
      "Epoch 1774/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1065 - acc: 0.9664 - val_loss: 0.7265 - val_acc: 0.9008\n",
      "Epoch 1775/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0871 - acc: 0.9748 - val_loss: 0.6856 - val_acc: 0.9076\n",
      "Epoch 1776/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0891 - acc: 0.9714 - val_loss: 0.7739 - val_acc: 0.9008\n",
      "Epoch 1777/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.1050 - acc: 0.9676 - val_loss: 0.6266 - val_acc: 0.9193\n",
      "Epoch 1778/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0844 - acc: 0.9731 - val_loss: 0.6547 - val_acc: 0.9076\n",
      "Epoch 1779/2000\n",
      "2380/2380 [==============================] - 0s 49us/step - loss: 0.0941 - acc: 0.9714 - val_loss: 0.9768 - val_acc: 0.8773\n",
      "Epoch 1780/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0836 - acc: 0.9718 - val_loss: 0.7094 - val_acc: 0.9008\n",
      "Epoch 1781/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0910 - acc: 0.9706 - val_loss: 0.6926 - val_acc: 0.9126\n",
      "Epoch 1782/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1082 - acc: 0.9676 - val_loss: 0.6670 - val_acc: 0.9025\n",
      "Epoch 1783/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0912 - acc: 0.9727 - val_loss: 0.6237 - val_acc: 0.8975\n",
      "Epoch 1784/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0796 - acc: 0.9748 - val_loss: 0.6724 - val_acc: 0.9109\n",
      "Epoch 1785/2000\n",
      "2380/2380 [==============================] - 0s 48us/step - loss: 0.0969 - acc: 0.9681 - val_loss: 0.7800 - val_acc: 0.8975\n",
      "Epoch 1786/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0924 - acc: 0.9681 - val_loss: 0.6107 - val_acc: 0.9160\n",
      "Epoch 1787/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0912 - acc: 0.9689 - val_loss: 0.6509 - val_acc: 0.9160\n",
      "Epoch 1788/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1005 - acc: 0.9693 - val_loss: 0.7417 - val_acc: 0.9025\n",
      "Epoch 1789/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0992 - acc: 0.9664 - val_loss: 0.7391 - val_acc: 0.9092\n",
      "Epoch 1790/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0855 - acc: 0.9723 - val_loss: 0.7047 - val_acc: 0.8874\n",
      "Epoch 1791/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0900 - acc: 0.9693 - val_loss: 0.6980 - val_acc: 0.9059\n",
      "Epoch 1792/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0906 - acc: 0.9702 - val_loss: 0.7380 - val_acc: 0.8773\n",
      "Epoch 1793/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0966 - acc: 0.9697 - val_loss: 0.6637 - val_acc: 0.9042\n",
      "Epoch 1794/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0845 - acc: 0.9714 - val_loss: 0.6598 - val_acc: 0.9176\n",
      "Epoch 1795/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0935 - acc: 0.9735 - val_loss: 0.7851 - val_acc: 0.8975\n",
      "Epoch 1796/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0950 - acc: 0.9693 - val_loss: 0.6852 - val_acc: 0.9109\n",
      "Epoch 1797/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0914 - acc: 0.9676 - val_loss: 0.6932 - val_acc: 0.8992\n",
      "Epoch 1798/2000\n",
      "2380/2380 [==============================] - 0s 48us/step - loss: 0.0831 - acc: 0.9685 - val_loss: 0.6747 - val_acc: 0.9126\n",
      "Epoch 1799/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0885 - acc: 0.9697 - val_loss: 0.7935 - val_acc: 0.9008\n",
      "Epoch 1800/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0917 - acc: 0.9702 - val_loss: 0.7556 - val_acc: 0.9059\n",
      "Epoch 1801/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0795 - acc: 0.9723 - val_loss: 0.6030 - val_acc: 0.9193\n",
      "Epoch 1802/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0792 - acc: 0.9739 - val_loss: 0.7441 - val_acc: 0.9109\n",
      "Epoch 1803/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0896 - acc: 0.9664 - val_loss: 0.7427 - val_acc: 0.8958\n",
      "Epoch 1804/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0883 - acc: 0.9714 - val_loss: 0.6984 - val_acc: 0.9143\n",
      "Epoch 1805/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0846 - acc: 0.9739 - val_loss: 0.7007 - val_acc: 0.9076\n",
      "Epoch 1806/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0896 - acc: 0.9693 - val_loss: 0.8211 - val_acc: 0.8941\n",
      "Epoch 1807/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0938 - acc: 0.9664 - val_loss: 0.7612 - val_acc: 0.8958\n",
      "Epoch 1808/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0930 - acc: 0.9676 - val_loss: 0.7134 - val_acc: 0.9109\n",
      "Epoch 1809/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0806 - acc: 0.9752 - val_loss: 0.6798 - val_acc: 0.9076\n",
      "Epoch 1810/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0962 - acc: 0.9702 - val_loss: 0.7503 - val_acc: 0.8958\n",
      "Epoch 1811/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0902 - acc: 0.9723 - val_loss: 0.8015 - val_acc: 0.9076\n",
      "Epoch 1812/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0929 - acc: 0.9689 - val_loss: 0.7478 - val_acc: 0.9126\n",
      "Epoch 1813/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0933 - acc: 0.9702 - val_loss: 0.7427 - val_acc: 0.9008\n",
      "Epoch 1814/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0849 - acc: 0.9702 - val_loss: 0.6902 - val_acc: 0.9193\n",
      "Epoch 1815/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0926 - acc: 0.9693 - val_loss: 0.6939 - val_acc: 0.9126\n",
      "Epoch 1816/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0856 - acc: 0.9697 - val_loss: 0.6779 - val_acc: 0.9059\n",
      "Epoch 1817/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0755 - acc: 0.9744 - val_loss: 0.7037 - val_acc: 0.9109\n",
      "Epoch 1818/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1021 - acc: 0.9685 - val_loss: 0.7192 - val_acc: 0.8941\n",
      "Epoch 1819/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0874 - acc: 0.9723 - val_loss: 0.6104 - val_acc: 0.9109\n",
      "Epoch 1820/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0839 - acc: 0.9714 - val_loss: 0.6671 - val_acc: 0.9059\n",
      "Epoch 1821/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0897 - acc: 0.9756 - val_loss: 0.6572 - val_acc: 0.9210\n",
      "Epoch 1822/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0805 - acc: 0.9710 - val_loss: 0.6664 - val_acc: 0.9126\n",
      "Epoch 1823/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0910 - acc: 0.9731 - val_loss: 0.6968 - val_acc: 0.9042\n",
      "Epoch 1824/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0944 - acc: 0.9710 - val_loss: 0.6578 - val_acc: 0.9109\n",
      "Epoch 1825/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0768 - acc: 0.9752 - val_loss: 0.8314 - val_acc: 0.8773\n",
      "Epoch 1826/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0904 - acc: 0.9718 - val_loss: 0.7397 - val_acc: 0.9008\n",
      "Epoch 1827/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0998 - acc: 0.9731 - val_loss: 0.6737 - val_acc: 0.9160\n",
      "Epoch 1828/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0927 - acc: 0.9710 - val_loss: 0.8276 - val_acc: 0.8941\n",
      "Epoch 1829/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0951 - acc: 0.9714 - val_loss: 0.7031 - val_acc: 0.9160\n",
      "Epoch 1830/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0927 - acc: 0.9672 - val_loss: 0.7579 - val_acc: 0.8840\n",
      "Epoch 1831/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0863 - acc: 0.9744 - val_loss: 0.7102 - val_acc: 0.9193\n",
      "Epoch 1832/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0842 - acc: 0.9735 - val_loss: 0.7237 - val_acc: 0.8924\n",
      "Epoch 1833/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0955 - acc: 0.9689 - val_loss: 0.6670 - val_acc: 0.9059\n",
      "Epoch 1834/2000\n",
      "2380/2380 [==============================] - 0s 61us/step - loss: 0.0998 - acc: 0.9685 - val_loss: 0.7588 - val_acc: 0.9042\n",
      "Epoch 1835/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0864 - acc: 0.9756 - val_loss: 0.8190 - val_acc: 0.8941\n",
      "Epoch 1836/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0971 - acc: 0.9676 - val_loss: 0.6859 - val_acc: 0.8891\n",
      "Epoch 1837/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0771 - acc: 0.9727 - val_loss: 0.6973 - val_acc: 0.8941\n",
      "Epoch 1838/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0912 - acc: 0.9735 - val_loss: 0.7535 - val_acc: 0.8924\n",
      "Epoch 1839/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0952 - acc: 0.9693 - val_loss: 0.7547 - val_acc: 0.8941\n",
      "Epoch 1840/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0886 - acc: 0.9706 - val_loss: 0.7742 - val_acc: 0.8958\n",
      "Epoch 1841/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0838 - acc: 0.9714 - val_loss: 0.7736 - val_acc: 0.9059\n",
      "Epoch 1842/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0882 - acc: 0.9702 - val_loss: 0.7038 - val_acc: 0.8941\n",
      "Epoch 1843/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0834 - acc: 0.9702 - val_loss: 0.6776 - val_acc: 0.9143\n",
      "Epoch 1844/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0891 - acc: 0.9727 - val_loss: 0.6578 - val_acc: 0.9160\n",
      "Epoch 1845/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0870 - acc: 0.9693 - val_loss: 0.6911 - val_acc: 0.9059\n",
      "Epoch 1846/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0962 - acc: 0.9702 - val_loss: 0.6462 - val_acc: 0.9008\n",
      "Epoch 1847/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1041 - acc: 0.9702 - val_loss: 0.7191 - val_acc: 0.9092\n",
      "Epoch 1848/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1006 - acc: 0.9676 - val_loss: 0.7851 - val_acc: 0.8975\n",
      "Epoch 1849/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0857 - acc: 0.9714 - val_loss: 0.6184 - val_acc: 0.9126\n",
      "Epoch 1850/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0929 - acc: 0.9706 - val_loss: 0.7093 - val_acc: 0.8958\n",
      "Epoch 1851/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0819 - acc: 0.9723 - val_loss: 0.7904 - val_acc: 0.8975\n",
      "Epoch 1852/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0860 - acc: 0.9710 - val_loss: 0.6148 - val_acc: 0.9109\n",
      "Epoch 1853/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1032 - acc: 0.9685 - val_loss: 0.7197 - val_acc: 0.9042\n",
      "Epoch 1854/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0835 - acc: 0.9714 - val_loss: 0.6710 - val_acc: 0.9109\n",
      "Epoch 1855/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0940 - acc: 0.9706 - val_loss: 0.6402 - val_acc: 0.8992\n",
      "Epoch 1856/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0914 - acc: 0.9702 - val_loss: 0.7021 - val_acc: 0.8941\n",
      "Epoch 1857/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0920 - acc: 0.9710 - val_loss: 0.6284 - val_acc: 0.9092\n",
      "Epoch 1858/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0875 - acc: 0.9718 - val_loss: 0.6311 - val_acc: 0.9143\n",
      "Epoch 1859/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0917 - acc: 0.9735 - val_loss: 0.7328 - val_acc: 0.9076\n",
      "Epoch 1860/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0913 - acc: 0.9681 - val_loss: 0.6785 - val_acc: 0.9160\n",
      "Epoch 1861/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0889 - acc: 0.9697 - val_loss: 0.6306 - val_acc: 0.9143\n",
      "Epoch 1862/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0999 - acc: 0.9685 - val_loss: 0.7793 - val_acc: 0.8975\n",
      "Epoch 1863/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0833 - acc: 0.9718 - val_loss: 0.6462 - val_acc: 0.9109\n",
      "Epoch 1864/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0832 - acc: 0.9748 - val_loss: 0.7238 - val_acc: 0.8975\n",
      "Epoch 1865/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0917 - acc: 0.9676 - val_loss: 0.8567 - val_acc: 0.8706\n",
      "Epoch 1866/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0795 - acc: 0.9731 - val_loss: 0.9350 - val_acc: 0.8689\n",
      "Epoch 1867/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1104 - acc: 0.9718 - val_loss: 0.7747 - val_acc: 0.8975\n",
      "Epoch 1868/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0942 - acc: 0.9702 - val_loss: 0.7220 - val_acc: 0.8958\n",
      "Epoch 1869/2000\n",
      "2380/2380 [==============================] - 0s 40us/step - loss: 0.0869 - acc: 0.9706 - val_loss: 0.6995 - val_acc: 0.9092\n",
      "Epoch 1870/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0936 - acc: 0.9723 - val_loss: 0.6877 - val_acc: 0.9042\n",
      "Epoch 1871/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0791 - acc: 0.9748 - val_loss: 0.6924 - val_acc: 0.9008\n",
      "Epoch 1872/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0870 - acc: 0.9706 - val_loss: 0.6751 - val_acc: 0.9109\n",
      "Epoch 1873/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0995 - acc: 0.9685 - val_loss: 0.6898 - val_acc: 0.9143\n",
      "Epoch 1874/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0786 - acc: 0.9786 - val_loss: 0.6862 - val_acc: 0.8992\n",
      "Epoch 1875/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0847 - acc: 0.9765 - val_loss: 0.7223 - val_acc: 0.8908\n",
      "Epoch 1876/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0890 - acc: 0.9697 - val_loss: 0.6800 - val_acc: 0.9059\n",
      "Epoch 1877/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1139 - acc: 0.9668 - val_loss: 0.8174 - val_acc: 0.8924\n",
      "Epoch 1878/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0903 - acc: 0.9706 - val_loss: 0.7669 - val_acc: 0.8908\n",
      "Epoch 1879/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0953 - acc: 0.9681 - val_loss: 0.7710 - val_acc: 0.8958\n",
      "Epoch 1880/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0986 - acc: 0.9664 - val_loss: 0.8868 - val_acc: 0.8908\n",
      "Epoch 1881/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0949 - acc: 0.9681 - val_loss: 0.7882 - val_acc: 0.8857\n",
      "Epoch 1882/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0978 - acc: 0.9693 - val_loss: 0.7744 - val_acc: 0.8874\n",
      "Epoch 1883/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0843 - acc: 0.9706 - val_loss: 0.6724 - val_acc: 0.9092\n",
      "Epoch 1884/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0874 - acc: 0.9676 - val_loss: 0.7133 - val_acc: 0.9076\n",
      "Epoch 1885/2000\n",
      "2380/2380 [==============================] - 0s 51us/step - loss: 0.1226 - acc: 0.9647 - val_loss: 0.6500 - val_acc: 0.9025\n",
      "Epoch 1886/2000\n",
      "2380/2380 [==============================] - 0s 47us/step - loss: 0.0914 - acc: 0.9723 - val_loss: 0.6784 - val_acc: 0.9092\n",
      "Epoch 1887/2000\n",
      "2380/2380 [==============================] - 0s 49us/step - loss: 0.0994 - acc: 0.9668 - val_loss: 0.7213 - val_acc: 0.8941\n",
      "Epoch 1888/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0853 - acc: 0.9689 - val_loss: 0.6417 - val_acc: 0.9008\n",
      "Epoch 1889/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0971 - acc: 0.9685 - val_loss: 0.6418 - val_acc: 0.9092\n",
      "Epoch 1890/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1040 - acc: 0.9689 - val_loss: 0.6530 - val_acc: 0.9126\n",
      "Epoch 1891/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0973 - acc: 0.9710 - val_loss: 0.6724 - val_acc: 0.9025\n",
      "Epoch 1892/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0806 - acc: 0.9752 - val_loss: 0.7212 - val_acc: 0.9143\n",
      "Epoch 1893/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1097 - acc: 0.9706 - val_loss: 0.7571 - val_acc: 0.8874\n",
      "Epoch 1894/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0921 - acc: 0.9744 - val_loss: 0.7485 - val_acc: 0.8908\n",
      "Epoch 1895/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0957 - acc: 0.9702 - val_loss: 0.6997 - val_acc: 0.9076\n",
      "Epoch 1896/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0926 - acc: 0.9752 - val_loss: 0.8152 - val_acc: 0.8824\n",
      "Epoch 1897/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0910 - acc: 0.9693 - val_loss: 0.6489 - val_acc: 0.9126\n",
      "Epoch 1898/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.1066 - acc: 0.9693 - val_loss: 0.7251 - val_acc: 0.8908\n",
      "Epoch 1899/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0856 - acc: 0.9706 - val_loss: 0.7470 - val_acc: 0.8958\n",
      "Epoch 1900/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0924 - acc: 0.9739 - val_loss: 0.7129 - val_acc: 0.9160\n",
      "Epoch 1901/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0911 - acc: 0.9731 - val_loss: 0.6794 - val_acc: 0.9193\n",
      "Epoch 1902/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0967 - acc: 0.9693 - val_loss: 0.7442 - val_acc: 0.9059\n",
      "Epoch 1903/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0895 - acc: 0.9731 - val_loss: 0.7254 - val_acc: 0.9025\n",
      "Epoch 1904/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0895 - acc: 0.9702 - val_loss: 0.8313 - val_acc: 0.8924\n",
      "Epoch 1905/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0920 - acc: 0.9689 - val_loss: 0.7662 - val_acc: 0.8874\n",
      "Epoch 1906/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0889 - acc: 0.9685 - val_loss: 0.6801 - val_acc: 0.9193\n",
      "Epoch 1907/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0998 - acc: 0.9655 - val_loss: 0.6932 - val_acc: 0.8958\n",
      "Epoch 1908/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0950 - acc: 0.9710 - val_loss: 0.7433 - val_acc: 0.9025\n",
      "Epoch 1909/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0841 - acc: 0.9731 - val_loss: 0.7929 - val_acc: 0.9059\n",
      "Epoch 1910/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0964 - acc: 0.9735 - val_loss: 0.7206 - val_acc: 0.8958\n",
      "Epoch 1911/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0825 - acc: 0.9735 - val_loss: 0.8517 - val_acc: 0.8958\n",
      "Epoch 1912/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0918 - acc: 0.9706 - val_loss: 0.7131 - val_acc: 0.9042\n",
      "Epoch 1913/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1096 - acc: 0.9685 - val_loss: 0.7350 - val_acc: 0.9042\n",
      "Epoch 1914/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0946 - acc: 0.9685 - val_loss: 0.8401 - val_acc: 0.8840\n",
      "Epoch 1915/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0811 - acc: 0.9748 - val_loss: 0.7286 - val_acc: 0.9076\n",
      "Epoch 1916/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0924 - acc: 0.9681 - val_loss: 0.6657 - val_acc: 0.9109\n",
      "Epoch 1917/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1027 - acc: 0.9735 - val_loss: 0.7349 - val_acc: 0.9143\n",
      "Epoch 1918/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.1045 - acc: 0.9685 - val_loss: 0.6520 - val_acc: 0.9126\n",
      "Epoch 1919/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0838 - acc: 0.9735 - val_loss: 0.7210 - val_acc: 0.9008\n",
      "Epoch 1920/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0936 - acc: 0.9718 - val_loss: 0.7182 - val_acc: 0.9076\n",
      "Epoch 1921/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1045 - acc: 0.9718 - val_loss: 0.7534 - val_acc: 0.9042\n",
      "Epoch 1922/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1078 - acc: 0.9710 - val_loss: 0.7794 - val_acc: 0.9092\n",
      "Epoch 1923/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0933 - acc: 0.9693 - val_loss: 0.7070 - val_acc: 0.9025\n",
      "Epoch 1924/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0987 - acc: 0.9651 - val_loss: 0.7064 - val_acc: 0.9092\n",
      "Epoch 1925/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0773 - acc: 0.9727 - val_loss: 0.6267 - val_acc: 0.9059\n",
      "Epoch 1926/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0932 - acc: 0.9689 - val_loss: 0.7098 - val_acc: 0.9092\n",
      "Epoch 1927/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0922 - acc: 0.9689 - val_loss: 0.7245 - val_acc: 0.8992\n",
      "Epoch 1928/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0827 - acc: 0.9706 - val_loss: 0.7630 - val_acc: 0.9059\n",
      "Epoch 1929/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0983 - acc: 0.9693 - val_loss: 0.6490 - val_acc: 0.9076\n",
      "Epoch 1930/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0823 - acc: 0.9702 - val_loss: 0.7610 - val_acc: 0.8958\n",
      "Epoch 1931/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0886 - acc: 0.9739 - val_loss: 0.6959 - val_acc: 0.9092\n",
      "Epoch 1932/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0995 - acc: 0.9676 - val_loss: 0.7353 - val_acc: 0.9042\n",
      "Epoch 1933/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0869 - acc: 0.9727 - val_loss: 0.6224 - val_acc: 0.9126\n",
      "Epoch 1934/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0822 - acc: 0.9710 - val_loss: 0.9675 - val_acc: 0.8891\n",
      "Epoch 1935/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.1028 - acc: 0.9714 - val_loss: 0.7133 - val_acc: 0.9059\n",
      "Epoch 1936/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0908 - acc: 0.9697 - val_loss: 0.7228 - val_acc: 0.9042\n",
      "Epoch 1937/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0921 - acc: 0.9727 - val_loss: 0.7975 - val_acc: 0.8807\n",
      "Epoch 1938/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0906 - acc: 0.9689 - val_loss: 0.6770 - val_acc: 0.9008\n",
      "Epoch 1939/2000\n",
      "2380/2380 [==============================] - 0s 41us/step - loss: 0.0798 - acc: 0.9748 - val_loss: 0.7093 - val_acc: 0.8908\n",
      "Epoch 1940/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0912 - acc: 0.9714 - val_loss: 0.9036 - val_acc: 0.8891\n",
      "Epoch 1941/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0919 - acc: 0.9727 - val_loss: 0.8010 - val_acc: 0.9025\n",
      "Epoch 1942/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0915 - acc: 0.9693 - val_loss: 0.6858 - val_acc: 0.8992\n",
      "Epoch 1943/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0851 - acc: 0.9731 - val_loss: 0.6830 - val_acc: 0.9193\n",
      "Epoch 1944/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0976 - acc: 0.9710 - val_loss: 0.6322 - val_acc: 0.9076\n",
      "Epoch 1945/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0985 - acc: 0.9718 - val_loss: 0.7829 - val_acc: 0.8992\n",
      "Epoch 1946/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1058 - acc: 0.9689 - val_loss: 0.6483 - val_acc: 0.9042\n",
      "Epoch 1947/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0850 - acc: 0.9735 - val_loss: 0.6585 - val_acc: 0.9126\n",
      "Epoch 1948/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0954 - acc: 0.9685 - val_loss: 0.6936 - val_acc: 0.9059\n",
      "Epoch 1949/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0864 - acc: 0.9752 - val_loss: 0.6553 - val_acc: 0.9126\n",
      "Epoch 1950/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0887 - acc: 0.9731 - val_loss: 0.6854 - val_acc: 0.8891\n",
      "Epoch 1951/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1027 - acc: 0.9739 - val_loss: 0.6542 - val_acc: 0.9143\n",
      "Epoch 1952/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0846 - acc: 0.9723 - val_loss: 0.7486 - val_acc: 0.9092\n",
      "Epoch 1953/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0984 - acc: 0.9664 - val_loss: 0.7111 - val_acc: 0.9160\n",
      "Epoch 1954/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0897 - acc: 0.9748 - val_loss: 0.7331 - val_acc: 0.8992\n",
      "Epoch 1955/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0816 - acc: 0.9689 - val_loss: 0.7187 - val_acc: 0.9092\n",
      "Epoch 1956/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0984 - acc: 0.9681 - val_loss: 0.7212 - val_acc: 0.8908\n",
      "Epoch 1957/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1019 - acc: 0.9655 - val_loss: 0.7157 - val_acc: 0.9126\n",
      "Epoch 1958/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0910 - acc: 0.9710 - val_loss: 0.6729 - val_acc: 0.9092\n",
      "Epoch 1959/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0911 - acc: 0.9689 - val_loss: 0.6899 - val_acc: 0.9008\n",
      "Epoch 1960/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0945 - acc: 0.9723 - val_loss: 0.6878 - val_acc: 0.9076\n",
      "Epoch 1961/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0851 - acc: 0.9752 - val_loss: 0.7568 - val_acc: 0.9025\n",
      "Epoch 1962/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0864 - acc: 0.9748 - val_loss: 0.6604 - val_acc: 0.9109\n",
      "Epoch 1963/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0981 - acc: 0.9727 - val_loss: 0.7839 - val_acc: 0.8958\n",
      "Epoch 1964/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1011 - acc: 0.9664 - val_loss: 0.7105 - val_acc: 0.9160\n",
      "Epoch 1965/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0865 - acc: 0.9752 - val_loss: 0.7055 - val_acc: 0.9059\n",
      "Epoch 1966/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0865 - acc: 0.9710 - val_loss: 0.7131 - val_acc: 0.9160\n",
      "Epoch 1967/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0899 - acc: 0.9685 - val_loss: 0.7617 - val_acc: 0.8992\n",
      "Epoch 1968/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0888 - acc: 0.9668 - val_loss: 0.7199 - val_acc: 0.8975\n",
      "Epoch 1969/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1003 - acc: 0.9647 - val_loss: 0.6950 - val_acc: 0.9092\n",
      "Epoch 1970/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0929 - acc: 0.9710 - val_loss: 0.7118 - val_acc: 0.8958\n",
      "Epoch 1971/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0858 - acc: 0.9748 - val_loss: 0.7356 - val_acc: 0.9126\n",
      "Epoch 1972/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0809 - acc: 0.9756 - val_loss: 0.7143 - val_acc: 0.9143\n",
      "Epoch 1973/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0923 - acc: 0.9706 - val_loss: 0.7107 - val_acc: 0.9109\n",
      "Epoch 1974/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.1094 - acc: 0.9672 - val_loss: 0.6579 - val_acc: 0.9160\n",
      "Epoch 1975/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0979 - acc: 0.9689 - val_loss: 0.6901 - val_acc: 0.9143\n",
      "Epoch 1976/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0801 - acc: 0.9735 - val_loss: 0.6850 - val_acc: 0.9109\n",
      "Epoch 1977/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0976 - acc: 0.9727 - val_loss: 0.6561 - val_acc: 0.9126\n",
      "Epoch 1978/2000\n",
      "2380/2380 [==============================] - 0s 46us/step - loss: 0.0774 - acc: 0.9744 - val_loss: 0.7764 - val_acc: 0.8908\n",
      "Epoch 1979/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1143 - acc: 0.9676 - val_loss: 0.6496 - val_acc: 0.9059\n",
      "Epoch 1980/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0993 - acc: 0.9660 - val_loss: 0.6854 - val_acc: 0.9008\n",
      "Epoch 1981/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0877 - acc: 0.9706 - val_loss: 0.6768 - val_acc: 0.9008\n",
      "Epoch 1982/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0959 - acc: 0.9689 - val_loss: 0.6906 - val_acc: 0.9025\n",
      "Epoch 1983/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0835 - acc: 0.9731 - val_loss: 0.7150 - val_acc: 0.9059\n",
      "Epoch 1984/2000\n",
      "2380/2380 [==============================] - 0s 45us/step - loss: 0.0970 - acc: 0.9727 - val_loss: 0.6775 - val_acc: 0.9092\n",
      "Epoch 1985/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0839 - acc: 0.9706 - val_loss: 0.6379 - val_acc: 0.9042\n",
      "Epoch 1986/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1111 - acc: 0.9651 - val_loss: 0.7146 - val_acc: 0.9042\n",
      "Epoch 1987/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0910 - acc: 0.9765 - val_loss: 0.7300 - val_acc: 0.8992\n",
      "Epoch 1988/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0916 - acc: 0.9685 - val_loss: 0.7102 - val_acc: 0.9109\n",
      "Epoch 1989/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0951 - acc: 0.9706 - val_loss: 0.6879 - val_acc: 0.9092\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0950 - acc: 0.9731 - val_loss: 0.8098 - val_acc: 0.8958\n",
      "Epoch 1991/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0785 - acc: 0.9739 - val_loss: 0.7088 - val_acc: 0.9059\n",
      "Epoch 1992/2000\n",
      "2380/2380 [==============================] - 0s 42us/step - loss: 0.0973 - acc: 0.9689 - val_loss: 0.7012 - val_acc: 0.9126\n",
      "Epoch 1993/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0857 - acc: 0.9718 - val_loss: 0.6877 - val_acc: 0.9076\n",
      "Epoch 1994/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0825 - acc: 0.9693 - val_loss: 0.7850 - val_acc: 0.9076\n",
      "Epoch 1995/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.1021 - acc: 0.9689 - val_loss: 0.6778 - val_acc: 0.9025\n",
      "Epoch 1996/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0900 - acc: 0.9727 - val_loss: 0.7875 - val_acc: 0.8975\n",
      "Epoch 1997/2000\n",
      "2380/2380 [==============================] - 0s 43us/step - loss: 0.0924 - acc: 0.9706 - val_loss: 0.7167 - val_acc: 0.9076\n",
      "Epoch 1998/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0824 - acc: 0.9714 - val_loss: 0.6249 - val_acc: 0.9160\n",
      "Epoch 1999/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0899 - acc: 0.9681 - val_loss: 0.6675 - val_acc: 0.9126\n",
      "Epoch 2000/2000\n",
      "2380/2380 [==============================] - 0s 44us/step - loss: 0.0927 - acc: 0.9714 - val_loss: 0.6568 - val_acc: 0.9109\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=2000, batch_size=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"acc\"],  label=[\"acc\"])\n",
    "plt.plot(history.history['val_acc'], label=[\"val_acc\"])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=[\"loss\"]) \n",
    "plt.plot(history.history['val_loss'], label=[\"val_loss\"])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. 5. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 0s 19us/step\n",
      "Loss / Accuracy Evaluation\n",
      "--------------------------\n",
      "Loss:     0.60622\n",
      "Accuracy: 0.92876\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss / Accuracy Evaluation\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Loss:     \" + str(round(test_loss,5)))\n",
    "print(\"Accuracy: \" + str(round(test_acc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tes_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01508865e-30, 2.31634818e-15, 0.00000000e+00, 5.73616830e-07,\n",
       "       9.99999404e-01], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tes_pred[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 6. Saving model in tensorflow.js Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflowjs library can't be installed directly with pip / conda due to conflicting dependencies. Best is to set up a new environment explicitly for this and install tensorflowjs with the following commands:\n",
    "\n",
    "```\n",
    "pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "pip install --no-deps tensorflowjs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.11.0rc2\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow==1.11.0rc2 (from versions: 0.12.1, 1.0.0, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2)\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow==1.11.0rc2\u001b[0m\n",
      "Requirement already satisfied: tensorflowjs in /Users/lsafari/anaconda3/lib/python3.6/site-packages (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "! pip install --no-deps tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/lsafari/anaconda3/lib/python3.6/site-packages (18.1)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /Users/lsafari/anaconda3/lib/python3.6/site-packages (4.8.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (6.4.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (4.3.2)\n",
      "Requirement already satisfied: jupyter_client in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (5.2.3)\n",
      "Requirement already satisfied: tornado>=4.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (5.0.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (39.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.8.1)\n",
      "Requirement already satisfied: decorator in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (4.3.0)\n",
      "Requirement already satisfied: backcall in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.1.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.7.4)\n",
      "Requirement already satisfied: pygments in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (1.0.15)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ipython_genutils in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: six in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (1.11.0)\n",
      "Requirement already satisfied: jupyter_core in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (17.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (2.7.3)\n",
      "Requirement already satisfied: parso>=0.2.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel) (0.5.2)\n",
      "Requirement already satisfied: tensorflow_hub in /Users/lsafari/anaconda3/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.14.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow_hub) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ipykernel\n",
    "! pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "from keras.models import load_model\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('drone_pos_model-nonpipeline.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('drone_pos_model-nonpipeline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'model_json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adapt the two files as follows in order for them to work on Azure:\n",
    "* add a file extension .pb to the file with no extension (otherwise Azure blocks it from viewing)\n",
    "* adapt the automatically generated model.json to reflect the extension .pb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
