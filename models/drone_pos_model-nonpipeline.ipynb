{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model for Posture Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining transformers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#from category_encoders.one_hot import OneHotEncoder\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer\n",
    "#from category_encoders.ordinal import OrdinalEncoder\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ipytest.magics\n",
    "import pytest\n",
    "# set the file name (required)\n",
    "__file__ = 'drone_pos_model.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shuffler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        x=x.loc[np.random.permutation(x.index)]\n",
    "        \n",
    "        return x\n",
    "############################################################################################\n",
    "class XCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, x_columns):\n",
    "        self.x_columns = x_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_x\",\"leftShoulder_x\",\"leftHip_x\",\"rightHip_x\"]].sum(axis=1)/4\n",
    "        for col in self.x_columns:\n",
    "            x[col] = x[col] - shift\n",
    "        return x\n",
    "############################################################################################\n",
    "    \n",
    "class YCentralizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, y_columns):\n",
    "        self.y_columns = y_columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shift=x[[\"rightShoulder_y\",\"leftShoulder_y\",\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/4\n",
    "        for col in list(set(self.y_columns)-set([\"label\"])):\n",
    "            x[col] = x[col] - shift\n",
    "        return x\n",
    "############################################################################################\n",
    "\n",
    "class YScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x): #x is df\n",
    "        shoulder_y = x[[\"rightShoulder_y\",\"leftShoulder_y\"]].sum(axis=1)/2\n",
    "        hip_y = x[[\"leftHip_y\",\"rightHip_y\"]].sum(axis=1)/2\n",
    "        y_dist = hip_y - shoulder_y\n",
    "        \n",
    "        for col in list(set(x.columns)-set([\"label\"])):\n",
    "            x[col] /= y_dist\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: \n",
      " [1 3 4 2 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.19500</td>\n",
       "      <td>0.50875</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.26625</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.41125</td>\n",
       "      <td>0.34625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.18875</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.18625</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.25875</td>\n",
       "      <td>0.33250</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.27625</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.46750</td>\n",
       "      <td>0.33625</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49125</td>\n",
       "      <td>0.19000</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.17875</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26125</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.19875</td>\n",
       "      <td>0.51125</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.26375</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.46375</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "0         0.49250         0.18750           0.4000          0.18250   \n",
       "1         0.49250         0.18875           0.4025          0.18625   \n",
       "2         0.49125         0.19000           0.4025          0.17875   \n",
       "\n",
       "   leftElbow_x  leftElbow_y  rightElbow_x  rightElbow_y  leftWrist_x  \\\n",
       "0       0.5050      0.26000       0.34375       0.19500      0.50875   \n",
       "1       0.5075      0.25875       0.33250       0.19750      0.50000   \n",
       "2       0.5050      0.26125       0.33500       0.19875      0.51125   \n",
       "\n",
       "   leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  leftHip_y  rightHip_x  \\\n",
       "0      0.33875       0.26625       0.16875    0.46500    0.34375     0.41125   \n",
       "1      0.33750       0.27625       0.17500    0.46750    0.33625     0.40875   \n",
       "2      0.33500       0.26375       0.16875    0.46375    0.33875     0.40875   \n",
       "\n",
       "   rightHip_y  label  \n",
       "0     0.34625      1  \n",
       "1     0.33750      1  \n",
       "2     0.33750      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pwd\n",
    "#df = pd.read_csv(\"video_001.csv\", delimiter=',')\n",
    "# Christian's video is less noisy. Therefore I only train the model with his data at the moment. \n",
    "# acc increased 5 % taking his video camparing to all videos.\n",
    "#path = \"all_videos_posture_steptime50_checksum8160\"\n",
    "#path = \"video_Christian_posture_steptime50_checksum8160\"\n",
    "path = \"video_all_posture_steptime50_checksum8160\"\n",
    "df = pd.read_csv(\"../data/\"+ path + \".csv\",low_memory=False)\n",
    "#df=df.drop([5557], axis=0)\n",
    "#type(df.leftShoulder_x)\n",
    "#df.info()\n",
    "#print(df.dtypes)\n",
    "#print()\n",
    "print('labels: \\n', df['label'].unique())\n",
    "# we have a mix of categorical, numeric, and string data.\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3719, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.dropna().drop_duplicates()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that we don't have any null values\n",
    "assert df1.isnull().all().all() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-pipline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(features_df, label_df, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2975, 16), (744, 16), (2975,), (744,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df.shape, x_test_df.shape, y_train_df.shape, y_test_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>leftShoulder_y</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>rightShoulder_y</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.50875</td>\n",
       "      <td>0.33875</td>\n",
       "      <td>0.26625</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.41125</td>\n",
       "      <td>0.34625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.18875</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.18625</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.25875</td>\n",
       "      <td>0.33250</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.27625</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>0.33625</td>\n",
       "      <td>0.40875</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leftShoulder_x  leftShoulder_y  rightShoulder_x  rightShoulder_y  \\\n",
       "0          0.4925         0.18750           0.4000          0.18250   \n",
       "1          0.4925         0.18875           0.4025          0.18625   \n",
       "\n",
       "   leftElbow_x  leftElbow_y  rightElbow_x  rightElbow_y  leftWrist_x  \\\n",
       "0       0.5050      0.26000       0.34375        0.1950      0.50875   \n",
       "1       0.5075      0.25875       0.33250        0.1975      0.50000   \n",
       "\n",
       "   leftWrist_y  rightWrist_x  rightWrist_y  leftHip_x  leftHip_y  rightHip_x  \\\n",
       "0      0.33875       0.26625       0.16875     0.4650    0.34375     0.41125   \n",
       "1      0.33750       0.27625       0.17500     0.4675    0.33625     0.40875   \n",
       "\n",
       "   rightHip_y  label  \n",
       "0     0.34625      1  \n",
       "1     0.33750      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df1.copy()\n",
    "#x=x.drop([\"label\"], axis = 1)\n",
    "x_cols = ['leftShoulder_x', 'rightShoulder_x',\n",
    "        'leftElbow_x', 'rightElbow_x',\n",
    "        'leftWrist_x', 'rightWrist_x',\n",
    "        'leftHip_x', 'rightHip_x']\n",
    "#xtrans = XCentralizer(x_cols)\n",
    "#x = xtrans.transform(x)\n",
    "\n",
    "y_cols = list(set(x.columns)-set(x_cols))\n",
    "#print(y_cols)\n",
    "#ytrans = YCentralizer(y_cols)\n",
    "#x = ytrans.transform(x)\n",
    "\n",
    "#ytrans = YScaler()\n",
    "#x = ytrans.transform(x)\n",
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "processing_pipeline = make_pipeline(\n",
    "    XCentralizer(x_cols),\n",
    "    YCentralizer(y_cols), \n",
    "    YScaler(),\n",
    "    Shuffler()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = processing_pipeline.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = processed_df.drop(\"label\", axis=1)\n",
    "label_df = processed_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0\n",
      "rootdir: /Users/lsafari/drone_steering/models, inifile:\n",
      "plugins: remotedata-0.2.1, openfiles-0.3.0, doctestplus-0.1.3, arraydiff-0.2\n",
      "collected 1 item\n",
      "\n",
      "drone_pos_model.py .                                                     [100%]\n",
      "\n",
      "=========================== 1 passed in 0.03 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "def test_processingpipeline():\n",
    "    # remember, this first pipeline only acts on the features, not the target.\n",
    "    processed_df = processing_pipeline.fit_transform(x)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert x.shape[0] == processed_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processed_df.iloc[:int(processed_df.shape[0]*0.8)]\n",
    "df_val = processed_df.iloc[int(processed_df.shape[0]*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train.shape[0] + df_val.shape[0] == processed_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = df_train['label']\n",
    "x_train_df = df_train.drop('label', axis = 1)\n",
    "y_val_df = df_val['label']\n",
    "x_val_df = df_val.drop('label', axis = 1)\n",
    "x_train=x_train_df.values\n",
    "y_train=y_train_df.values\n",
    "x_val=x_val_df.values\n",
    "y_val=y_val_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= [ 0.22014925 -0.56343284 -0.27985075 -0.43656716  0.78731343 -0.5858209\n",
      " -0.34701493 -0.01119403  1.33208955 -0.79477612 -0.32462687  0.49626866\n",
      "  0.21268657  0.48880597 -0.15298507  0.51119403] \n",
      " y_train= 2\n"
     ]
    }
   ],
   "source": [
    "x_train\n",
    "print(\"x_train=\", x_train[0],\"\\n y_train=\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                340       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 735\n",
      "Trainable params: 735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import optimizers, losses, metrics\n",
    "\n",
    "\n",
    "#default vaues\n",
    "#activation=\"relu\"\n",
    "#optimizer=\"adam\"\n",
    "lr=0.01\n",
    "#momentum=0\n",
    "#creat model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(\n",
    "        20, \n",
    "        activation=\"relu\", \n",
    "        input_shape=(16, )))\n",
    "model.add(layers.Dense(15, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"softmax\")) #is a fast rectifier\n",
    "model.summary()   \n",
    "\n",
    "model.compile(\n",
    "optimizer=optimizers.RMSprop(lr=0.01),\n",
    "loss=losses.categorical_crossentropy,\n",
    "metrics=[\"accuracy\"] \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2975/2975 [==============================] - 0s 78us/step - loss: 1.1012 - acc: 0.5896\n",
      "Epoch 2/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.7281 - acc: 0.7543\n",
      "Epoch 3/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.6340 - acc: 0.7956\n",
      "Epoch 4/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.5745 - acc: 0.8171\n",
      "Epoch 5/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.5494 - acc: 0.8229\n",
      "Epoch 6/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.5145 - acc: 0.8444\n",
      "Epoch 7/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.4862 - acc: 0.8461\n",
      "Epoch 8/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.4777 - acc: 0.8521\n",
      "Epoch 9/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.4753 - acc: 0.8548\n",
      "Epoch 10/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.4450 - acc: 0.8595\n",
      "Epoch 11/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.4351 - acc: 0.8642\n",
      "Epoch 12/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.4305 - acc: 0.8632\n",
      "Epoch 13/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.4242 - acc: 0.8686\n",
      "Epoch 14/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.4037 - acc: 0.8756\n",
      "Epoch 15/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.4013 - acc: 0.8753\n",
      "Epoch 16/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.4092 - acc: 0.8743\n",
      "Epoch 17/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.3974 - acc: 0.8810\n",
      "Epoch 18/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.4001 - acc: 0.8723\n",
      "Epoch 19/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3834 - acc: 0.8780\n",
      "Epoch 20/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.3778 - acc: 0.8864\n",
      "Epoch 21/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.3706 - acc: 0.8800\n",
      "Epoch 22/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3659 - acc: 0.8854\n",
      "Epoch 23/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3621 - acc: 0.8894\n",
      "Epoch 24/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3649 - acc: 0.8810\n",
      "Epoch 25/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.3672 - acc: 0.8830\n",
      "Epoch 26/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.3523 - acc: 0.8897\n",
      "Epoch 27/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.3487 - acc: 0.8911\n",
      "Epoch 28/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3519 - acc: 0.8857\n",
      "Epoch 29/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3439 - acc: 0.8904\n",
      "Epoch 30/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.3527 - acc: 0.8914\n",
      "Epoch 31/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3268 - acc: 0.8931\n",
      "Epoch 32/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3327 - acc: 0.8928\n",
      "Epoch 33/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3413 - acc: 0.8911\n",
      "Epoch 34/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3276 - acc: 0.8934\n",
      "Epoch 35/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3234 - acc: 0.8971\n",
      "Epoch 36/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3180 - acc: 0.9002\n",
      "Epoch 37/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3153 - acc: 0.9032\n",
      "Epoch 38/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3170 - acc: 0.8975\n",
      "Epoch 39/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3179 - acc: 0.8985\n",
      "Epoch 40/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3133 - acc: 0.9008\n",
      "Epoch 41/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.3121 - acc: 0.9005\n",
      "Epoch 42/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3097 - acc: 0.8998\n",
      "Epoch 43/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3045 - acc: 0.9015\n",
      "Epoch 44/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3036 - acc: 0.9049\n",
      "Epoch 45/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.3034 - acc: 0.9042\n",
      "Epoch 46/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3055 - acc: 0.9086\n",
      "Epoch 47/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3002 - acc: 0.9022\n",
      "Epoch 48/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2966 - acc: 0.9055\n",
      "Epoch 49/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2981 - acc: 0.9018\n",
      "Epoch 50/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3040 - acc: 0.9039\n",
      "Epoch 51/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.3075 - acc: 0.9062\n",
      "Epoch 52/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2931 - acc: 0.9076\n",
      "Epoch 53/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2870 - acc: 0.9049\n",
      "Epoch 54/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2855 - acc: 0.9079\n",
      "Epoch 55/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2961 - acc: 0.9089\n",
      "Epoch 56/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2879 - acc: 0.9045\n",
      "Epoch 57/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2816 - acc: 0.9106\n",
      "Epoch 58/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2806 - acc: 0.9089\n",
      "Epoch 59/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2870 - acc: 0.9079\n",
      "Epoch 60/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2840 - acc: 0.9086\n",
      "Epoch 61/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2786 - acc: 0.9126\n",
      "Epoch 62/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2785 - acc: 0.9092\n",
      "Epoch 63/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2705 - acc: 0.9123\n",
      "Epoch 64/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2788 - acc: 0.9109\n",
      "Epoch 65/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2698 - acc: 0.9126\n",
      "Epoch 66/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2746 - acc: 0.9150\n",
      "Epoch 67/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2741 - acc: 0.9146\n",
      "Epoch 68/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2784 - acc: 0.9099\n",
      "Epoch 69/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2784 - acc: 0.9099\n",
      "Epoch 70/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2727 - acc: 0.9163\n",
      "Epoch 71/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2626 - acc: 0.9160\n",
      "Epoch 72/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2686 - acc: 0.9096\n",
      "Epoch 73/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2639 - acc: 0.9109\n",
      "Epoch 74/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2632 - acc: 0.9126\n",
      "Epoch 75/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2730 - acc: 0.9136\n",
      "Epoch 76/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.2639 - acc: 0.9146\n",
      "Epoch 77/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2606 - acc: 0.9150\n",
      "Epoch 78/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2620 - acc: 0.9126\n",
      "Epoch 79/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2652 - acc: 0.9160\n",
      "Epoch 80/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2639 - acc: 0.9153\n",
      "Epoch 81/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2643 - acc: 0.9139\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2641 - acc: 0.9133\n",
      "Epoch 83/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2568 - acc: 0.9123\n",
      "Epoch 84/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2556 - acc: 0.9173\n",
      "Epoch 85/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2672 - acc: 0.9143\n",
      "Epoch 86/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2610 - acc: 0.9173\n",
      "Epoch 87/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2495 - acc: 0.9153\n",
      "Epoch 88/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2663 - acc: 0.9190\n",
      "Epoch 89/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2549 - acc: 0.9160\n",
      "Epoch 90/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2564 - acc: 0.9193\n",
      "Epoch 91/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2469 - acc: 0.9213\n",
      "Epoch 92/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2487 - acc: 0.9193\n",
      "Epoch 93/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2486 - acc: 0.9207\n",
      "Epoch 94/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2616 - acc: 0.9109\n",
      "Epoch 95/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2491 - acc: 0.9170\n",
      "Epoch 96/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2560 - acc: 0.9213\n",
      "Epoch 97/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2481 - acc: 0.9193\n",
      "Epoch 98/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2430 - acc: 0.9227\n",
      "Epoch 99/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2405 - acc: 0.9210\n",
      "Epoch 100/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2341 - acc: 0.9200\n",
      "Epoch 101/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2478 - acc: 0.9200\n",
      "Epoch 102/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2438 - acc: 0.9240\n",
      "Epoch 103/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2416 - acc: 0.9190\n",
      "Epoch 104/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2270 - acc: 0.9277\n",
      "Epoch 105/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2384 - acc: 0.9190\n",
      "Epoch 106/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2473 - acc: 0.9203\n",
      "Epoch 107/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2298 - acc: 0.9247\n",
      "Epoch 108/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2503 - acc: 0.9190\n",
      "Epoch 109/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2272 - acc: 0.9274\n",
      "Epoch 110/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2281 - acc: 0.9244\n",
      "Epoch 111/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2371 - acc: 0.9287\n",
      "Epoch 112/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2418 - acc: 0.9227\n",
      "Epoch 113/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2426 - acc: 0.9210\n",
      "Epoch 114/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2289 - acc: 0.9277\n",
      "Epoch 115/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2420 - acc: 0.9244\n",
      "Epoch 116/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2372 - acc: 0.9247\n",
      "Epoch 117/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2352 - acc: 0.9244\n",
      "Epoch 118/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2382 - acc: 0.9257\n",
      "Epoch 119/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2334 - acc: 0.9207\n",
      "Epoch 120/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2291 - acc: 0.9254\n",
      "Epoch 121/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2228 - acc: 0.9304\n",
      "Epoch 122/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2276 - acc: 0.9257\n",
      "Epoch 123/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2206 - acc: 0.9287\n",
      "Epoch 124/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2127 - acc: 0.9250\n",
      "Epoch 125/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2401 - acc: 0.9277\n",
      "Epoch 126/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2220 - acc: 0.9261\n",
      "Epoch 127/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2350 - acc: 0.9224\n",
      "Epoch 128/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2237 - acc: 0.9291\n",
      "Epoch 129/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2177 - acc: 0.9311\n",
      "Epoch 130/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2146 - acc: 0.9264\n",
      "Epoch 131/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2238 - acc: 0.9244\n",
      "Epoch 132/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2182 - acc: 0.9277\n",
      "Epoch 133/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2117 - acc: 0.9314\n",
      "Epoch 134/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2188 - acc: 0.9277\n",
      "Epoch 135/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2279 - acc: 0.9257\n",
      "Epoch 136/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2203 - acc: 0.9301\n",
      "Epoch 137/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2211 - acc: 0.9304\n",
      "Epoch 138/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2223 - acc: 0.9271\n",
      "Epoch 139/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2146 - acc: 0.9314\n",
      "Epoch 140/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2322 - acc: 0.9267\n",
      "Epoch 141/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2340 - acc: 0.9267\n",
      "Epoch 142/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2188 - acc: 0.9261\n",
      "Epoch 143/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2250 - acc: 0.9291\n",
      "Epoch 144/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2228 - acc: 0.9271\n",
      "Epoch 145/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2165 - acc: 0.9287\n",
      "Epoch 146/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2275 - acc: 0.9301\n",
      "Epoch 147/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2246 - acc: 0.9234\n",
      "Epoch 148/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2129 - acc: 0.9324\n",
      "Epoch 149/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2180 - acc: 0.9257\n",
      "Epoch 150/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2302 - acc: 0.9230\n",
      "Epoch 151/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2237 - acc: 0.9247\n",
      "Epoch 152/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2187 - acc: 0.9287\n",
      "Epoch 153/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2133 - acc: 0.9308\n",
      "Epoch 154/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2244 - acc: 0.9297\n",
      "Epoch 155/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2240 - acc: 0.9274\n",
      "Epoch 156/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2190 - acc: 0.9301\n",
      "Epoch 157/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2220 - acc: 0.9311\n",
      "Epoch 158/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2205 - acc: 0.9257\n",
      "Epoch 159/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2221 - acc: 0.9321\n",
      "Epoch 160/1000\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 0.2173 - acc: 0.9277\n",
      "Epoch 161/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2182 - acc: 0.9267\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2132 - acc: 0.9334\n",
      "Epoch 163/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2101 - acc: 0.9331\n",
      "Epoch 164/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2130 - acc: 0.9271\n",
      "Epoch 165/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2141 - acc: 0.9271\n",
      "Epoch 166/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2152 - acc: 0.9308\n",
      "Epoch 167/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2141 - acc: 0.9318\n",
      "Epoch 168/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2219 - acc: 0.9277\n",
      "Epoch 169/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2097 - acc: 0.9311\n",
      "Epoch 170/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2135 - acc: 0.9311\n",
      "Epoch 171/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2089 - acc: 0.9321\n",
      "Epoch 172/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2072 - acc: 0.9321\n",
      "Epoch 173/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2022 - acc: 0.9314\n",
      "Epoch 174/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2011 - acc: 0.9365\n",
      "Epoch 175/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2152 - acc: 0.9294\n",
      "Epoch 176/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2067 - acc: 0.9314\n",
      "Epoch 177/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2003 - acc: 0.9334\n",
      "Epoch 178/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2120 - acc: 0.9274\n",
      "Epoch 179/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2065 - acc: 0.9321\n",
      "Epoch 180/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2129 - acc: 0.9287\n",
      "Epoch 181/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2206 - acc: 0.9328\n",
      "Epoch 182/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2029 - acc: 0.9355\n",
      "Epoch 183/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2240 - acc: 0.9308\n",
      "Epoch 184/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2170 - acc: 0.9358\n",
      "Epoch 185/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2047 - acc: 0.9365\n",
      "Epoch 186/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2045 - acc: 0.9287\n",
      "Epoch 187/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2073 - acc: 0.9304\n",
      "Epoch 188/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2051 - acc: 0.9328\n",
      "Epoch 189/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2278 - acc: 0.9314\n",
      "Epoch 190/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2124 - acc: 0.9287\n",
      "Epoch 191/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2106 - acc: 0.9351\n",
      "Epoch 192/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2078 - acc: 0.9345\n",
      "Epoch 193/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2036 - acc: 0.9291\n",
      "Epoch 194/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2066 - acc: 0.9341\n",
      "Epoch 195/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2022 - acc: 0.9334\n",
      "Epoch 196/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1978 - acc: 0.9314\n",
      "Epoch 197/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2068 - acc: 0.9294\n",
      "Epoch 198/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2150 - acc: 0.9308\n",
      "Epoch 199/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2010 - acc: 0.9351\n",
      "Epoch 200/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2068 - acc: 0.9358\n",
      "Epoch 201/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2219 - acc: 0.9338\n",
      "Epoch 202/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1984 - acc: 0.9368\n",
      "Epoch 203/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1945 - acc: 0.9355\n",
      "Epoch 204/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1968 - acc: 0.9368\n",
      "Epoch 205/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2011 - acc: 0.9371\n",
      "Epoch 206/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1934 - acc: 0.9368\n",
      "Epoch 207/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.2023 - acc: 0.9355\n",
      "Epoch 208/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2025 - acc: 0.9385\n",
      "Epoch 209/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2093 - acc: 0.9328\n",
      "Epoch 210/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1913 - acc: 0.9382\n",
      "Epoch 211/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2007 - acc: 0.9361\n",
      "Epoch 212/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2041 - acc: 0.9368\n",
      "Epoch 213/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1913 - acc: 0.9378\n",
      "Epoch 214/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2049 - acc: 0.9358\n",
      "Epoch 215/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2003 - acc: 0.9338\n",
      "Epoch 216/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2069 - acc: 0.9321\n",
      "Epoch 217/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2221 - acc: 0.9338\n",
      "Epoch 218/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2131 - acc: 0.9304\n",
      "Epoch 219/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2091 - acc: 0.9318\n",
      "Epoch 220/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2020 - acc: 0.9328\n",
      "Epoch 221/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2063 - acc: 0.9331\n",
      "Epoch 222/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1974 - acc: 0.9308\n",
      "Epoch 223/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.2186 - acc: 0.9348\n",
      "Epoch 224/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2144 - acc: 0.9304\n",
      "Epoch 225/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1877 - acc: 0.9398\n",
      "Epoch 226/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1936 - acc: 0.9378\n",
      "Epoch 227/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2041 - acc: 0.9345\n",
      "Epoch 228/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2020 - acc: 0.9358\n",
      "Epoch 229/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2150 - acc: 0.9345\n",
      "Epoch 230/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1977 - acc: 0.9321\n",
      "Epoch 231/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.2052 - acc: 0.9338\n",
      "Epoch 232/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1977 - acc: 0.9351\n",
      "Epoch 233/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2093 - acc: 0.9341\n",
      "Epoch 234/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1920 - acc: 0.9348\n",
      "Epoch 235/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1860 - acc: 0.9408\n",
      "Epoch 236/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2017 - acc: 0.9297\n",
      "Epoch 237/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2082 - acc: 0.9331\n",
      "Epoch 238/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2053 - acc: 0.9375\n",
      "Epoch 239/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.2036 - acc: 0.9355\n",
      "Epoch 240/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2254 - acc: 0.9328\n",
      "Epoch 241/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1915 - acc: 0.9368\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1959 - acc: 0.9365\n",
      "Epoch 243/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2074 - acc: 0.9388\n",
      "Epoch 244/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2027 - acc: 0.9345\n",
      "Epoch 245/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2057 - acc: 0.9331\n",
      "Epoch 246/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1979 - acc: 0.9341\n",
      "Epoch 247/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2050 - acc: 0.9341\n",
      "Epoch 248/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1876 - acc: 0.9402\n",
      "Epoch 249/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1854 - acc: 0.9361\n",
      "Epoch 250/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2120 - acc: 0.9385\n",
      "Epoch 251/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1981 - acc: 0.9442\n",
      "Epoch 252/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2102 - acc: 0.9311\n",
      "Epoch 253/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2011 - acc: 0.9318\n",
      "Epoch 254/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2073 - acc: 0.9345\n",
      "Epoch 255/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1850 - acc: 0.9358\n",
      "Epoch 256/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2053 - acc: 0.9402\n",
      "Epoch 257/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1870 - acc: 0.9371\n",
      "Epoch 258/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2146 - acc: 0.9368\n",
      "Epoch 259/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2042 - acc: 0.9398\n",
      "Epoch 260/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1922 - acc: 0.9368\n",
      "Epoch 261/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2059 - acc: 0.9388\n",
      "Epoch 262/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1931 - acc: 0.9328\n",
      "Epoch 263/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2006 - acc: 0.9351\n",
      "Epoch 264/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1973 - acc: 0.9368\n",
      "Epoch 265/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1947 - acc: 0.9341\n",
      "Epoch 266/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1948 - acc: 0.9378\n",
      "Epoch 267/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2027 - acc: 0.9328\n",
      "Epoch 268/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1948 - acc: 0.9351\n",
      "Epoch 269/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1941 - acc: 0.9328\n",
      "Epoch 270/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1893 - acc: 0.9378\n",
      "Epoch 271/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1993 - acc: 0.9308\n",
      "Epoch 272/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2165 - acc: 0.9311\n",
      "Epoch 273/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1913 - acc: 0.9321\n",
      "Epoch 274/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1914 - acc: 0.9385\n",
      "Epoch 275/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.2051 - acc: 0.9348\n",
      "Epoch 276/1000\n",
      "2975/2975 [==============================] - 0s 32us/step - loss: 0.1936 - acc: 0.9388\n",
      "Epoch 277/1000\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 0.1998 - acc: 0.9375\n",
      "Epoch 278/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1845 - acc: 0.9429\n",
      "Epoch 279/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1801 - acc: 0.9408\n",
      "Epoch 280/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1993 - acc: 0.9355\n",
      "Epoch 281/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2008 - acc: 0.9348\n",
      "Epoch 282/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1895 - acc: 0.9365\n",
      "Epoch 283/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1988 - acc: 0.9341\n",
      "Epoch 284/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1831 - acc: 0.9425\n",
      "Epoch 285/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1888 - acc: 0.9415\n",
      "Epoch 286/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2044 - acc: 0.9398\n",
      "Epoch 287/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1855 - acc: 0.9425\n",
      "Epoch 288/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.2004 - acc: 0.9418\n",
      "Epoch 289/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2028 - acc: 0.9385\n",
      "Epoch 290/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1958 - acc: 0.9358\n",
      "Epoch 291/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1985 - acc: 0.9358\n",
      "Epoch 292/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1933 - acc: 0.9408\n",
      "Epoch 293/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1863 - acc: 0.9368\n",
      "Epoch 294/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1886 - acc: 0.9378\n",
      "Epoch 295/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1909 - acc: 0.9371\n",
      "Epoch 296/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1964 - acc: 0.9382\n",
      "Epoch 297/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1925 - acc: 0.9398\n",
      "Epoch 298/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2025 - acc: 0.9385\n",
      "Epoch 299/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1875 - acc: 0.9385\n",
      "Epoch 300/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.2067 - acc: 0.9338\n",
      "Epoch 301/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1842 - acc: 0.9435\n",
      "Epoch 302/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1884 - acc: 0.9405\n",
      "Epoch 303/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2094 - acc: 0.9368\n",
      "Epoch 304/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1846 - acc: 0.9415\n",
      "Epoch 305/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1976 - acc: 0.9368\n",
      "Epoch 306/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1867 - acc: 0.9371\n",
      "Epoch 307/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1938 - acc: 0.9365\n",
      "Epoch 308/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1947 - acc: 0.9422\n",
      "Epoch 309/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1871 - acc: 0.9375\n",
      "Epoch 310/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1898 - acc: 0.9368\n",
      "Epoch 311/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1839 - acc: 0.9405\n",
      "Epoch 312/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2018 - acc: 0.9385\n",
      "Epoch 313/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1912 - acc: 0.9371\n",
      "Epoch 314/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1830 - acc: 0.9385\n",
      "Epoch 315/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1770 - acc: 0.9439\n",
      "Epoch 316/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1748 - acc: 0.9395\n",
      "Epoch 317/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1894 - acc: 0.9361\n",
      "Epoch 318/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1856 - acc: 0.9351\n",
      "Epoch 319/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1813 - acc: 0.9418\n",
      "Epoch 320/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1858 - acc: 0.9405\n",
      "Epoch 321/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1821 - acc: 0.9378\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1825 - acc: 0.9375\n",
      "Epoch 323/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1767 - acc: 0.9405\n",
      "Epoch 324/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1895 - acc: 0.9452\n",
      "Epoch 325/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1823 - acc: 0.9355\n",
      "Epoch 326/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1963 - acc: 0.9388\n",
      "Epoch 327/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2262 - acc: 0.9321\n",
      "Epoch 328/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.2111 - acc: 0.9402\n",
      "Epoch 329/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1729 - acc: 0.9418\n",
      "Epoch 330/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1835 - acc: 0.9378\n",
      "Epoch 331/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1842 - acc: 0.9455\n",
      "Epoch 332/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1833 - acc: 0.9415\n",
      "Epoch 333/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1826 - acc: 0.9445\n",
      "Epoch 334/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1972 - acc: 0.9388\n",
      "Epoch 335/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1764 - acc: 0.9435\n",
      "Epoch 336/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1735 - acc: 0.9418\n",
      "Epoch 337/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1742 - acc: 0.9466\n",
      "Epoch 338/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1840 - acc: 0.9398\n",
      "Epoch 339/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1732 - acc: 0.9462\n",
      "Epoch 340/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1750 - acc: 0.9405\n",
      "Epoch 341/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1951 - acc: 0.9425\n",
      "Epoch 342/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1848 - acc: 0.9408\n",
      "Epoch 343/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1783 - acc: 0.9442\n",
      "Epoch 344/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1831 - acc: 0.9435\n",
      "Epoch 345/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1890 - acc: 0.9435\n",
      "Epoch 346/1000\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 0.1682 - acc: 0.9466\n",
      "Epoch 347/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1939 - acc: 0.9382\n",
      "Epoch 348/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1834 - acc: 0.9388\n",
      "Epoch 349/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1745 - acc: 0.9442\n",
      "Epoch 350/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1873 - acc: 0.9405\n",
      "Epoch 351/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1729 - acc: 0.9435\n",
      "Epoch 352/1000\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 0.1958 - acc: 0.9405\n",
      "Epoch 353/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1745 - acc: 0.9445\n",
      "Epoch 354/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1976 - acc: 0.9429\n",
      "Epoch 355/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1940 - acc: 0.9405\n",
      "Epoch 356/1000\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 0.1958 - acc: 0.9462\n",
      "Epoch 357/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1908 - acc: 0.9449\n",
      "Epoch 358/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1768 - acc: 0.9358\n",
      "Epoch 359/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1762 - acc: 0.9435\n",
      "Epoch 360/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1793 - acc: 0.9398\n",
      "Epoch 361/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1903 - acc: 0.9388\n",
      "Epoch 362/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.2152 - acc: 0.9371\n",
      "Epoch 363/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1899 - acc: 0.9442\n",
      "Epoch 364/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1931 - acc: 0.9351\n",
      "Epoch 365/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1868 - acc: 0.9492\n",
      "Epoch 366/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1805 - acc: 0.9435\n",
      "Epoch 367/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1947 - acc: 0.9392\n",
      "Epoch 368/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1848 - acc: 0.9375\n",
      "Epoch 369/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1696 - acc: 0.9415\n",
      "Epoch 370/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1785 - acc: 0.9415\n",
      "Epoch 371/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1673 - acc: 0.9442\n",
      "Epoch 372/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1902 - acc: 0.9378\n",
      "Epoch 373/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1921 - acc: 0.9378\n",
      "Epoch 374/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1893 - acc: 0.9392\n",
      "Epoch 375/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1667 - acc: 0.9415\n",
      "Epoch 376/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1746 - acc: 0.9392\n",
      "Epoch 377/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1683 - acc: 0.9459\n",
      "Epoch 378/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1759 - acc: 0.9435\n",
      "Epoch 379/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1803 - acc: 0.9449\n",
      "Epoch 380/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1786 - acc: 0.9402\n",
      "Epoch 381/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1904 - acc: 0.9442\n",
      "Epoch 382/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1748 - acc: 0.9375\n",
      "Epoch 383/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1617 - acc: 0.9462\n",
      "Epoch 384/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1838 - acc: 0.9358\n",
      "Epoch 385/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1820 - acc: 0.9425\n",
      "Epoch 386/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1828 - acc: 0.9445\n",
      "Epoch 387/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1846 - acc: 0.9382\n",
      "Epoch 388/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1835 - acc: 0.9405\n",
      "Epoch 389/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1699 - acc: 0.9459\n",
      "Epoch 390/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1818 - acc: 0.9462\n",
      "Epoch 391/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1801 - acc: 0.9375\n",
      "Epoch 392/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1848 - acc: 0.9429\n",
      "Epoch 393/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1694 - acc: 0.9425\n",
      "Epoch 394/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1924 - acc: 0.9429\n",
      "Epoch 395/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1896 - acc: 0.9412\n",
      "Epoch 396/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1874 - acc: 0.9361\n",
      "Epoch 397/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1747 - acc: 0.9432\n",
      "Epoch 398/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1864 - acc: 0.9442\n",
      "Epoch 399/1000\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 0.1721 - acc: 0.9415\n",
      "Epoch 400/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1905 - acc: 0.9455\n",
      "Epoch 401/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1785 - acc: 0.9415\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1740 - acc: 0.9432\n",
      "Epoch 403/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1618 - acc: 0.9432\n",
      "Epoch 404/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1866 - acc: 0.9445\n",
      "Epoch 405/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1738 - acc: 0.9439\n",
      "Epoch 406/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1691 - acc: 0.9415\n",
      "Epoch 407/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1744 - acc: 0.9455\n",
      "Epoch 408/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1791 - acc: 0.9425\n",
      "Epoch 409/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1829 - acc: 0.9398\n",
      "Epoch 410/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1825 - acc: 0.9425\n",
      "Epoch 411/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1839 - acc: 0.9398\n",
      "Epoch 412/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1702 - acc: 0.9509\n",
      "Epoch 413/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1725 - acc: 0.9459\n",
      "Epoch 414/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1942 - acc: 0.9351\n",
      "Epoch 415/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1759 - acc: 0.9429\n",
      "Epoch 416/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1806 - acc: 0.9432\n",
      "Epoch 417/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1813 - acc: 0.9469\n",
      "Epoch 418/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1795 - acc: 0.9466\n",
      "Epoch 419/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1818 - acc: 0.9402\n",
      "Epoch 420/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1711 - acc: 0.9452\n",
      "Epoch 421/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1786 - acc: 0.9432\n",
      "Epoch 422/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1794 - acc: 0.9442\n",
      "Epoch 423/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1860 - acc: 0.9371\n",
      "Epoch 424/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1794 - acc: 0.9425\n",
      "Epoch 425/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1874 - acc: 0.9388\n",
      "Epoch 426/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1711 - acc: 0.9462\n",
      "Epoch 427/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1699 - acc: 0.9415\n",
      "Epoch 428/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1840 - acc: 0.9422\n",
      "Epoch 429/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1756 - acc: 0.9408\n",
      "Epoch 430/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1692 - acc: 0.9455\n",
      "Epoch 431/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.2062 - acc: 0.9378\n",
      "Epoch 432/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1654 - acc: 0.9479\n",
      "Epoch 433/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1662 - acc: 0.9455\n",
      "Epoch 434/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1939 - acc: 0.9402\n",
      "Epoch 435/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1779 - acc: 0.9412\n",
      "Epoch 436/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1782 - acc: 0.9462\n",
      "Epoch 437/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1691 - acc: 0.9442\n",
      "Epoch 438/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1763 - acc: 0.9412\n",
      "Epoch 439/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1739 - acc: 0.9415\n",
      "Epoch 440/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1790 - acc: 0.9439\n",
      "Epoch 441/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1717 - acc: 0.9455\n",
      "Epoch 442/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1705 - acc: 0.9429\n",
      "Epoch 443/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1724 - acc: 0.9429\n",
      "Epoch 444/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1653 - acc: 0.9459\n",
      "Epoch 445/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1715 - acc: 0.9455\n",
      "Epoch 446/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1832 - acc: 0.9375\n",
      "Epoch 447/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1665 - acc: 0.9466\n",
      "Epoch 448/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1794 - acc: 0.9418\n",
      "Epoch 449/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1692 - acc: 0.9466\n",
      "Epoch 450/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1786 - acc: 0.9459\n",
      "Epoch 451/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1660 - acc: 0.9476\n",
      "Epoch 452/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1723 - acc: 0.9429\n",
      "Epoch 453/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1710 - acc: 0.9418\n",
      "Epoch 454/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1829 - acc: 0.9425\n",
      "Epoch 455/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.2012 - acc: 0.9412\n",
      "Epoch 456/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1835 - acc: 0.9415\n",
      "Epoch 457/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1783 - acc: 0.9375\n",
      "Epoch 458/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1723 - acc: 0.9445\n",
      "Epoch 459/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1771 - acc: 0.9442\n",
      "Epoch 460/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1721 - acc: 0.9442\n",
      "Epoch 461/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1856 - acc: 0.9472\n",
      "Epoch 462/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1863 - acc: 0.9439\n",
      "Epoch 463/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1820 - acc: 0.9418\n",
      "Epoch 464/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1703 - acc: 0.9445\n",
      "Epoch 465/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1609 - acc: 0.9486\n",
      "Epoch 466/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1883 - acc: 0.9422\n",
      "Epoch 467/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1756 - acc: 0.9429\n",
      "Epoch 468/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1671 - acc: 0.9479\n",
      "Epoch 469/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1720 - acc: 0.9466\n",
      "Epoch 470/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1813 - acc: 0.9462\n",
      "Epoch 471/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1772 - acc: 0.9425\n",
      "Epoch 472/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1713 - acc: 0.9479\n",
      "Epoch 473/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1781 - acc: 0.9442\n",
      "Epoch 474/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1673 - acc: 0.9402\n",
      "Epoch 475/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1781 - acc: 0.9425\n",
      "Epoch 476/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1823 - acc: 0.9432\n",
      "Epoch 477/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1702 - acc: 0.9482\n",
      "Epoch 478/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1540 - acc: 0.9476\n",
      "Epoch 479/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1629 - acc: 0.9479\n",
      "Epoch 480/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1793 - acc: 0.9526\n",
      "Epoch 481/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1639 - acc: 0.9476\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1814 - acc: 0.9439\n",
      "Epoch 483/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1811 - acc: 0.9418\n",
      "Epoch 484/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1806 - acc: 0.9462\n",
      "Epoch 485/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1778 - acc: 0.9455\n",
      "Epoch 486/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1732 - acc: 0.9418\n",
      "Epoch 487/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1758 - acc: 0.9462\n",
      "Epoch 488/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1689 - acc: 0.9455\n",
      "Epoch 489/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1662 - acc: 0.9439\n",
      "Epoch 490/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1646 - acc: 0.9486\n",
      "Epoch 491/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1684 - acc: 0.9429\n",
      "Epoch 492/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1691 - acc: 0.9452\n",
      "Epoch 493/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1729 - acc: 0.9459\n",
      "Epoch 494/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1830 - acc: 0.9435\n",
      "Epoch 495/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1676 - acc: 0.9486\n",
      "Epoch 496/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1622 - acc: 0.9455\n",
      "Epoch 497/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1793 - acc: 0.9469\n",
      "Epoch 498/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1665 - acc: 0.9452\n",
      "Epoch 499/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1761 - acc: 0.9459\n",
      "Epoch 500/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1739 - acc: 0.9415\n",
      "Epoch 501/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1665 - acc: 0.9509\n",
      "Epoch 502/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1591 - acc: 0.9439\n",
      "Epoch 503/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1783 - acc: 0.9462\n",
      "Epoch 504/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1524 - acc: 0.9496\n",
      "Epoch 505/1000\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 0.1700 - acc: 0.9452\n",
      "Epoch 506/1000\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 0.1736 - acc: 0.9455\n",
      "Epoch 507/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1893 - acc: 0.9405\n",
      "Epoch 508/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1769 - acc: 0.9476\n",
      "Epoch 509/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1656 - acc: 0.9486\n",
      "Epoch 510/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1610 - acc: 0.9479\n",
      "Epoch 511/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1735 - acc: 0.9445\n",
      "Epoch 512/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1570 - acc: 0.9472\n",
      "Epoch 513/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1733 - acc: 0.9452\n",
      "Epoch 514/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1810 - acc: 0.9432\n",
      "Epoch 515/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1736 - acc: 0.9412\n",
      "Epoch 516/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1671 - acc: 0.9486\n",
      "Epoch 517/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1786 - acc: 0.9459\n",
      "Epoch 518/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1659 - acc: 0.9472\n",
      "Epoch 519/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1691 - acc: 0.9506\n",
      "Epoch 520/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1527 - acc: 0.9496\n",
      "Epoch 521/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1677 - acc: 0.9429\n",
      "Epoch 522/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1768 - acc: 0.9439\n",
      "Epoch 523/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1686 - acc: 0.9445\n",
      "Epoch 524/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1917 - acc: 0.9395\n",
      "Epoch 525/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1691 - acc: 0.9499\n",
      "Epoch 526/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1670 - acc: 0.9452\n",
      "Epoch 527/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1712 - acc: 0.9445\n",
      "Epoch 528/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1586 - acc: 0.9482\n",
      "Epoch 529/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1733 - acc: 0.9466\n",
      "Epoch 530/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1594 - acc: 0.9476\n",
      "Epoch 531/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1726 - acc: 0.9429\n",
      "Epoch 532/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1693 - acc: 0.9476\n",
      "Epoch 533/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1668 - acc: 0.9503\n",
      "Epoch 534/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1507 - acc: 0.9499\n",
      "Epoch 535/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1633 - acc: 0.9479\n",
      "Epoch 536/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1667 - acc: 0.9482\n",
      "Epoch 537/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1636 - acc: 0.9452\n",
      "Epoch 538/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1566 - acc: 0.9486\n",
      "Epoch 539/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1634 - acc: 0.9499\n",
      "Epoch 540/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1632 - acc: 0.9513\n",
      "Epoch 541/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1575 - acc: 0.9479\n",
      "Epoch 542/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1669 - acc: 0.9489\n",
      "Epoch 543/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1730 - acc: 0.9466\n",
      "Epoch 544/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1528 - acc: 0.9519\n",
      "Epoch 545/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1682 - acc: 0.9435\n",
      "Epoch 546/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1593 - acc: 0.9533\n",
      "Epoch 547/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1676 - acc: 0.9469\n",
      "Epoch 548/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1700 - acc: 0.9482\n",
      "Epoch 549/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1564 - acc: 0.9449\n",
      "Epoch 550/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1521 - acc: 0.9482\n",
      "Epoch 551/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1746 - acc: 0.9486\n",
      "Epoch 552/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1644 - acc: 0.9459\n",
      "Epoch 553/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1677 - acc: 0.9435\n",
      "Epoch 554/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1629 - acc: 0.9469\n",
      "Epoch 555/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1589 - acc: 0.9503\n",
      "Epoch 556/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1712 - acc: 0.9466\n",
      "Epoch 557/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1781 - acc: 0.9425\n",
      "Epoch 558/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1667 - acc: 0.9452\n",
      "Epoch 559/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1698 - acc: 0.9459\n",
      "Epoch 560/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1730 - acc: 0.9462\n",
      "Epoch 561/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1677 - acc: 0.9412\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1704 - acc: 0.9418\n",
      "Epoch 563/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1562 - acc: 0.9439\n",
      "Epoch 564/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1644 - acc: 0.9516\n",
      "Epoch 565/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1535 - acc: 0.9506\n",
      "Epoch 566/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1547 - acc: 0.9499\n",
      "Epoch 567/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1709 - acc: 0.9452\n",
      "Epoch 568/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1594 - acc: 0.9506\n",
      "Epoch 569/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1588 - acc: 0.9479\n",
      "Epoch 570/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1706 - acc: 0.9445\n",
      "Epoch 571/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1570 - acc: 0.9486\n",
      "Epoch 572/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1696 - acc: 0.9472\n",
      "Epoch 573/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1491 - acc: 0.9509\n",
      "Epoch 574/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1468 - acc: 0.9543\n",
      "Epoch 575/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1707 - acc: 0.9466\n",
      "Epoch 576/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1730 - acc: 0.9452\n",
      "Epoch 577/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1500 - acc: 0.9486\n",
      "Epoch 578/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1696 - acc: 0.9469\n",
      "Epoch 579/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1659 - acc: 0.9492\n",
      "Epoch 580/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1691 - acc: 0.9506\n",
      "Epoch 581/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1658 - acc: 0.9506\n",
      "Epoch 582/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1759 - acc: 0.9466\n",
      "Epoch 583/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1525 - acc: 0.9469\n",
      "Epoch 584/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1672 - acc: 0.9479\n",
      "Epoch 585/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1546 - acc: 0.9472\n",
      "Epoch 586/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1699 - acc: 0.9445\n",
      "Epoch 587/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1585 - acc: 0.9482\n",
      "Epoch 588/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1523 - acc: 0.9469\n",
      "Epoch 589/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1512 - acc: 0.9476\n",
      "Epoch 590/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1640 - acc: 0.9472\n",
      "Epoch 591/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1609 - acc: 0.9455\n",
      "Epoch 592/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1631 - acc: 0.9486\n",
      "Epoch 593/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1628 - acc: 0.9476\n",
      "Epoch 594/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1566 - acc: 0.9462\n",
      "Epoch 595/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1555 - acc: 0.9499\n",
      "Epoch 596/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1702 - acc: 0.9469\n",
      "Epoch 597/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1534 - acc: 0.9523\n",
      "Epoch 598/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1593 - acc: 0.9479\n",
      "Epoch 599/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1572 - acc: 0.9516\n",
      "Epoch 600/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1513 - acc: 0.9469\n",
      "Epoch 601/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1563 - acc: 0.9479\n",
      "Epoch 602/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1704 - acc: 0.9462\n",
      "Epoch 603/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1446 - acc: 0.9492\n",
      "Epoch 604/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1684 - acc: 0.9472\n",
      "Epoch 605/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1453 - acc: 0.9536\n",
      "Epoch 606/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1600 - acc: 0.9489\n",
      "Epoch 607/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1716 - acc: 0.9469\n",
      "Epoch 608/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1711 - acc: 0.9452\n",
      "Epoch 609/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1493 - acc: 0.9516\n",
      "Epoch 610/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1564 - acc: 0.9496\n",
      "Epoch 611/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1603 - acc: 0.9486\n",
      "Epoch 612/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1594 - acc: 0.9472\n",
      "Epoch 613/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1830 - acc: 0.9445\n",
      "Epoch 614/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1564 - acc: 0.9479\n",
      "Epoch 615/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1480 - acc: 0.9489\n",
      "Epoch 616/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1480 - acc: 0.9509\n",
      "Epoch 617/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1626 - acc: 0.9432\n",
      "Epoch 618/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1518 - acc: 0.9462\n",
      "Epoch 619/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1714 - acc: 0.9486\n",
      "Epoch 620/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1570 - acc: 0.9503\n",
      "Epoch 621/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1606 - acc: 0.9469\n",
      "Epoch 622/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1476 - acc: 0.9486\n",
      "Epoch 623/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1703 - acc: 0.9412\n",
      "Epoch 624/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1460 - acc: 0.9516\n",
      "Epoch 625/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1649 - acc: 0.9503\n",
      "Epoch 626/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1525 - acc: 0.9489\n",
      "Epoch 627/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1645 - acc: 0.9469\n",
      "Epoch 628/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1758 - acc: 0.9462\n",
      "Epoch 629/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1684 - acc: 0.9499\n",
      "Epoch 630/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1530 - acc: 0.9472\n",
      "Epoch 631/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1707 - acc: 0.9479\n",
      "Epoch 632/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1515 - acc: 0.9516\n",
      "Epoch 633/1000\n",
      "2975/2975 [==============================] - 0s 53us/step - loss: 0.1713 - acc: 0.9489\n",
      "Epoch 634/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1462 - acc: 0.9499\n",
      "Epoch 635/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1557 - acc: 0.9486\n",
      "Epoch 636/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1650 - acc: 0.9462\n",
      "Epoch 637/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1552 - acc: 0.9509\n",
      "Epoch 638/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1716 - acc: 0.9476\n",
      "Epoch 639/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1570 - acc: 0.9486\n",
      "Epoch 640/1000\n",
      "2975/2975 [==============================] - 0s 54us/step - loss: 0.1598 - acc: 0.9455\n",
      "Epoch 641/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1605 - acc: 0.9482\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1531 - acc: 0.9499\n",
      "Epoch 643/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1603 - acc: 0.9509\n",
      "Epoch 644/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1559 - acc: 0.9496\n",
      "Epoch 645/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1542 - acc: 0.9476\n",
      "Epoch 646/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1605 - acc: 0.9503\n",
      "Epoch 647/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1605 - acc: 0.9499\n",
      "Epoch 648/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1610 - acc: 0.9442\n",
      "Epoch 649/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1659 - acc: 0.9469\n",
      "Epoch 650/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1668 - acc: 0.9536\n",
      "Epoch 651/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1572 - acc: 0.9486\n",
      "Epoch 652/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1699 - acc: 0.9492\n",
      "Epoch 653/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1805 - acc: 0.9455\n",
      "Epoch 654/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1580 - acc: 0.9489\n",
      "Epoch 655/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1768 - acc: 0.9459\n",
      "Epoch 656/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1610 - acc: 0.9553\n",
      "Epoch 657/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1664 - acc: 0.9482\n",
      "Epoch 658/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1452 - acc: 0.9516\n",
      "Epoch 659/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1711 - acc: 0.9469\n",
      "Epoch 660/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1524 - acc: 0.9533\n",
      "Epoch 661/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1764 - acc: 0.9489\n",
      "Epoch 662/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1636 - acc: 0.9506\n",
      "Epoch 663/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1548 - acc: 0.9455\n",
      "Epoch 664/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1632 - acc: 0.9439\n",
      "Epoch 665/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1594 - acc: 0.9472\n",
      "Epoch 666/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1602 - acc: 0.9489\n",
      "Epoch 667/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1615 - acc: 0.9506\n",
      "Epoch 668/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1685 - acc: 0.9496\n",
      "Epoch 669/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1653 - acc: 0.9503\n",
      "Epoch 670/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1467 - acc: 0.9533\n",
      "Epoch 671/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1477 - acc: 0.9516\n",
      "Epoch 672/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1448 - acc: 0.9523\n",
      "Epoch 673/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1669 - acc: 0.9496\n",
      "Epoch 674/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1538 - acc: 0.9496\n",
      "Epoch 675/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1591 - acc: 0.9489\n",
      "Epoch 676/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1660 - acc: 0.9472\n",
      "Epoch 677/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1521 - acc: 0.9496\n",
      "Epoch 678/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1652 - acc: 0.9509\n",
      "Epoch 679/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1541 - acc: 0.9526\n",
      "Epoch 680/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1544 - acc: 0.9509\n",
      "Epoch 681/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1593 - acc: 0.9466\n",
      "Epoch 682/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1428 - acc: 0.9509\n",
      "Epoch 683/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1598 - acc: 0.9472\n",
      "Epoch 684/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1649 - acc: 0.9523\n",
      "Epoch 685/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1689 - acc: 0.9506\n",
      "Epoch 686/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1550 - acc: 0.9486\n",
      "Epoch 687/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1685 - acc: 0.9482\n",
      "Epoch 688/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1564 - acc: 0.9526\n",
      "Epoch 689/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1540 - acc: 0.9496\n",
      "Epoch 690/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1454 - acc: 0.9499\n",
      "Epoch 691/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1502 - acc: 0.9536\n",
      "Epoch 692/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1608 - acc: 0.9476\n",
      "Epoch 693/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1651 - acc: 0.9519\n",
      "Epoch 694/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1421 - acc: 0.9576\n",
      "Epoch 695/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1513 - acc: 0.9529\n",
      "Epoch 696/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1681 - acc: 0.9476\n",
      "Epoch 697/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1639 - acc: 0.9479\n",
      "Epoch 698/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1553 - acc: 0.9509\n",
      "Epoch 699/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1583 - acc: 0.9539\n",
      "Epoch 700/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1592 - acc: 0.9492\n",
      "Epoch 701/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1695 - acc: 0.9503\n",
      "Epoch 702/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1643 - acc: 0.9476\n",
      "Epoch 703/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1694 - acc: 0.9449\n",
      "Epoch 704/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1639 - acc: 0.9482\n",
      "Epoch 705/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1659 - acc: 0.9519\n",
      "Epoch 706/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1682 - acc: 0.9516\n",
      "Epoch 707/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1506 - acc: 0.9523\n",
      "Epoch 708/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1438 - acc: 0.9519\n",
      "Epoch 709/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1544 - acc: 0.9492\n",
      "Epoch 710/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1499 - acc: 0.9486\n",
      "Epoch 711/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1508 - acc: 0.9472\n",
      "Epoch 712/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1505 - acc: 0.9519\n",
      "Epoch 713/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1502 - acc: 0.9459\n",
      "Epoch 714/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1602 - acc: 0.9472\n",
      "Epoch 715/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1546 - acc: 0.9499\n",
      "Epoch 716/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1514 - acc: 0.9455\n",
      "Epoch 717/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1647 - acc: 0.9533\n",
      "Epoch 718/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1447 - acc: 0.9516\n",
      "Epoch 719/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1524 - acc: 0.9496\n",
      "Epoch 720/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1649 - acc: 0.9499\n",
      "Epoch 721/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1528 - acc: 0.9523\n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1503 - acc: 0.9536\n",
      "Epoch 723/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1648 - acc: 0.9482\n",
      "Epoch 724/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1612 - acc: 0.9506\n",
      "Epoch 725/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1566 - acc: 0.9496\n",
      "Epoch 726/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1534 - acc: 0.9543\n",
      "Epoch 727/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1652 - acc: 0.9506\n",
      "Epoch 728/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1534 - acc: 0.9523\n",
      "Epoch 729/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1720 - acc: 0.9506\n",
      "Epoch 730/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1601 - acc: 0.9482\n",
      "Epoch 731/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1483 - acc: 0.9499\n",
      "Epoch 732/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1516 - acc: 0.9489\n",
      "Epoch 733/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1653 - acc: 0.9536\n",
      "Epoch 734/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1522 - acc: 0.9539\n",
      "Epoch 735/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1538 - acc: 0.9466\n",
      "Epoch 736/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1588 - acc: 0.9516\n",
      "Epoch 737/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1630 - acc: 0.9462\n",
      "Epoch 738/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1451 - acc: 0.9539\n",
      "Epoch 739/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1619 - acc: 0.9533\n",
      "Epoch 740/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1527 - acc: 0.9482\n",
      "Epoch 741/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1542 - acc: 0.9523\n",
      "Epoch 742/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1544 - acc: 0.9499\n",
      "Epoch 743/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1821 - acc: 0.9503\n",
      "Epoch 744/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1501 - acc: 0.9533\n",
      "Epoch 745/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1690 - acc: 0.9466\n",
      "Epoch 746/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1509 - acc: 0.9499\n",
      "Epoch 747/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1597 - acc: 0.9492\n",
      "Epoch 748/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1549 - acc: 0.9445\n",
      "Epoch 749/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1689 - acc: 0.9479\n",
      "Epoch 750/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1497 - acc: 0.9526\n",
      "Epoch 751/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1634 - acc: 0.9509\n",
      "Epoch 752/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1512 - acc: 0.9536\n",
      "Epoch 753/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1781 - acc: 0.9466\n",
      "Epoch 754/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1396 - acc: 0.9539\n",
      "Epoch 755/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1448 - acc: 0.9556\n",
      "Epoch 756/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1472 - acc: 0.9509\n",
      "Epoch 757/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1613 - acc: 0.9499\n",
      "Epoch 758/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1404 - acc: 0.9516\n",
      "Epoch 759/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1355 - acc: 0.9546\n",
      "Epoch 760/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1654 - acc: 0.9496\n",
      "Epoch 761/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1420 - acc: 0.9560\n",
      "Epoch 762/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1472 - acc: 0.9509\n",
      "Epoch 763/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1459 - acc: 0.9550\n",
      "Epoch 764/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1562 - acc: 0.9526\n",
      "Epoch 765/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1549 - acc: 0.9526\n",
      "Epoch 766/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1582 - acc: 0.9506\n",
      "Epoch 767/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1370 - acc: 0.9519\n",
      "Epoch 768/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1479 - acc: 0.9523\n",
      "Epoch 769/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1529 - acc: 0.9496\n",
      "Epoch 770/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1656 - acc: 0.9509\n",
      "Epoch 771/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1512 - acc: 0.9486\n",
      "Epoch 772/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1530 - acc: 0.9492\n",
      "Epoch 773/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1602 - acc: 0.9503\n",
      "Epoch 774/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1570 - acc: 0.9533\n",
      "Epoch 775/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1548 - acc: 0.9503\n",
      "Epoch 776/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1513 - acc: 0.9513\n",
      "Epoch 777/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1638 - acc: 0.9539\n",
      "Epoch 778/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1510 - acc: 0.9513\n",
      "Epoch 779/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1616 - acc: 0.9469\n",
      "Epoch 780/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1748 - acc: 0.9432\n",
      "Epoch 781/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1642 - acc: 0.9459\n",
      "Epoch 782/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1616 - acc: 0.9472\n",
      "Epoch 783/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1597 - acc: 0.9560\n",
      "Epoch 784/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1507 - acc: 0.9543\n",
      "Epoch 785/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1570 - acc: 0.9496\n",
      "Epoch 786/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1569 - acc: 0.9506\n",
      "Epoch 787/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1512 - acc: 0.9499\n",
      "Epoch 788/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1546 - acc: 0.9526\n",
      "Epoch 789/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1547 - acc: 0.9526\n",
      "Epoch 790/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1532 - acc: 0.9539\n",
      "Epoch 791/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1624 - acc: 0.9523\n",
      "Epoch 792/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1636 - acc: 0.9536\n",
      "Epoch 793/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1512 - acc: 0.9553\n",
      "Epoch 794/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1453 - acc: 0.9539\n",
      "Epoch 795/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1437 - acc: 0.9573\n",
      "Epoch 796/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1663 - acc: 0.9529\n",
      "Epoch 797/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1723 - acc: 0.9462\n",
      "Epoch 798/1000\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 0.1425 - acc: 0.9539\n",
      "Epoch 799/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1615 - acc: 0.9503\n",
      "Epoch 800/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1561 - acc: 0.9489\n",
      "Epoch 801/1000\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1370 - acc: 0.9556\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 39us/step - loss: 0.1516 - acc: 0.9469\n",
      "Epoch 803/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1498 - acc: 0.9587\n",
      "Epoch 804/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1425 - acc: 0.9546\n",
      "Epoch 805/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1444 - acc: 0.9533\n",
      "Epoch 806/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1746 - acc: 0.9509\n",
      "Epoch 807/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1451 - acc: 0.9519\n",
      "Epoch 808/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1619 - acc: 0.9523\n",
      "Epoch 809/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1446 - acc: 0.9506\n",
      "Epoch 810/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1562 - acc: 0.9492\n",
      "Epoch 811/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1517 - acc: 0.9539\n",
      "Epoch 812/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1461 - acc: 0.9526\n",
      "Epoch 813/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1545 - acc: 0.9513\n",
      "Epoch 814/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1512 - acc: 0.9513\n",
      "Epoch 815/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1503 - acc: 0.9563\n",
      "Epoch 816/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1502 - acc: 0.9499\n",
      "Epoch 817/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1654 - acc: 0.9550\n",
      "Epoch 818/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1494 - acc: 0.9539\n",
      "Epoch 819/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1613 - acc: 0.9476\n",
      "Epoch 820/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1634 - acc: 0.9503\n",
      "Epoch 821/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1364 - acc: 0.9543\n",
      "Epoch 822/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1649 - acc: 0.9509\n",
      "Epoch 823/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1623 - acc: 0.9499\n",
      "Epoch 824/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1748 - acc: 0.9499\n",
      "Epoch 825/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1603 - acc: 0.9492\n",
      "Epoch 826/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1514 - acc: 0.9560\n",
      "Epoch 827/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1528 - acc: 0.9536\n",
      "Epoch 828/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1536 - acc: 0.9533\n",
      "Epoch 829/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1605 - acc: 0.9526\n",
      "Epoch 830/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1427 - acc: 0.9566\n",
      "Epoch 831/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1446 - acc: 0.9523\n",
      "Epoch 832/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1628 - acc: 0.9519\n",
      "Epoch 833/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1536 - acc: 0.9509\n",
      "Epoch 834/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1381 - acc: 0.9573\n",
      "Epoch 835/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1554 - acc: 0.9476\n",
      "Epoch 836/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1490 - acc: 0.9539\n",
      "Epoch 837/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1506 - acc: 0.9519\n",
      "Epoch 838/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1621 - acc: 0.9506\n",
      "Epoch 839/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1534 - acc: 0.9536\n",
      "Epoch 840/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1654 - acc: 0.9523\n",
      "Epoch 841/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1547 - acc: 0.9516\n",
      "Epoch 842/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1533 - acc: 0.9503\n",
      "Epoch 843/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1545 - acc: 0.9499\n",
      "Epoch 844/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1389 - acc: 0.9526\n",
      "Epoch 845/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1384 - acc: 0.9550\n",
      "Epoch 846/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1476 - acc: 0.9543\n",
      "Epoch 847/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1465 - acc: 0.9546\n",
      "Epoch 848/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1436 - acc: 0.9556\n",
      "Epoch 849/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1510 - acc: 0.9516\n",
      "Epoch 850/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1521 - acc: 0.9529\n",
      "Epoch 851/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1624 - acc: 0.9476\n",
      "Epoch 852/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1481 - acc: 0.9509\n",
      "Epoch 853/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1516 - acc: 0.9513\n",
      "Epoch 854/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1540 - acc: 0.9516\n",
      "Epoch 855/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1536 - acc: 0.9496\n",
      "Epoch 856/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1472 - acc: 0.9550\n",
      "Epoch 857/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1606 - acc: 0.9509\n",
      "Epoch 858/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1389 - acc: 0.9553\n",
      "Epoch 859/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1530 - acc: 0.9529\n",
      "Epoch 860/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1757 - acc: 0.9503\n",
      "Epoch 861/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1496 - acc: 0.9536\n",
      "Epoch 862/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1455 - acc: 0.9573\n",
      "Epoch 863/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1461 - acc: 0.9513\n",
      "Epoch 864/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1531 - acc: 0.9496\n",
      "Epoch 865/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1419 - acc: 0.9513\n",
      "Epoch 866/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1494 - acc: 0.9536\n",
      "Epoch 867/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1553 - acc: 0.9499\n",
      "Epoch 868/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1519 - acc: 0.9506\n",
      "Epoch 869/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1510 - acc: 0.9489\n",
      "Epoch 870/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1610 - acc: 0.9492\n",
      "Epoch 871/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1547 - acc: 0.9516\n",
      "Epoch 872/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1580 - acc: 0.9509\n",
      "Epoch 873/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1502 - acc: 0.9543\n",
      "Epoch 874/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1524 - acc: 0.9556\n",
      "Epoch 875/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1428 - acc: 0.9523\n",
      "Epoch 876/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1493 - acc: 0.9516\n",
      "Epoch 877/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1568 - acc: 0.9506\n",
      "Epoch 878/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1431 - acc: 0.9543\n",
      "Epoch 879/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1492 - acc: 0.9476\n",
      "Epoch 880/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1443 - acc: 0.9539\n",
      "Epoch 881/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1511 - acc: 0.9539\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1406 - acc: 0.9546\n",
      "Epoch 883/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1627 - acc: 0.9587\n",
      "Epoch 884/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1591 - acc: 0.9523\n",
      "Epoch 885/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1577 - acc: 0.9509\n",
      "Epoch 886/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1556 - acc: 0.9539\n",
      "Epoch 887/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1553 - acc: 0.9523\n",
      "Epoch 888/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1385 - acc: 0.9563\n",
      "Epoch 889/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1451 - acc: 0.9523\n",
      "Epoch 890/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1532 - acc: 0.9539\n",
      "Epoch 891/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1624 - acc: 0.9499\n",
      "Epoch 892/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1526 - acc: 0.9546\n",
      "Epoch 893/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1523 - acc: 0.9546\n",
      "Epoch 894/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1587 - acc: 0.9509\n",
      "Epoch 895/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1479 - acc: 0.9529\n",
      "Epoch 896/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1588 - acc: 0.9526\n",
      "Epoch 897/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1645 - acc: 0.9482\n",
      "Epoch 898/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1316 - acc: 0.9556\n",
      "Epoch 899/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1512 - acc: 0.9519\n",
      "Epoch 900/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1609 - acc: 0.9486\n",
      "Epoch 901/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1528 - acc: 0.9526\n",
      "Epoch 902/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1419 - acc: 0.9576\n",
      "Epoch 903/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1434 - acc: 0.9550\n",
      "Epoch 904/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1589 - acc: 0.9513\n",
      "Epoch 905/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1500 - acc: 0.9550\n",
      "Epoch 906/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1539 - acc: 0.9580\n",
      "Epoch 907/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1693 - acc: 0.9523\n",
      "Epoch 908/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1394 - acc: 0.9560\n",
      "Epoch 909/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1627 - acc: 0.9496\n",
      "Epoch 910/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1611 - acc: 0.9516\n",
      "Epoch 911/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1440 - acc: 0.9533\n",
      "Epoch 912/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1485 - acc: 0.9513\n",
      "Epoch 913/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1558 - acc: 0.9496\n",
      "Epoch 914/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1513 - acc: 0.9489\n",
      "Epoch 915/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1518 - acc: 0.9519\n",
      "Epoch 916/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1530 - acc: 0.9506\n",
      "Epoch 917/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1436 - acc: 0.9543\n",
      "Epoch 918/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1563 - acc: 0.9539\n",
      "Epoch 919/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1351 - acc: 0.9600\n",
      "Epoch 920/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1551 - acc: 0.9503\n",
      "Epoch 921/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1458 - acc: 0.9516\n",
      "Epoch 922/1000\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 0.1462 - acc: 0.9539\n",
      "Epoch 923/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1658 - acc: 0.9523\n",
      "Epoch 924/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1439 - acc: 0.9553\n",
      "Epoch 925/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1705 - acc: 0.9543\n",
      "Epoch 926/1000\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 0.1607 - acc: 0.9506\n",
      "Epoch 927/1000\n",
      "2975/2975 [==============================] - 0s 43us/step - loss: 0.1678 - acc: 0.9503\n",
      "Epoch 928/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1433 - acc: 0.9536\n",
      "Epoch 929/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1529 - acc: 0.9539\n",
      "Epoch 930/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1525 - acc: 0.9556\n",
      "Epoch 931/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1596 - acc: 0.9486\n",
      "Epoch 932/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1394 - acc: 0.9546\n",
      "Epoch 933/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1502 - acc: 0.9526\n",
      "Epoch 934/1000\n",
      "2975/2975 [==============================] - 0s 52us/step - loss: 0.1617 - acc: 0.9556\n",
      "Epoch 935/1000\n",
      "2975/2975 [==============================] - 0s 55us/step - loss: 0.1448 - acc: 0.9546\n",
      "Epoch 936/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1425 - acc: 0.9597\n",
      "Epoch 937/1000\n",
      "2975/2975 [==============================] - 0s 53us/step - loss: 0.1450 - acc: 0.9563\n",
      "Epoch 938/1000\n",
      "2975/2975 [==============================] - 0s 53us/step - loss: 0.1564 - acc: 0.9546\n",
      "Epoch 939/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1590 - acc: 0.9526\n",
      "Epoch 940/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1509 - acc: 0.9566\n",
      "Epoch 941/1000\n",
      "2975/2975 [==============================] - 0s 53us/step - loss: 0.1475 - acc: 0.9526\n",
      "Epoch 942/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1619 - acc: 0.9526\n",
      "Epoch 943/1000\n",
      "2975/2975 [==============================] - 0s 53us/step - loss: 0.1509 - acc: 0.9479\n",
      "Epoch 944/1000\n",
      "2975/2975 [==============================] - 0s 52us/step - loss: 0.1576 - acc: 0.9523\n",
      "Epoch 945/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1438 - acc: 0.9570\n",
      "Epoch 946/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1436 - acc: 0.9550\n",
      "Epoch 947/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1420 - acc: 0.9556\n",
      "Epoch 948/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1434 - acc: 0.9566\n",
      "Epoch 949/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1436 - acc: 0.9580\n",
      "Epoch 950/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1558 - acc: 0.9560\n",
      "Epoch 951/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1442 - acc: 0.9539\n",
      "Epoch 952/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1532 - acc: 0.9546\n",
      "Epoch 953/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1379 - acc: 0.9526\n",
      "Epoch 954/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1458 - acc: 0.9587\n",
      "Epoch 955/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1668 - acc: 0.9506\n",
      "Epoch 956/1000\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 0.1504 - acc: 0.9539\n",
      "Epoch 957/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1525 - acc: 0.9523\n",
      "Epoch 958/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1541 - acc: 0.9516\n",
      "Epoch 959/1000\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 0.1401 - acc: 0.9529\n",
      "Epoch 960/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1364 - acc: 0.9576\n",
      "Epoch 961/1000\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 0.1467 - acc: 0.9566\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1538 - acc: 0.9556\n",
      "Epoch 963/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1420 - acc: 0.9523\n",
      "Epoch 964/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1369 - acc: 0.9536\n",
      "Epoch 965/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1441 - acc: 0.9519\n",
      "Epoch 966/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1681 - acc: 0.9546\n",
      "Epoch 967/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1512 - acc: 0.9516\n",
      "Epoch 968/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1481 - acc: 0.9576\n",
      "Epoch 969/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1354 - acc: 0.9576\n",
      "Epoch 970/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1452 - acc: 0.9533\n",
      "Epoch 971/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1461 - acc: 0.9553\n",
      "Epoch 972/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1569 - acc: 0.9536\n",
      "Epoch 973/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1551 - acc: 0.9556\n",
      "Epoch 974/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1566 - acc: 0.9539\n",
      "Epoch 975/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1512 - acc: 0.9556\n",
      "Epoch 976/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1652 - acc: 0.9509\n",
      "Epoch 977/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1461 - acc: 0.9479\n",
      "Epoch 978/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1670 - acc: 0.9523\n",
      "Epoch 979/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1486 - acc: 0.9536\n",
      "Epoch 980/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1625 - acc: 0.9556\n",
      "Epoch 981/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1817 - acc: 0.9506\n",
      "Epoch 982/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1536 - acc: 0.9526\n",
      "Epoch 983/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1572 - acc: 0.9506\n",
      "Epoch 984/1000\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 0.1526 - acc: 0.9526\n",
      "Epoch 985/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1387 - acc: 0.9576\n",
      "Epoch 986/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1432 - acc: 0.9590\n",
      "Epoch 987/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1629 - acc: 0.9523\n",
      "Epoch 988/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1495 - acc: 0.9546\n",
      "Epoch 989/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1416 - acc: 0.9560\n",
      "Epoch 990/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1512 - acc: 0.9546\n",
      "Epoch 991/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1430 - acc: 0.9536\n",
      "Epoch 992/1000\n",
      "2975/2975 [==============================] - 0s 45us/step - loss: 0.1667 - acc: 0.9513\n",
      "Epoch 993/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1536 - acc: 0.9503\n",
      "Epoch 994/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1563 - acc: 0.9543\n",
      "Epoch 995/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1469 - acc: 0.9573\n",
      "Epoch 996/1000\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 0.1581 - acc: 0.9516\n",
      "Epoch 997/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1467 - acc: 0.9550\n",
      "Epoch 998/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1403 - acc: 0.9570\n",
      "Epoch 999/1000\n",
      "2975/2975 [==============================] - 0s 48us/step - loss: 0.1393 - acc: 0.9543\n",
      "Epoch 1000/1000\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 0.1471 - acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNX9//HXZ7IQdgg7BAhgAFlEMLK4gqggWmndUatVW0q16q+7VEXrUq1tbdUvBXfc6r6hImgRNxYhCLKGJQEhIBIChCWEbOf3x0yGLJNMiIHJHd7Px4PHZO6cuXNurr5z5pxzzzXnHCIiEl18ka6AiIjUPYW7iEgUUriLiEQhhbuISBRSuIuIRCGFu4hIFFK4i4hEIYW7iEgUUriLiESh2Eh9cOvWrV1ycnKkPl5ExJMWL168wznXJly5iIV7cnIyaWlpkfp4ERFPMrNva1JO3TIiIlFI4S4iEoUU7iIiUShife4iImUVFhaSlZVFfn5+pKtSLyQkJJCUlERcXFyt3q9wF5F6ISsri6ZNm5KcnIyZRbo6EeWcIycnh6ysLLp161arfahbRkTqhfz8fFq1anXMBzuAmdGqVasf9C1G4S4i9YaC/ZAf+rvwXLgv2riThz9aQ0FRSaSrIiJSb3ku3Bd/u4tHP1lPUYnCXUSkKp4L99IvKrqvt4jUtY0bN9KwYUNOPPFEwH8lfen2fv361dnnDB8+nI0bNwIwYsQImjRpUudX7Hsv3APprmwXkSOhR48eLF269Kh93pw5c0hNTa3z/XpuKqQF2u5OTXeRqPWX91ayauueOt1nn47NuOtHfQ/rPW3aVF6fKz8/n1/96lekpaURGxvLww8/zIgRI1i5ciXXXXcdBQUFlJSU8Oabb9KxY0cuu+wysrKyKC4u5s477+Tyyy8nMTGRmJiYujq0kLwX7mq5i8hRsmjRokrbJk+eDMDy5ctJT0/n3HPPZe3atUydOpVbb72Vq666ioKCAoqLi5kxYwYdO3bkgw8+ACA3NxeAt95664jX3XPhXkoNd5Hodbgt7KPpyy+/5Oabbwagd+/edO3albVr1zJs2DDuv/9+srKyuOiii0hJSaF///78/ve/509/+hMXXHABp59++lGrpwf73NV0F5HIqapL+Morr2T69Ok0bNiQUaNG8cknn9CzZ08WL15M//79mThxIvfcc89Rq6fnWu7B2TJKdxGJgDPOOIOXXnqJs846i7Vr17Jp0yZ69epFZmYm3bt355ZbbiEzM5Nly5bRu3dvEhMTufrqq2nSpAnTpk07avX0XriXNtyV7SISATfeeCMTJkygf//+xMbGMm3aNBo0aMCrr77Kiy++SFxcHO3bt2fSpEksWrSIP/zhD/h8PuLi4pgyZcpRq6f3wj3wqGwXkaMlOTmZFStWAP7VGkO1wCdOnMjEiRPLbRs1ahSjRo06GlWsxLN97poKKSJ1LSYmhtzc3OBFTEfDiBEjyMzMrPXSvlXxXstd46kiUcs5F9HFwzp37szmzZuP6mfOmTMn5PYf2oD1Xss98KiGu0h0SUhIICcnR9/KObSee0JCQq334bmWe2nTXbNlRKJLUlISWVlZZGdnR7oq9ULpnZhqy3PhHvzCpmwXiSpxcXG1vuuQVOa9bhn1uYuIhOW5cPcFZ8tEuCIiIvVY2HA3s2fMbLuZrajidTOzR81svZktM7NBdV/NMp8XeCxRuouIVKkmLfdpwOhqXj8PSAn8Gw8c0Uuw1C0jIhJe2HB3zn0O7KymyFjgeee3AGhhZh3qqoIVaT13EZHw6qLPvRNQdtZ/VmDbkaG1ZUREwqqLcA91OVnI6DWz8WaWZmZptZ3LGrlr10REvKMuwj0L6FzmeRKwNVRB59wTzrlU51xqqNtX1YRptoyISFh1Ee7TgWsCs2aGArnOue/qYL8haT13EZHwwl6hamYvA8OB1maWBdwFxAE456YCM4AxwHogD7juSFXWXx//o1ruIiJVCxvuzrlxYV53wE11VqMwNBVSRCQ8z12hqqmQIiLheS/c1XIXEQnLc+FeSg13EZGqeS7cD92lRekuIlIV74V74FEtdxGRqnkv3NXnLiISlvfCHV2hKiISjvfCPdhyV7qLiFTFe+EeeFTLXUSkat4Ldy0/ICISlufCvbTtrm4ZEZGqeS7c1XIXEQnPe+Ee6QqIiHiA98JdN+sQEQnLe+EeeFSfu4hI1bwX7upzFxEJy7vhHtlqiIjUa94Ld92sQ0QkLM+FO2q5i4iE5blw1/IDIiLheS/cdbMOEZGwvBfugUe13EVEqua9cFefu4hIWN4Ld92sQ0QkLO+Fe/AiJqW7iEhVvBvuka2GiEi95r1wD3TLlKjlLiJSJe+Fu2ZCioiE5b1wDzwq20VEqua9cNd67iIiYXkw3P2PWs9dRKRq3gv3wKNa7iIiVatRuJvZaDNbY2brzey2EK93MbM5ZrbEzJaZ2Zi6r2rpZ/kfle0iIlULG+5mFgNMBs4D+gDjzKxPhWJ3AK855wYCVwD/qeuKlqkRoIuYRESqU5OW+2BgvXMu0zlXALwCjK1QxgHNAj83B7bWXRXLU8tdRCS82BqU6QRsLvM8CxhSoczdwEdmdjPQGDi7TmoXQmmfu9JdRKRqNWm5W4htFaN1HDDNOZcEjAFeMLNK+zaz8WaWZmZp2dnZh19bykyFVLqLiFSpJuGeBXQu8zyJyt0uNwCvATjn5gMJQOuKO3LOPeGcS3XOpbZp06ZWFdZsGRGR8GoS7ouAFDPrZmbx+AdMp1coswkYCWBmx+MP99o1zcM4tCrkkdi7iEh0CBvuzrki4NfALGA1/lkxK83sHjO7MFDsd8AvzOwb4GXgZ+4ITWcJrud+JHYuIhIlajKginNuBjCjwrZJZX5eBZxat1ULTeu5i4iE57krVEsp2kVEqua5cFefu4hIeN4Ldy36KyISlvfCXS13EZGwvBvuka2GiEi95r1wRzfrEBEJx3vhrpt1iIiE5b1wDzyq5S4iUjXvhbv63EVEwvJguOtmHSIi4Xgu3GN9/nAvLlG4i4hUxXPhHhMI96JihbuISFU8F+6xPn+Vi9RyFxGpkvfCPaa0W6YkwjUREam/vBfupd0yarmLiFTJc+EeowFVEZGwPBfu6nMXEQnPc+GulruISHieC/dYTYUUEQnLc+Hu8xlmmi0jIlIdz4U7+Fvv6nMXEamaJ8M9xmfqcxcRqYYnwz3W51PLXUSkGp4Md7XcRUSq58lw9/e5a0BVRKQqngx3tdxFRKrnyXCP9RmFmucuIlIlT4Z7TIxa7iIi1fFkuMf5fBQWq89dRKQq3gz3GJ+WHxARqYY3wz3WKFDLXUSkSp4M9/gYdcuIiFSnRuFuZqPNbI2ZrTez26ooc5mZrTKzlWb237qtZnlxMT4OFincRUSqEhuugJnFAJOBc4AsYJGZTXfOrSpTJgWYCJzqnNtlZm2PVIUB4mN97DtYdCQ/QkTE02rSch8MrHfOZTrnCoBXgLEVyvwCmOyc2wXgnNtet9UsLz7GR4Fa7iIiVapJuHcCNpd5nhXYVlZPoKeZzTWzBWY2OtSOzGy8maWZWVp2dnbtaoy/W0Z97iIiVatJuFuIbRXnIcYCKcBwYBzwlJm1qPQm555wzqU651LbtGlzuHUNio/16QpVEZFq1CTcs4DOZZ4nAVtDlHnXOVfonNsArMEf9kdEnLplRESqVZNwXwSkmFk3M4sHrgCmVyjzDjACwMxa4++myazLipYVH+vTPHcRkWqEDXfnXBHwa2AWsBp4zTm30szuMbMLA8VmATlmtgqYA/zBOZdzpCodH2NquYuIVCPsVEgA59wMYEaFbZPK/OyA3wb+HXHxsT4OFhUfjY8SEfEkT16h2rhBLPmFJRSpa0ZEJCRPhnvThDgAXcgkIlIFj4a7vzdpb77CXUQkFE+Ge7NAyz33QGGEayIiUj95NNzVchcRqY4nw71xA3+45xUo3EVEQvFouMcAsL9A0yFFRELxZLg3ig+03DVbRkQkJE+Ge2m3jFruIiKheTLcG8UHumXUchcRCcmT4R4X4yM+1sd+DaiKiITkyXAHaBwfQ95BdcuIiITi2XBvFB+rlruISBU8G+6NG6jlLiJSFc+Gu1ruIiJV82y4N24QQ56mQoqIhOTZcG8UH6upkCIiVfBsuDdtEMserQopIhKSZ8M9uXVjtubmq/UuIhKCZ8N9QOcWAHy86vsI10REpP7xbLifflxrADKy90W4JiIi9Y9nw93nM5o2iNV9VEVEQvBsuAM0ahCjPncRkRA8He6NG8Rq2V8RkRC8He6a6y4iEpK3w13dMiIiIXk63Fs3acD3ew5GuhoiIvWOp8O9e5smZO3K42CR+t1FRMrydLj36dCMEgffbM6NdFVEROoVT4f7Kce1IsZnfL42O9JVERGpVzwd7s0S4ujdvinLt6jlLiJSlqfDHfyDqrvzCiJdDRGReqVG4W5mo81sjZmtN7Pbqil3iZk5M0utuypWr0WjOL7JymXr7gNH6yNFROq9sOFuZjHAZOA8oA8wzsz6hCjXFLgF+KquK1mdFg3jADj/0S+O5seKiNRrNWm5DwbWO+cynXMFwCvA2BDl7gUeAvLrsH5hNYiLAWBXXiEFRSVH86NFROqtmoR7J2BzmedZgW1BZjYQ6Oyce7+6HZnZeDNLM7O07Oy6meFy04jjgj9/tSGnTvYpIuJ1NQl3C7HNBV808wH/An4XbkfOuSecc6nOudQ2bdrUvJbVaN4wjqev9Xfx78rTbfdERKBm4Z4FdC7zPAnYWuZ5U6Af8KmZbQSGAtOP5qDqoC4tAdixV0sRiIhAzcJ9EZBiZt3MLB64Aphe+qJzLtc519o5l+ycSwYWABc659KOSI1DaN4wjvgYH1s0Y0ZEBKhBuDvnioBfA7OA1cBrzrmVZnaPmV14pCtYEz6fMahrC+au3xHpqoiI1AuxNSnknJsBzKiwbVIVZYf/8GodvjN7tuVvM9P5fk8+7ZolRKIKIiL1huevUC11Zk//AO2Qv84mfdueCNdGRCSyoibcj+/QNPjz/1Z9H8GaiIhEXtSEu5nx8GUDADhQqPXdReTYFjXhDnDRoCTiYozJczL46dNHdRUEEZF6JarCHfzTIgG+WKeZMyJy7Iq6cJ9xy+nBn+ekb49gTUREIifqwr1tswTG9G8PwHXTFkW4NiIikRF14Q4wODkx0lUQEYmoqAz378usMbMnX4uJicixJyrD/fLUQ+ucfbZGN88WkWNPVIZ7cuvGZP51DImN47n55SW8u3RLpKskInJURWW4g38xsZ8O7QrAH95YRq7WeheRY0jUhjvALSNTeGzcQIqKS7h/xirWfb+XO95Zzu68gkhXTUTkiKrRqpBeFeMzfjSgI//9ahOvpWXxWloWACd0asFlJ3cO824REe+K6pZ7qXvG9i33fEFmDns1i0ZEotgxEe4p7Zry1Z9H0qlFQwDeWrKFnz931G4UJSJy1B0T4Q7QrlkCX/5pBBa43fdXG3ay+Ntdka2UiMgRcsyEO/iXBb70pKTg84unzKOouCSCNRIROTKOqXAHeOCiE7hxeI/g8+Nu/5Arn1zAM19uiGCtRETqVlTPlgklxmf8YVQvzu7Tjov+Mw+AeRk5zMvIIS7WR58OzTipa8sI11JE5Ic55lru4O+eGdSlJd1aNy63/c53VnDxlHk451i4YSefrtnOvoNFEaqliEjtmXMuIh+cmprq0tIiO2Nld14BryzaTMtGcfzpzeUhywzs0oK7f9SXPh2bERdzTP4tFJF6xMwWO+dSw5U7ptOqRaN4JpzZg9F9O1RZZsmm3YydPJdJ7644ijUTEflhjumWe0XFJf7umPmZOTw6e12l19fcN5oGsTERqJmIiJ9a7rUQ4zOG9WjFrSNTODm58qDq32euIX3bHpJv+4Dfvro0AjUUEakZhXsIMT7j+euH8PPTupXb/tSXGxj97y8A/1Wuz87dwJbdByJRRRGRaqlbJozcvEKaNYzlhLs/Ym8VM2deHT+UD1dsIyN7Hy/cMOQo11BEjiXqlqkjzRvFYWac3rN1lWUuf2IB0+Zt5It1O/hs7aE7Pz35eSYzln93NKopIlKOwr2GJl3Ql+4V5sWHMvHNZXybs58Zy7/j/hmrufGlr5m9+nvGTp7LJ+nf1+iznHPMWrmNQg8sjeCFOoocixTuNdS+eQJv/OqUctsGJDXnvh/3K7dta24+Z/79U2586evgthueS+Obzbu5floaE99azpptewE4UFDM9r355d4/ec56npm7kV++sJhH/uefsXOwqJjsMjf9Bn930bbc8u8tde/7q7h4yrzaHehh+C73ACm3f8hrizYf8c8SkcNzzC0/8EMkNo5nwcSRtGgUR2FxCU0T4nDOccc7NZ8D//LCTby8cBN/ubAv732zlbRvd7HxwfMB/xWyLyz4Nlh23Xb/H4GbXlrC/1Z/z4YHxmCBZS3HPPoFW3Yf4OlrU2nWMI6TkxOD73u6huvkFBSVEOMzYnxW4/qXtXmnfzD55UWbdPMTkXqmRi13MxttZmvMbL2Z3Rbi9d+a2SozW2Zms82sa91XtX5o3zyBhLgYmibEAf6lDD689fTD3s9d01eSFlhy+Nm5G7j88fnlgh0gv7CEpZt387/V3weflyqdpXPDc2lcOnU+v3/9G+at31Hpc/ILi9m1v4D8wmJ+99o35Wb39LzjQ8Y/X/tB7dLlk/MOFoct+0n691z0n7kUl0RmAF/kWBM23M0sBpgMnAf0AcaZWZ8KxZYAqc65E4A3gIfquqL1WUrbJgBccXJnYgOt4FvOOo5xgzuz8PaR5frqX/7FUCZdUP7X95f3VvHVhp2V9js/M4fLHp8ffL4zr4C/zUxnU05epbJvLM7iyqe+4oX5G4Pbsvce5KdPf8XAez9mwouLefPrLCa+5V9moXSW1Oz07dUe28qtuTz88VpCzaraH5g9tL8g/Po7N/93CV9v2q07YIkcJTXplhkMrHfOZQKY2SvAWGBVaQHn3Jwy5RcAV9dlJeu72Bgfq+8ZTYNYHw9c1J+vN+1iUJeWwS6U2b87kxJHsPvjpK4t2br7AOf1b8/FU+ZXud+CovKDle8s2cKUTzOY8mlGle+5892VwZ9Pvv9/wZ8/XeOfxfP52mxWbMllb/6hQP5y3Q5OS2nN/Iwc5mfmcOlJSXRObMTfZ6UzeY7/s64e0oWWjeMpcS54le7+GrTYK9qbX0SLRvGH/b5Qnp27gb+8t4r0e0eTEKcrh0XKqkm4dwLKjphlAdVN5r4B+PCHVMqLGsYfCpeTuiaWe83MiCnTrR0f6+OOQOv9qz+PZMhfZ1fa3+BuiSys0Jr/+6w1dVLXCx77stzzq5/+Cp9BaY/Jo7PXseTOc4LBDrBtTz7XPLOQDTv2s+a+84BDLfcYn7FzfwFNE2IrLa62eWceLRvHU9ruL/tH5YeaPGc9ALkHCiuF+/a9+Qy+fzZPXpPKOX3a1dlninhFTcI91GhbyI5TM7saSAXOrOL18cB4gC5dutSwitGtXbMEXhk/lFkrtzGydzsGdW1Bo3j/acnee7Bc67uiqVcPYsKLX1faHuszig6zb7ti8YH3flzu+YX/Nzf4s3MOMwsuh1ziHIPu/ZjLUpPo2qoxx7Vtwv6DRWTvPcgDH6aX288f3/yGe8b2I6Vtk+C4RVl78wspKfFfX1DWsqzdbN19gNH9Ki/yNmP5d1x3avmriVdt3QPAc/M2KtzlmFSTcM8Cyk6FSAK2VixkZmcDtwNnOucOVnwdwDn3BPAE+K9QPezaRqmh3VsxtHurStvbNG3A0knn0DQhjt++tpR3l5b/tY/u14G7f9SHu99bRe/2TTm+QzPeXrKF+FgfRQXFjOjVhjlrsivt94f689sr+OOoXtz3gb9nbs8Bf8i/s3Rrpa6kilZs2RO8Scp9P+5HXIyRvfcgvz4rBYCfPbuIxd/u4uqhXTg5OZGxJ3YCDv1xKZ1ZtGPfQUqHAf7y3iquGZZcbtZPxYHbjOx9xMf46JzYqEbHmFdQxHPzvuXnp3cLfhsp/WP7j0sHcEmZ2zWK1Ec1CfdFQIqZdQO2AFcAV5YtYGYDgceB0c656kfo5LCU9k8/csVAHrliIIu/3cmSTbsZ0bstAIMCd4362SnJxMf6eHvJFsYN7hK8GcmcNdnE+CwYdm/feAonJLVg5opt/G1mOmcf345n5h7eLQZLp3OWyj3gHyQNF+wVvfl1Fks27QYgM3s/Azq3CN60/MUFm3hxwSYe/DCdv17UP/ie4hLH8XfOpKDCxVO78gpo3aQBmdn7aN4wjl15/jpl7crjjIfmsGmnfxB644Pnk1/oHyuo2JWzause+nRsBsCUTzN47JP1tGoSz2Wp/rbNhh37g8d/NMI9M3sfHZo3LNflV1845zhYVKKxjnqsRmvLmNkY4N9ADPCMc+5+M7sHSHPOTTez/wH9gdJr7Tc55y6sbp9eWVvGC7J25ZHUshFFxSU8M3cDVwzuQrPAHPzHPlnPwC4teD0ti9OOa11pPnpBUQk97zg0RNI5sSHPXz+EJZt2cUbPNpzywCcUFJfwi9O78eQXdXuf2Y7NE9haxYVYh+uO84/nxM4tuGSqf4D6ghM68P6yyks/dG/dmMwd+4mP8VFQXELv9k157vrBLMjM4dZXlnLqca2YcvVJTHhhMfMycvjV8B7My8hhdN/2nNi5BeOeXMCgLi1468ZTq63Puu/30qVVo1ovEV1UXMJxt3/IiF5tePa6wTV6z9TPMmjbtAEXDTryf3imzd3A3e+tYtHtZ5PYOJ70bXvo27H5Ef9cL+k7aSaj+3Xgn5cNqNP91nRtGS0cJjzz5QYaxPkY068DLRtXP5Ml+bYPav05D17Un9veCn3Hq0i79KQkXl+cVaOyPdo05qFLBnBi5xbE+AznHBt27Kd7mya8v2wrjeJjuH5aGqcd15rnrx+ML9Bd5JwjI3sf2/ccZOrnmTxzbSqxVdzda9f+Agbe+zFmsOEBf1fUkk27mPpZBo+NG0R8bOX3lZ6bW0am8NQXmcy77aw6m5lU0YX/9yXLsnKZ/utT+XRNNg9/vJb3bz6Nfp0qB3xxiePR2eu4akgX2jZLCG7PLywmPsZHiXM89eUGrh2WXO5byudrs8kvLObcvu3D1mfqZ/7B/wln9qiDo6sbpeejtCuxrtQ03HWFqnB9haWNq/Ofqwbx9pItPHLFiXy86ntmrdzGjOXbuPfH/bgzcKVuy0aHukUAJl85iG937ueSk5KYl5HD9G8qDdlEXE2DHSAjez8XT5nHGT3b8Pz1g3nqiw3cP2M1PxrQkffKHNuX63fQ/+5ZDO/Vlg9CLCB321vLufvCvsTFGA/MSOeSk5L4x0dr2HOgkKxd/ovNnIP+d89iSLdWwYvZet7xIcO6t2J+Zg5LJ51Di0bxwa4mIHijmYUbdtKiUTwnJx+algswc8U2mjWM5ZQerdm1v4CC4hIemb2OHm2aMKpvO5JaVh6X+OULaSzcsJMlk84F/IPo4L+5/JNfZAKQvS/kUBtLN+/mkdnrWL4ll2d+drL//SWO3nfO5OqhXTipa0se/DCdXfsLmDjm+OD7rnlmIVCzcHwwMHB/uOG+c38Bn63dzk8Glv+289DMdHq0acLFNex+KygqYVtuPl1a+X93Zc9HpCjc5bCM6d+BMf39M1bGntiJUX3bM+mCQto3T+DHJ3akqNjx/rKt3PnuSl6fMIze7ZuWmxUz/ozu5cK9tHukdZMGdE5syJJNu/nnpQPIPVDIPe/7B2zv+lEf5mXkcPuY40nftpcmDWJZuCGHRz9ZH9xPo/gY8grK/w91/gkdOCOlNZk79vP4Z5khj+f8/h1CBm9NfL42m5TbZ1BY7A+690L80dpfUFzl/t9YnMWabXvp3b4pry/OYtq8jSHL7c0vCgZ7qfmZOQCkb9tLateWDH2g8nTahz9eS3pgHSPw/66fu34wE15cDPj/UJddAwn86xJtfPB89h0s4uGP1rL7QAFdExsza6X/8x+amc5VQ7tSOuTxYJnZUIVFJUx8azl/Gt2LBrExTHxrGX8c3ZvZgbqXro+0J7+QT1b7h+ZeS8uid3v/OEfp2M20uRsq/aHYub+AxMbxPD9/Ix2aN+ScPu1wzlFU4sLe2zi/sBjn/NOVC4pK2Lm/gAWZOfx4YCcmvLiYhRt2clKXxGAwz1mznf8EriU5sUsLerRpEnK/l06dR/vmDXls3EDumr6Clxdu5pu7zmVvfiGn/e3QpT/Zew/y7tItTP0sg7Q7zqm2rnVJ3TJS55xz7NhXQJumDUK+viknj6xdeXyXm8+Azs05++HPGd6rDdPK9C0fLCqm1x0z/YPCvx8ecj8Hi4r50xvLuPzkLgzr0YoFmTk8+GE6PxnYie9y8/ntOT2Jj/Wx+NtdwYXUVt0zivs+WM1/v/IPCP/3F0PYlJPHc/O/ZfV3e8Ie2/gzuvPE56H/UFR0UteWwQHiI6niN6UfatU9o+gzaVat3/+zU5Jp3SSef3y0ttJrSyedw/mPflluGYxbRqYEv21sfPD8Sl1/pcdXdhxl44Pn8+CH6Uz9LIPJVw7ipv9+Hdz+wgL/ubx3bD9ifMaF//clK7bk8tS1qVw/7VDmXJ7amVfTDl3CU/oNoeznD05OZOHGnTw2biB3T19Jr/ZN+e8vhpYrt/HB8xn2wGy+y81nzu+H85tXl7J08+6Qv5sZt5weHLSvLfW5i2e89XUWw3u1JbFCf//MFdvon9ScTi0a/qD9F5c4HpqVzlWDu9KlVSPmZ+Qw7skF9OnQjBll1gXavDOPXXkFwWmXp/RoxbwMfwt5dN/2zFy5jUeuOJFbXwl/i8XurRtzw+nduP1t79xY/ZdndufxzzK5ckiX4B+/o6Ft0wZsD7Tqzz+hAx+EGAivaPbvzmTkPz+rtP2xcQO5+eUlALRoFEdSy4as2BL+jzb4w37mym3BbxBVufOCPsxbvyO4dMc7N53Kjyf7/5s5q3dbPgmzpMfbN57CwC6Vb+NZUwp3kSps35PP4L/O5uHLBoScWTJr5TZ++cJibjuvN0O6JRIX42P26u38639reX3CMPp2bMbW3Qc4++HPAbh9zPHcP2P7v4vXAAAI3ElEQVR18P33ju3LVUO6crCohOMnzQSoNjCvGtKFl35gmL4+YRjZew/y/PyNLMjcGdzv+u37Qq5bVNEbE4ax+rs95ZavqM9G9W0X7CrymnvH9uWnw5Jr/X4NqIpUoW2zBDL/OiY4i6Wic/u048lrUjmrd9vghVG92zdlaPfE4NLK3Vo34dKTkrju1G706diM01Ja0zmxEbNWbOP8Ezrg8xkN42NIv3c0hcUl7M4rDIb7Axf1p0PzBNo2TWD6N1v5zTkp/O7cXvx9VjovLzzUTXD28e0q9bW/f/NpweUjMv46hszsfXRr3Tg46+aLdTtYkLmTq4Z04f6f9OfawKBkr3ZNue7U5OBspbLLTfzm7J6kJicGrzgG/4qfpe2+P4zqxdDuiSHXQQp3NfQ9Y/sy9dMMbj07hS27DvDZ2mwuSe0cHHwP57fn9OThjw9174zs3ZZP12Z7NtjBv/6TmXH10CO7eK5a7iJHybtLt9CjTZOQ0wXBP/DX+05/S3/tfefhcMzPyGFIt1Y88OFqurduzM9O7cb8jBxWf7cn5Cyn9dv3ce0zC3n7xlNo2yyBeRk7uPLJr5h69SDO6dOeHn+ewYCk5tw04jjGv+AfWH103EAuHNAxOP3y1pEp3DoyhQH3fMRvzu4Z/JzM7H10SWzEtc8u5Ozj2wWXfNi5v4BBFZarAGiWEMuyu0eFPNbhf5/DxhCrmw7ulsiLNwwJXntRsQ9+wwNjOO1vc4J99s9edzLjn08LDmoD/Gp4D87s2YYrnlhQaf8je7elf1Jz/h24EU5Zvds3LTcAXdH9P+nH459lBi+Iq8o/Lh3A0s27uHhQEj/5T+ib5ky77mSG92pb7X6qom4ZEalkWdZuuiY2pnmjOPIKinjz6y1cNbhL8FvMrv0FNGsYd1g3cCksLiHl9kMXwj11TSo/fz6Nk5Nb8vqEU6p8z4otucHwm/n/Tg/OmoHyg5VLNu0Kltv44Pnc9NLXfLD8u2BAvrxwExPfWs5HvzmDT9K3B+fLf7Eum1ifj+fmbeTELi148MN0Hrr4BFo2jucXgfsYPH1tKjc8l8a9Y/ty9dCudJs4A4Bv7jqX3XkFXDxlHg1iY/jnZQMY2r0V23Lzee+brXyxfgefr82mX6dmlfr0S6enAvzkP3NZsmk34wZ35jfn9GTKpxm8kZbF538cEfaakqoo3EXkqHp36RZmrtjGlKtP4sUF3zK6X3taNwk9Y6pU2sadFBSXcEqP8jegn5exg29z8hg32L/A4Pa9+RwoKKZrq8bkFxazfvu+4Dcg5xx7DhRVWmyuoozsffRo04SPVm5j/AuL+cnATvzr8hPLlbnxpcU0jIstd1Vp6UJ5ZR0oKGbF1ly6tW7Mo7PX0a5ZArE+Y25GDs9ff2jWV15BEQVFJeUuJisqLqny4rWaULiLiIRQWFzCPz5aw4QzetS69RxJGlAVEQkhLsbHxPOOD1/Q42r/3UBEROothbuISBRSuIuIRCGFu4hIFFK4i4hEIYW7iEgUUriLiEQhhbuISBSK2BWqZpYNfFvLt7cGdtRhdbxAx3xs0DEfG37IMXd1zrUJVyhi4f5DmFlaTS6/jSY65mODjvnYcDSOWd0yIiJRSOEuIhKFvBruT0S6AhGgYz426JiPDUf8mD3Z5y4iItXzastdRESq4blwN7PRZrbGzNab2W2Rrk9dMbPOZjbHzFab2UozuzWwPdHMPjazdYHHloHtZmaPBn4Py8xsUGSPoHbMLMbMlpjZ+4Hn3czsq8Dxvmpm8YHtDQLP1wdeT45kvWvLzFqY2Rtmlh4418OOgXP8m8B/0yvM7GUzS4jG82xmz5jZdjNbUWbbYZ9bM7s2UH6dmV1b2/p4KtzNLAaYDJwH9AHGmVmfyNaqzhQBv3POHQ8MBW4KHNttwGznXAowO/Ac/L+DlMC/8cCUo1/lOnErsLrM878B/woc7y7ghsD2G4BdzrnjgH8FynnRI8BM51xvYAD+Y4/ac2xmnYBbgFTnXD8gBriC6DzP04DRFbYd1rk1s0TgLmAIMBi4q/QPwmFzznnmHzAMmFXm+URgYqTrdYSO9V3gHGAN0CGwrQOwJvDz48C4MuWD5bzyD0gK/Ad/FvA+YPgv7IiteL6BWcCwwM+xgXIW6WM4zONtBmyoWO8oP8edgM1AYuC8vQ+MitbzDCQDK2p7boFxwONltpcrdzj/PNVy59B/KKWyAtuiSuCr6EDgK6Cdc+47gMBj20CxaPhd/Bv4I1ASeN4K2O2cKwo8L3tMweMNvJ4bKO8l3YFs4NlAV9RTZtaYKD7HzrktwD+ATcB3+M/bYqL7PJd1uOe2zs6518LdQmyLquk+ZtYEeBP4f865PdUVDbHNM78LM7sA2O6cW1x2c4iirgaveUUsMAiY4pwbCOzn0Nf0UDx/zIEuhbFAN6Aj0Bh/l0RF0XSea6Kq46yz4/dauGcBncs8TwK2Rqgudc7M4vAH+0vOubcCm783sw6B1zsA2wPbvf67OBW40Mw2Aq/g75r5N9DCzEpv3F72mILHG3i9ObDzaFa4DmQBWc65rwLP38Af9tF6jgHOBjY457Kdc4XAW8ApRPd5Lutwz22dnXOvhfsiICUw0h6Pf2BmeoTrVCfMzICngdXOuYfLvDQdKB0xvxZ/X3zp9msCo+5DgdzSr39e4Jyb6JxLcs4l4z+PnzjnrgLmAJcEilU83tLfwyWB8p5q0TnntgGbzaxXYNNIYBVReo4DNgFDzaxR4L/x0mOO2vNcweGe21nAuWbWMvCt59zAtsMX6QGIWgxYjAHWAhnA7ZGuTx0e12n4v34tA5YG/o3B3984G1gXeEwMlDf8M4cygOX4ZyNE/DhqeezDgfcDP3cHFgLrgdeBBoHtCYHn6wOvd490vWt5rCcCaYHz/A7QMtrPMfAXIB1YAbwANIjG8wy8jH9coRB/C/yG2pxb4PrA8a8HrqttfXSFqohIFPJat4yIiNSAwl1EJAop3EVEopDCXUQkCincRUSikMJdRCQKKdxFRKKQwl1EJAr9f+8YdbsjG4SuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history[\"loss\"], label=[\"loss\"]) #play with hyperparameters to see the changes\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(history.history[\"acc\"],  label=[\"acc\"])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 0s 40us/step\n",
      "Loss / Accuracy Evaluation\n",
      "--------------------------\n",
      "Loss:     0.47856\n",
      "Accuracy: 0.92608\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_val, y_val)\n",
    "print(\"Loss / Accuracy Evaluation\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Loss:     \" + str(round(test_loss,5)))\n",
    "print(\"Accuracy: \" + str(round(test_acc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5722799e-05, 9.9990404e-01, 0.0000000e+00, 8.0190061e-05,\n",
       "       1.8794732e-09], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_pred[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model in tensorflow.js Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflowjs library can't be installed directly with pip / conda due to conflicting dependencies. Best is to set up a new environment explicitly for this and install tensorflowjs with the following commands:\n",
    "\n",
    "```\n",
    "pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "pip install --no-deps tensorflowjs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.11.0rc2\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow==1.11.0rc2 (from versions: 0.12.1, 1.0.0, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2)\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow==1.11.0rc2\u001b[0m\n",
      "Requirement already satisfied: tensorflowjs in /Users/lsafari/anaconda3/lib/python3.6/site-packages (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==1.11.0rc2 h5py numpy keras\n",
    "! pip install --no-deps tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/d7/90f34cb0d83a6c5631cf71dfe64cc1054598c843a92b400e55675cc2ac37/pip-18.1-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 3.5MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.0\n",
      "    Uninstalling pip-18.0:\n",
      "      Successfully uninstalled pip-18.0\n",
      "Successfully installed pip-18.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /Users/lsafari/anaconda3/lib/python3.6/site-packages (4.8.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (6.4.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (4.3.2)\n",
      "Requirement already satisfied: jupyter_client in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (5.2.3)\n",
      "Requirement already satisfied: tornado>=4.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipykernel) (5.0.2)\n",
      "Requirement already satisfied: pickleshare in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.7.4)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.12.0)\n",
      "Requirement already satisfied: backcall in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.8.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (1.0.15)\n",
      "Requirement already satisfied: decorator in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (4.3.0)\n",
      "Requirement already satisfied: pygments in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (39.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel) (0.1.0)\n",
      "Requirement already satisfied: ipython_genutils in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: six in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (1.11.0)\n",
      "Requirement already satisfied: jupyter_core in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (17.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jupyter_client->ipykernel) (2.7.3)\n",
      "Requirement already satisfied: parso>=0.2.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel) (0.5.2)\n",
      "Requirement already satisfied: tensorflow_hub in /Users/lsafari/anaconda3/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (3.6.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.14.3)\n",
      "Requirement already satisfied: setuptools in /Users/lsafari/anaconda3/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow_hub) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ipykernel\n",
    "! pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lsafari/drone_steering/models\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "model.save('pose_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'model_pose_tfjs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adapt the two files as follows in order for them to work on Azure:\n",
    "* add a file extension .pb to the file with no extension (otherwise Azure blocks it from viewing)\n",
    "* adapt the automatically generated model.json to reflect the extension .pb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
