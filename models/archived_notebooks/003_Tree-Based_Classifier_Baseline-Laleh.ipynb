{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/lsafari/drone_steering/models/playground\n",
      "1 /Users/lsafari/drone_steering/models\n",
      "2 /Users/lsafari/drone_steering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "counter = 0\n",
    "print(counter, cwd)\n",
    "while not cwd.endswith(\"drone_steering\") and counter < 10:\n",
    "    os.chdir('..')\n",
    "    cwd = os.getcwd()\n",
    "    counter = counter + 1\n",
    "    print(counter, cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_local.module import DataEnsembler, GestureTransformer\n",
    "\n",
    "de = DataEnsembler(120)\n",
    "de.investigate_available_datafiles(data_dir='data/gesture/',is_frame_based=True)\n",
    "de.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Data rescaling to actual video length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de.rescale_data_frames(time_of_first_frame='avg',verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Interpolate and adjust framebased labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de.interpolate_and_convert_framebased_labels(new_frmlen=50,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de.assemble_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de.display_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = de.X.copy()\n",
    "y = de.y.copy().astype(\"int32\")\n",
    "gt = GestureTransformer(byrow=True, feature_names= list(de.feature_names))\n",
    "X = gt.transform(X, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Filtering 0-Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of 0-labels to use for traing\n",
    "n = 750\n",
    "\n",
    "\n",
    "# only select certain indeces to prevent too many 0-labeled instances\n",
    "idx = []\n",
    "for i in sorted(set(y)):\n",
    "    idx.append(np.where(np.isclose(y,i))[0])\n",
    "\n",
    "print(\"----- labels summary before --------------------------------\")\n",
    "for i in sorted(set(y)):\n",
    "    print(i,len(idx[i]))\n",
    "print(\"\")\n",
    "    \n",
    "zero_idx = np.random.choice(idx[0], n, replace=False)\n",
    "keep_idx = np.concatenate([zero_idx,idx[1],idx[2],idx[3],idx[4],idx[5],idx[6]])\n",
    "keep_idx = sorted(keep_idx)\n",
    "\n",
    "y = y[keep_idx]\n",
    "X = X[keep_idx]\n",
    "print(\"Shapes after:\",y.shape, X.shape) \n",
    "print(\"\")\n",
    "\n",
    "idx = []\n",
    "for i in sorted(set(y)):\n",
    "    idx.append(np.where(np.isclose(y,i))[0])\n",
    "\n",
    "print(\"----- labels summary after --------------------------------\")\n",
    "for i in sorted(set(y)):\n",
    "    print(i,len(idx[i]))\n",
    "print(\"\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) OneHot-Encoding of target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)\n",
    "print(type(ohe))\n",
    "target = ohe.fit_transform(y.reshape(-1,1))\n",
    "print(\"Before:\", y.shape)\n",
    "print(\"After:\", target.shape)\n",
    "target[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=10)\n",
    "print(\"Training Data:\", x_train.shape, y_train.shape)\n",
    "print(\"Test Data:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators = 100, # 100\n",
    "    criterion = \"gini\", # {gini, entropy}\n",
    "    max_depth = None , # None\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "model.fit(x_train.reshape(x_train.shape[0],-1),y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy is already 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_train.reshape(x_train.shape[0],-1))\n",
    "(preds == y_train).all(axis = 1).sum()/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy is 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test.reshape(x_test.shape[0],-1))\n",
    "(preds == y_test).all(axis = 1).sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch with Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 500, 1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = [5, 10, 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 110, num = 4)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "               'randomforestclassifier__max_features': max_features,\n",
    "               'randomforestclassifier__max_depth': max_depth,\n",
    "              }\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "              }\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training takes quite a long time - do not needlessly repeat it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = random_grid\n",
    "scoring = \"accuracy\"\n",
    "clf = GridSearchCV(model, params, n_jobs = -1, verbose = 10, scoring = scoring)\n",
    "clf.fit(x_train.reshape(x_train.shape[0],-1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine performance of best Gridsearch-Model on the Holdout-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.best_estimator_.predict(x_test.reshape(x_test.shape[0],-1))\n",
    "(preds == y_test).all(axis = 1).sum()/y_test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
