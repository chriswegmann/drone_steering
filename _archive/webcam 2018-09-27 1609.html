<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta content="stuff, to, help, search, engines, not" name="keywords">
<meta content="What this page is about." name="description">
<meta content="Display Webcam Stream" name="title">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Capturing coordinates with PoseNet</title>

<script src="https://unpkg.com/@tensorflow/tfjs"></script>
<script src="https://unpkg.com/@tensorflow-models/posenet"></script>
  
<style>
#video {
    width: 800px;
    height: 555px;
    background-color: #666;
}
</style>
</head>
  
<body>
	
    <div id="main">
        <video id="video" playsinline="" style=" -moz-transform: scaleX(-1);
        -o-transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
        transform: scaleX(-1);
        ">
        </video>
        <canvas id="output">
    </canvas></div>	
	
	

<button id="video_button" onclick='get_coordinates()'>Get coordinates</button>
<p>
  We have stored the coordinates
  <span id="count">0</span>
  time(s).
</p>

<script> 

//var video = document.querySelector("#videoElement");

	const multiplier = 0.5;
  const imageScaleFactor = 0.5;
  const flipHorizontal = false;
  const outputStride = 8;
	const videoWidth = 800;
	const videoHeight = 555;
  let estimator = null;
  localStorage.position = ''

	video = loadVideo();

	function get_coordinates() {
	// runs the video and gets the coordinates for each snapshot of a time interval as long as the video is running

		var i = 0;
		var interval = 300

	  //node = document.getElementById('count'),
	  tid = setInterval(function() {
	    //if (!video.ended && !video.paused) {
	    if (i < 10) {
	    	++i;
	      document.getElementById('count').innerHTML = i
	      getCoordSnapshot(video)
	    }
	  }, interval);

	}
  
  function getCoordSnapshot(imgData) {
	// gets to coordinates of imgData at the given time and stores it locally in a log file. This log file is available under
	// C:\Users\Christian\AppData\Local\Google\Chrome\User Data\Default\Local Storage\leveldb
	
    posenet
      .load(multiplier)
      .then(function(net) {
        if (!estimator) estimator = createEstimator(net);
        return estimator(imgData, imageScaleFactor, flipHorizontal, outputStride)
      })
      .then((resp) => {
        position = JSON.stringify(resp)
        console.log(position);
        localStorage.position = localStorage.position + position;
      })
  }

  function createEstimator(net) {
    return function (imageElement, scaleFactor, flipHorizontal, outputStride) {
      return net.estimateSinglePose(imageElement, scaleFactor, flipHorizontal, outputStride);
    }
  }  

	function sleep(milliseconds) {
	  var start = new Date().getTime();
	  for (var i = 0; i < 1e7; i++) {
	    if ((new Date().getTime() - start) > milliseconds){
	      break;
	    }
	  }
	}


/**
 * Loads a the camera to be used in the demo
 *
 */
async function setupCamera() {

  const video = document.getElementById('video');
  video.width = videoWidth;
  video.height = videoHeight;

  const stream = await navigator.mediaDevices.getUserMedia({
    'audio': false,
    'video': {
      facingMode: 'user',
      width: videoWidth,
      height: videoHeight
    }
  });
  video.srcObject = stream;

	return video;

}

async function loadVideo() {
  const video = await setupCamera();
  video.play();

  return video;
}

const guiState = {
  algorithm: 'multi-pose',
  input: {
    mobileNetArchitecture: '0.75',
    outputStride: 16,
    imageScaleFactor: 0.5
  },
  singlePoseDetection: {
    minPoseConfidence: 0.1,
    minPartConfidence: 0.5
  },
  multiPoseDetection: {
    maxPoseDetections: 5,
    minPoseConfidence: 0.15,
    minPartConfidence: 0.1,
    nmsRadius: 30.0
  },
  output: {
    showVideo: true,
    showSkeleton: true,
    showPoints: true,
    showBoundingBox: false
  },
  net: null
};









</script>
</body>
</html>